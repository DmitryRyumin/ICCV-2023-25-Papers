# ICCVW-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/workshops/w-on-cv-in-plant-phenotyping-and-agriculture.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/workshops/w-representation-learning-with-very-limited-images.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Workshop on New Ideas in Vision Transformers

![Section Papers](https://img.shields.io/badge/Section%20Papers-18-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-8-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-9-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-10-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Explaining Through Transformer Input Sampling | [![GitHub](https://img.shields.io/github/stars/aenglebert/Transformer_Input_Sampling?style=flat)](https://github.com/aenglebert/Transformer_Input_Sampling) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Englebert_Explaining_Through_Transformer_Input_Sampling_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| Actor-Agnostic Multi-Label Action Recognition with Multi-Modal Query | [![GitHub](https://img.shields.io/github/stars/mondalanindya/MSQNet?style=flat)](https://github.com/mondalanindya/MSQNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Mondal_Actor-Agnostic_Multi-Label_Action_Recognition_with_Multi-Modal_Query_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.10763-b31b1b.svg)](https://arxiv.org/abs/2307.10763) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bafoEVdQYJg) |
| All-Pairs Consistency Learning forWeakly Supervised Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Sun_All-pairs_Consistency_Learning_forWeakly_Supervised_Semantic_Segmentation_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| Dual-Contrastive Dual-Consistency Dual-Transformer: A Semi-Supervised Approach to Medical Image Segmentation | [![GitHub](https://img.shields.io/github/stars/ziyangwang007/CV-SSL-MIS?style=flat)](https://github.com/ziyangwang007/CV-SSL-MIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Wang_Dual-Contrastive_Dual-Consistency_Dual-Transformer_A_Semi-Supervised_Approach_to_Medical_Image_Segmentation_ICCVW_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JU9koBE83co) |
| A Hybrid Visual Transformer for Efficient Deep Human Activity Recognition | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Djenouri_A_Hybrid_Visual_Transformer_for_Efficient_Deep_Human_Activity_Recognition_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| Which Tokens to Use? Investigating Token Reduction in Vision Transformers | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://vap.aau.dk/tokens/) <br /> [![GitHub](https://img.shields.io/github/stars/JoakimHaurum/TokenReduction?style=flat)](https://github.com/JoakimHaurum/TokenReduction) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Haurum_Which_Tokens_to_Use_Investigating_Token_Reduction_in_Vision_Transformers_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04657-b31b1b.svg)](https://arxiv.org/abs/2308.04657) | :heavy_minus_sign: |
| Hierarchical Spatiotemporal Transformers for Video Object Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Yoo_Hierarchical_Spatiotemporal_Transformers_for_Video_Object_Segmentation_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08263-b31b1b.svg)](https://arxiv.org/abs/2307.08263) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JV9TyazM38Y) |
| IDTransformer: Transformer for Intrinsic Image Decomposition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://morpheus3000.github.io/IDTransformer.web/) <br /> [![GitHub](https://img.shields.io/github/stars/ParthaDasWeb/IDTransformer.web?style=flat)](https://github.com/ParthaDasWeb/IDTransformer.web) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Das_IDTransformer_Transformer_for_Intrinsic_Image_Decomposition_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| MSViT: Dynamic Mixed-Scale Tokenization for Vision Transformers | [![GitHub](https://img.shields.io/github/stars/Qualcomm-AI-research/batchshaping?style=flat)](https://github.com/Qualcomm-AI-research/batchshaping) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Havtorn_MSViT_Dynamic_Mixed-Scale_Tokenization_for_Vision_Transformers_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.02321-b31b1b.svg)](https://arxiv.org/abs/2307.02321) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1H7LJ7-v58w) |
| Template-Guided Illumination Correction for Document Images with Imperfect Geometric Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://felixhertlein.github.io/illtrtemplate/) <br /> [![GitHub](https://img.shields.io/github/stars/FelixHertlein/illtrtemplate-model?style=flat)](https://github.com/FelixHertlein/illtrtemplate-model) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Hertlein_Template-Guided_Illumination_Correction_for_Document_Images_with_Imperfect_Geometric_Reconstruction_ICCVW_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CWrMHbvScSM) |
| Spatio-Temporal Convolution-Attention Video Network | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Diba_Spatio-Temporal_Convolution-Attention_Video_Network_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| TSOSVNet: Teacher-Student Collaborative Knowledge Distillation for Online Signature Verification | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Sekhar_TSOSVNet_Teacher-Student_Collaborative_Knowledge_Distillation_for_Online_Signature_Verification_ICCVW_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=y0akK9vZ4xE) |
| SeMask: Semantically Masked Transformers for Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/Picsart-AI-Research/SeMask-Segmentation?style=flat)](https://github.com/Picsart-AI-Research/SeMask-Segmentation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Jain_SeMask_Semantically_Masked_Transformers_for_Semantic_Segmentation_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2112.12782-b31b1b.svg)](https://arxiv.org/abs/2112.12782) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=eLg2rmFWiGs) |
| TransInpaint: Transformer-based Image Inpainting with Context Adaptation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Shamsolmoali_TransInpaint_Transformer-Based_Image_Inpainting_with_Context_Adaptation_ICCVW_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ynEg6y4si_8) |
| Interactive Image Segmentation with Cross-Modality Vision Transformers | [![GitHub](https://img.shields.io/github/stars/lik1996/iCMFormer?style=flat)](https://github.com/lik1996/iCMFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Li_Interactive_Image_Segmentation_with_Cross-Modality_Vision_Transformers_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.02280-b31b1b.svg)](https://arxiv.org/abs/2307.02280) | :heavy_minus_sign:  |
| MOSAIC: Multi-Object Segmented Arbitrary Stylization using CLIP | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Ganugula_MOSAIC_Multi-Object_Segmented_Arbitrary_Stylization_Using_CLIP_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13716-b31b1b.svg)](https://arxiv.org/abs/2309.13716) | :heavy_minus_sign: |
| On Moving Object Segmentation from Monocular Video with Transformers | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Homeyer_On_Moving_Object_Segmentation_from_Monocular_Video_with_Transformers_ICCVW_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5kuGvSJmitQ) |
| SCSC: Spatial Cross-Scale Convolution Module to Strengthen Both CNNs and Transformers | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Wang_SCSC_Spatial_Cross-Scale_Convolution_Module_to_Strengthen_Both_CNNs_and_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07110-b31b1b.svg)](https://arxiv.org/abs/2308.07110) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LE6ncJVvJMQ) |
