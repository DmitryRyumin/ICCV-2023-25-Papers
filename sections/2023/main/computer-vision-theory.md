# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ü§ó-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/low-level-and-physics-based-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/video-analysis-and-understanding.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Computer Vision Theory

![Section Papers](https://img.shields.io/badge/Section%20Papers-9-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-5-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-6-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Environment-Invariant Curriculum Relation Learning for Fine-Grained Scene Graph Generation | [![GitHub](https://img.shields.io/github/stars/myukzzz/EICR?style=flat)](https://github.com/myukzzz/EICR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Min_Environment-Invariant_Curriculum_Relation_Learning_for_Fine-Grained_Scene_Graph_Generation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03282-b31b1b.svg)](https://arxiv.org/abs/2308.03282) | :heavy_minus_sign: |
| DCPB: Deformable Convolution based on the Poincar√© Ball for Top-View Fisheye Cameras | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_DCPB_Deformable_Convolution_Based_on_the_Poincare_Ball_for_Top-view_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| FemtoDet: An Object Detection Baseline for Energy Versus Performance Tradeoffs | [![GitHub](https://img.shields.io/github/stars/yh-pengtu/FemtoDet?style=flat)](https://github.com/yh-pengtu/FemtoDet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_FemtoDet_An_Object_Detection_Baseline_for_Energy_Versus_Performance_Tradeoffs_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.06719-b31b1b.svg)](https://arxiv.org/abs/2301.06719) | :heavy_minus_sign: |
| Curvature-Aware Training for Coordinate Networks | [![GitHub](https://img.shields.io/github/stars/sfchng/curvature-aware-INRs?style=flat)](https://github.com/sfchng/curvature-aware-INRs) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Saratchandran_Curvature-Aware_Training_for_Coordinate_Networks_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.08552-b31b1b.svg)](https://arxiv.org/abs/2305.08552) | :heavy_minus_sign: |
| Yes, We CANN: Constrained Approximate Nearest Neighbors for Local Feature-based Visual Localization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Aiger_Yes_we_CANN_Constrained_Approximate_Nearest_Neighbors_for_Local_Feature-Based_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.09012-b31b1b.svg)](https://arxiv.org/abs/2306.09012) | :heavy_minus_sign: |
| Unleashing the Potential of Spiking Neural Networks with Dynamic Confidence | [![GitHub](https://img.shields.io/github/stars/chenlicodebank/Dynamic-Confidence-in-Spiking-Neural-Networks?style=flat)](https://github.com/chenlicodebank/Dynamic-Confidence-in-Spiking-Neural-Networks) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unleashing_the_Potential_of_Spiking_Neural_Networks_with_Dynamic_Confidence_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Minimal Solutions to Uncalibrated Two-View Geometry with Known Epipoles | [![GitHub](https://img.shields.io/github/stars/g9nkn/uncalibF_epipoles?style=flat)](https://github.com/g9nkn/uncalibF_epipoles) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakano_Minimal_Solutions_to_Uncalibrated_Two-view_Geometry_with_Known_Epipoles_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| FBLNet: FeedBack Loop Network for Driver Attention Prediction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FBLNet_FeedBack_Loop_Network_for_Driver_Attention_Prediction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02096-b31b1b.svg)](https://arxiv.org/abs/2212.02096) | :heavy_minus_sign: |
| Deep Feature Deblurring Diffusion for Detecting Out-of-Distribution Objects | [![GitHub](https://img.shields.io/github/stars/AmingWu/DFDD-OOD?style=flat)](https://github.com/AmingWu/DFDD-OOD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Deep_Feature_Deblurring_Diffusion_for_Detecting_Out-of-Distribution_Objects_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
