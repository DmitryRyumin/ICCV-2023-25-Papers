# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/recognition-retrieval.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/low-level-and-physics-based-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Transfer, Low-Shot, Continual, Long-Tail Learning

![Section Papers](https://img.shields.io/badge/Section%20Papers-110-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-78-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-72-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-7-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| ImbSAM: A Closer Look at Sharpness-Aware Minimization in Class-Imbalanced Recognition | [![GitHub](https://img.shields.io/github/stars/cool-xuan/Imbalanced_SAM?style=flat)](https://github.com/cool-xuan/Imbalanced_SAM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ImbSAM_A_Closer_Look_at_Sharpness-Aware_Minimization_in_Class-Imbalanced_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07815-b31b1b.svg)](https://arxiv.org/abs/2308.07815) | :heavy_minus_sign: |
| LFS-GAN: Lifelong Few-Shot Image Generation | [![GitHub](https://img.shields.io/github/stars/JJuOn/LFS-GAN?style=flat)](https://github.com/JJuOn/LFS-GAN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11917-b31b1b.svg)](https://arxiv.org/abs/2308.11917) | :heavy_minus_sign: |
| Augmented Box Replay: Overcoming Foreground Shift for Incremental Object Detection | [![GitHub](https://img.shields.io/github/stars/YuyangSunshine/ABR_IOD?style=flat)](https://github.com/YuyangSunshine/ABR_IOD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Augmented_Box_Replay_Overcoming_Foreground_Shift_for_Incremental_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12427-b31b1b.svg)](https://arxiv.org/abs/2307.12427) | :heavy_minus_sign: |
| Contrastive Model Adaptation for Cross-Condition Robustness in Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/brdav/cma?style=flat)](https://github.com/brdav/cma) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bruggemann_Contrastive_Model_Adaptation_for_Cross-Condition_Robustness_in_Semantic_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05194-b31b1b.svg)](https://arxiv.org/abs/2303.05194) | :heavy_minus_sign: |
| Towards Effective Instance Discrimination Contrastive Loss for Unsupervised Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/zhyx12/EIDCo?style=flat)](https://github.com/zhyx12/EIDCo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Effective_Instance_Discrimination_Contrastive_Loss_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2202.02802-b31b1b.svg)](https://arxiv.org/abs/2202.02802) | :heavy_minus_sign: |
| Adversarial Bayesian Augmentation for Single-Source Domain Generalization | [![GitHub](https://img.shields.io/github/stars/shengcheng/ABA?style=flat)](https://github.com/shengcheng/ABA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Adversarial_Bayesian_Augmentation_for_Single-Source_Domain_Generalization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09520-b31b1b.svg)](https://arxiv.org/abs/2307.09520) | :heavy_minus_sign: |
| Measuring Asymmetric Gradient Discrepancy in Parallel Continual Learning | [![GitHub](https://img.shields.io/github/stars/fanlyu/maxdo?style=flat)](https://github.com/fanlyu/maxdo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| CSDA: Learning Category-Scale Joint Feature for Domain Adaptive Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_CSDA_Learning_Category-Scale_Joint_Feature_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Distilling from Similar Tasks for Transfer Learning on a Budget | [![GitHub](https://img.shields.io/github/stars/Kennethborup/DistillWeighted?style=flat)](https://github.com/Kennethborup/DistillWeighted) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Borup_Distilling_from_Similar_Tasks_for_Transfer_Learning_on_a_Budget_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.12314-b31b1b.svg)](https://arxiv.org/abs/2304.12314) | :heavy_minus_sign: |
| Complementary Domain Adaptation and Generalization for Unsupervised Continual Domain Shift Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Complementary_Domain_Adaptation_and_Generalization_for_Unsupervised_Continual_Domain_Shift_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15833-b31b1b.svg)](https://arxiv.org/abs/2303.15833) | :heavy_minus_sign: |
| Camera-Driven Representation Learning for Unsupervised Domain Adaptive Person Re-Identification | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cvlab.yonsei.ac.kr/projects/CaCL/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Camera-Driven_Representation_Learning_for_Unsupervised_Domain_Adaptive_Person_Re-identification_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11901-b31b1b.svg)](https://arxiv.org/abs/2308.11901) | :heavy_minus_sign: |
| Introducing Language Guidance in Prompt-based Continual Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_Introducing_Language_Guidance_in_Prompt-based_Continual_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.15827-b31b1b.svg)](https://arxiv.org/abs/2308.15827) | :heavy_minus_sign: |
| Fast and Accurate Transferability Measurement by Evaluating Intra-Class Feature Variance | [![GitHub](https://img.shields.io/github/stars/snudatalab/TMI?style=flat)](https://github.com/snudatalab/TMI) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Fast_and_Accurate_Transferability_Measurement_by_Evaluating_Intra-class_Feature_Variance_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.05986-b31b1b.svg)](https://arxiv.org/abs/2308.05986) | :heavy_minus_sign: |
| A Unified Continual Learning Framework with General Parameter-Efficient Tuning | [![GitHub](https://img.shields.io/github/stars/gqk/LAE?style=flat)](https://github.com/gqk/LAE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_A_Unified_Continual_Learning_Framework_with_General_Parameter-Efficient_Tuning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10070-b31b1b.svg)](https://arxiv.org/abs/2303.10070) | :heavy_minus_sign: |
| SFHarmony: Source Free Domain Adaptation for Distributed Neuroimaging Analysis | [![GitHub](https://img.shields.io/github/stars/nkdinsdale/SFHarmony?style=flat)](https://github.com/nkdinsdale/SFHarmony) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dinsdale_SFHarmony_Source_Free_Domain_Adaptation_for_Distributed_Neuroimaging_Analysis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15965-b31b1b.svg)](https://arxiv.org/abs/2303.15965) | :heavy_minus_sign: |
| Towards Realistic Evaluation of Industrial Continual Learning Scenarios with an Emphasis on Energy Consumption and Computational Footprint | [![GitHub](https://img.shields.io/github/stars/Vivek9Chavan/RECIL?style=flat)](https://github.com/Vivek9Chavan/RECIL) <br /> [![InVar](https://img.shields.io/badge/InVar-dataset-20BEFF.svg)](https://fordatis.fraunhofer.de/handle/fordatis/329.2) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chavan_Towards_Realistic_Evaluation_of_Industrial_Continual_Learning_Scenarios_with_an_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TsWfYqz8qbk) |
| CDAC: Cross-Domain Attention Consistency in Transformer for Domain Adaptive Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/wangkaihong/CDAC?style=flat)](https://github.com/wangkaihong/CDAC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CDAC_Cross-domain_Attention_Consistency_in_Transformer_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14703-b31b1b.svg)](https://arxiv.org/abs/2211.14703) | :heavy_minus_sign: |
| PC-Adapter: Topology-Aware Adapter for Efficient Domain Adaption on Point Clouds with Rectified Pseudo-Label | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_PC-Adapter_Topology-Aware_Adapter_for_Efficient_Domain_Adaption_on_Point_Clouds_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.16936-b31b1b.svg)](https://arxiv.org/abs/2309.16936) | :heavy_minus_sign: |
| DETA: Denoised Task Adaptation for Few-Shot Learning | [![GitHub](https://img.shields.io/github/stars/JimZAI/DETA?style=flat)](https://github.com/JimZAI/DETA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06315-b31b1b.svg)](https://arxiv.org/abs/2303.06315) | :heavy_minus_sign: |
| Activate and Reject: Towards Safe Domain Generalization under Category Shift | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Activate_and_Reject_Towards_Safe_Domain_Generalization_under_Category_Shift_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Generalizable Decision Boundaries: Dualistic Meta-Learning for Open Set Domain Generalization | [![GitHub](https://img.shields.io/github/stars/zzwdx/MEDIC?style=flat)](https://github.com/zzwdx/MEDIC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Generalizable_Decision_Boundaries_Dualistic_Meta-Learning_for_Open_Set_Domain_Generalization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09391-b31b1b.svg)](https://arxiv.org/abs/2308.09391) | :heavy_minus_sign: |
| Continual Zero-Shot Learning through Semantically Guided Generative Random Walks | [![GitHub](https://img.shields.io/github/stars/wx-zhang/IGCZSL?style=flat)](https://github.com/wx-zhang/IGCZSL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Continual_Zero-Shot_Learning_through_Semantically_Guided_Generative_Random_Walks_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12366-b31b1b.svg)](https://arxiv.org/abs/2308.12366) | :heavy_minus_sign: |
| Zero-Shot Point Cloud Segmentation by Semantic-Visual Aware Synthesis | [![GitHub](https://img.shields.io/github/stars/leolyj/3DPC-GZSL?style=flat)](https://github.com/leolyj/3DPC-GZSL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Point_Cloud_Segmentation_by_Semantic-Visual_Aware_Synthesis_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| MDCS: More Diverse Experts with Consistency Self-Distillation for Long-Tailed Recognition | [![GitHub](https://img.shields.io/github/stars/fistyee/MDCS?style=flat)](https://github.com/fistyee/MDCS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MDCS_More_Diverse_Experts_with_Consistency_Self-distillation_for_Long-tailed_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09922-b31b1b.svg)](https://arxiv.org/abs/2308.09922) | :heavy_minus_sign: |
| Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02429-b31b1b.svg)](https://arxiv.org/abs/2309.02429) | :heavy_minus_sign: |
| Confidence-based Visual Dispersal for Few-Shot Unsupervised Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/Bostoncake/C-VisDiT?style=flat)](https://github.com/Bostoncake/C-VisDiT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.15575-b31b1b.svg)](https://arxiv.org/abs/2309.15575) | :heavy_minus_sign: |
| BEV-DG: Cross-Modal Learning under Bird's-Eye View for Domain Generalization of 3D Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_BEV-DG_Cross-Modal_Learning_under_Birds-Eye_View_for_Domain_Generalization_of_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06530-b31b1b.svg)](https://arxiv.org/abs/2308.06530) | :heavy_minus_sign: |
| CDFSL-V: Cross-Domain Few-Shot Learning for Videos | [![GitHub](https://img.shields.io/github/stars/Sarinda251/CDFSL-V?style=flat)](https://github.com/Sarinda251/CDFSL-V) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Samarasinghe_CDFSL-V_Cross-Domain_Few-Shot_Learning_for_Videos_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03989-b31b1b.svg)](https://arxiv.org/abs/2309.03989) | :heavy_minus_sign: |
| Energy-based Self-Training and Normalization for Unsupervised Domain Adaptation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Herath_Energy-based_Self-Training_and_Normalization_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Regularized Mask Tuning: Uncovering Hidden Knowledge in Pre-Trained Vision-Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wuw2019.github.io/R-AMT/) <br /> [![GitHub](https://img.shields.io/github/stars/wuw2019/R-AMT?style=flat)](https://github.com/wuw2019/R-AMT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Regularized_Mask_Tuning_Uncovering_Hidden_Knowledge_in_Pre-Trained_Vision-Language_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15049-b31b1b.svg)](https://arxiv.org/abs/2307.15049) | :heavy_minus_sign: |
| NAPA-VQ: Neighborhood-Aware Prototype Augmentation with Vector Quantization for Continual Learning | [![GitHub](https://img.shields.io/github/stars/TamashaM/NAPA-VQ?style=flat)](https://github.com/TamashaM/NAPA-VQ) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Malepathirana_NAPA-VQ_Neighborhood-Aware_Prototype_Augmentation_with_Vector_Quantization_for_Continual_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09297-b31b1b.svg)](https://arxiv.org/abs/2308.09297) | :heavy_minus_sign: |
| A Sentence Speaks a Thousand Images: Domain Generalization through Distilling CLIP with Language Guidance | [![GitHub](https://img.shields.io/github/stars/OoDBag/RISE?style=flat)](https://github.com/OoDBag/RISE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_A_Sentence_Speaks_a_Thousand_Images_Domain_Generalization_through_Distilling_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.12530-b31b1b.svg)](https://arxiv.org/abs/2309.12530) | :heavy_minus_sign: |
| ViM: Vision Middleware for Unified Downstream Transferring | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_ViM_Vision_Middleware_for_Unified_Downstream_Transferring_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06911-b31b1b.svg)](https://arxiv.org/abs/2303.06911) | :heavy_minus_sign: |
| Learning to Learn: How to Continuously Teach Humans and Machines | [![GitHub](https://img.shields.io/github/stars/ZhangLab-DeepNeuroCogLab/Learning2Learn?style=flat)](https://github.com/ZhangLab-DeepNeuroCogLab/Learning2Learn) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Learning_to_Learn_How_to_Continuously_Teach_Humans_and_Machines_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.15470-b31b1b.svg)](https://arxiv.org/abs/2211.15470) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xz1TSRAQCN4) |
| A Good Student is Cooperative and Reliable: CNN-Transformer Collaborative Learning for Semantic Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vlislab22.github.io/CTCL/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_A_Good_Student_is_Cooperative_and_Reliable_CNN-Transformer_Collaborative_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12574-b31b1b.svg)](https://arxiv.org/abs/2307.12574) | :heavy_minus_sign: |
| Online Class Incremental Learning on Stochastic Blurry Task Boundary via Mask and Visual Prompt Tuning | [![GitHub](https://img.shields.io/github/stars/moonjunyyy/Si-Blurry?style=flat)](https://github.com/moonjunyyy/Si-Blurry) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_Online_Class_Incremental_Learning_on_Stochastic_Blurry_Task_Boundary_via_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09303-b31b1b.svg)](https://arxiv.org/abs/2308.09303) | :heavy_minus_sign: |
| Heterogeneous Forgetting Compensation for Class-Incremental Learning | [![GitHub](https://img.shields.io/github/stars/JiahuaDong/HFC?style=flat)](https://github.com/JiahuaDong/HFC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Heterogeneous_Forgetting_Compensation_for_Class-Incremental_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03374-b31b1b.svg)](https://arxiv.org/abs/2308.03374) | :heavy_minus_sign: |
| Disposable Transfer Learning for Selective Source Task Unlearning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Koh_Disposable_Transfer_Learning_for_Selective_Source_Task_Unlearning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09971-b31b1b.svg)](https://arxiv.org/abs/2308.09971) | :heavy_minus_sign: |
| Online Continual Learning on Hierarchical Label Expansion | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Online_Continual_Learning_on_Hierarchical_Label_Expansion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14374-b31b1b.svg)](https://arxiv.org/abs/2308.14374) | :heavy_minus_sign: |
| Black-Box Unsupervised Domain Adaptation with Bi-Directional Atkinson-Shiffrin Memory | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13236-b31b1b.svg)](https://arxiv.org/abs/2308.13236) | :heavy_minus_sign: |
| Local and Global Logit Adjustments for Long-Tailed Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_Local_and_Global_Logit_Adjustments_for_Long-Tailed_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| FS-DETR: Few-Shot DEtection TRansformer with Prompting and without Re-Training | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.04845-b31b1b.svg)](https://arxiv.org/abs/2210.04845) | :heavy_minus_sign: |
| Tuning Pre-Trained Model via Moment Probing | [![GitHub](https://img.shields.io/github/stars/mingzeG/Moment-Probing?style=flat)](https://github.com/mingzeG/Moment-Probing) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Tuning_Pre-trained_Model_via_Moment_Probing_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11342-b31b1b.svg)](https://arxiv.org/abs/2307.11342) | :heavy_minus_sign: |
| Benchmarking Low-Shot Robustness to Natural Distribution Shifts | [![GitHub](https://img.shields.io/github/stars/Aaditya-Singh/Low-Shot-Robustness?style=flat)](https://github.com/Aaditya-Singh/Low-Shot-Robustness) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Benchmarking_Low-Shot_Robustness_to_Natural_Distribution_Shifts_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11263-b31b1b.svg)](https://arxiv.org/abs/2304.11263) | :heavy_minus_sign: |
| Label-Guided Knowledge Distillation for Continual Semantic Segmentation on 2D Images and 3D Point Clouds | [![GitHub](https://img.shields.io/github/stars/Ze-Yang/LGKD?style=flat)](https://github.com/Ze-Yang/LGKD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Label-Guided_Knowledge_Distillation_for_Continual_Semantic_Segmentation_on_2D_Images_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| ETran: Energy-based Transferability Estimation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gholami_ETran_Energy-Based_Transferability_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.02027-b31b1b.svg)](https://arxiv.org/abs/2308.02027) | :heavy_minus_sign: |
| PÃ˜DA: Prompt-Driven Zero-Shot Domain Adaptation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://astra-vision.github.io/PODA/) <br /> [![GitHub](https://img.shields.io/github/stars/astra-vision/PODA?style=flat)](https://github.com/astra-vision/PODA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.03241-b31b1b.svg)](https://arxiv.org/abs/2212.03241) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kataxQoPuSE) |
| Local Context-Aware Active Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/tsun/LADA?style=flat)](https://github.com/tsun/LADA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Local_Context-Aware_Active_Domain_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.12856-b31b1b.svg)](https://arxiv.org/abs/2208.12856) | :heavy_minus_sign: |
| MRN: Multiplexed Routing Network for Incremental Multilingual Text Recognition | [![GitHub](https://img.shields.io/github/stars/simplify23/MRN?style=flat)](https://github.com/simplify23/MRN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_MRN_Multiplexed_Routing_Network_for_Incremental_Multilingual_Text_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.14758-b31b1b.svg)](https://arxiv.org/abs/2305.14758) | :heavy_minus_sign: |
| Few-Shot Dataset Distillation via Translative Pre-Training | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Few-Shot_Dataset_Distillation_via_Translative_Pre-Training_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Wasserstein Expansible Variational Autoencoder for Discriminative and Generative Continual Learning | [![GitHub](https://img.shields.io/github/stars/dtuzi123/WEVAE?style=flat)](https://github.com/dtuzi123/WEVAE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Wasserstein_Expansible_Variational_Autoencoder_for_Discriminative_and_Generative_Continual_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Tangent Model Composition for Ensembling and Continual Fine-Tuning | [![GitHub](https://img.shields.io/github/stars/tianyu139/tangent-model-composition?style=flat)](https://github.com/tianyu139/tangent-model-composition) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Tangent_Model_Composition_for_Ensembling_and_Continual_Fine-tuning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08114-b31b1b.svg)](https://arxiv.org/abs/2307.08114) | :heavy_minus_sign: |
| Look at the Neighbor: Distortion-Aware Unsupervised Domain Adaptation for Panoramic Semantic Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vlislab22.github.io/DATR/) <br /> [![GitHub](https://img.shields.io/github/stars/zhengxuJosh/DATR?style=flat)](https://github.com/zhengxuJosh/DATR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Look_at_the_Neighbor_Distortion-aware_Unsupervised_Domain_Adaptation_for_Panoramic_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.05493-b31b1b.svg)](https://arxiv.org/abs/2308.05493) | :heavy_minus_sign: |
| Homeomorphism Alignment for Unsupervised Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/buerzlh/HMA?style=flat)](https://github.com/buerzlh/HMA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Homeomorphism_Alignment_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Knowledge Restore and Transfer for Multi-Label Class-Incremental Learning | [![GitHub](https://img.shields.io/github/stars/witdsl/KRT-MLCIL?style=flat)](https://github.com/witdsl/KRT-MLCIL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Knowledge_Restore_and_Transfer_for_Multi-Label_Class-Incremental_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.13334-b31b1b.svg)](https://arxiv.org/abs/2302.13334) | :heavy_minus_sign: |
| Unsupervised Domain Adaptation for Training Event-based Networks using Contrastive Learning and Uncorrelated Conditioning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_Unsupervised_Domain_Adaptation_for_Training_Event-Based_Networks_Using_Contrastive_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12424-b31b1b.svg)](https://arxiv.org/abs/2303.12424) | :heavy_minus_sign: |
| A Simple Recipe to Meta-Learn Forward and Backward Transfer | [![GitHub](https://img.shields.io/github/stars/Aladoro/SimpleMetaLearner4ContinualLearning?style=flat)](https://github.com/Aladoro/SimpleMetaLearner4ContinualLearning) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cetin_A_Simple_Recipe_to_Meta-Learn_Forward_and_Backward_Transfer_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Dynamic Residual Classifier for Class Incremental Learning | [![GitHub](https://img.shields.io/github/stars/chen-xw/DRC-CIL?style=flat)](https://github.com/chen-xw/DRC-CIL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dynamic_Residual_Classifier_for_Class_Incremental_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13305-b31b1b.svg)](https://arxiv.org/abs/2308.13305) | :heavy_minus_sign: |
| Concept-Wise Fine-Tuning Matters in Preventing Negative Transfer | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Concept-wise_Fine-tuning_Matters_in_Preventing_Negative_Transfer_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Online Prototype Learning for Online Continual Learning | [![GitHub](https://img.shields.io/github/stars/weilllllls/OnPro?style=flat)](https://github.com/weilllllls/OnPro) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Online_Prototype_Learning_for_Online_Continual_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.00301-b31b1b.svg)](https://arxiv.org/abs/2308.00301) | :heavy_minus_sign: |
| Bidirectional Alignment for Domain Adaptive Detection with Transformers | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Bidirectional_Alignment_for_Domain_Adaptive_Detection_with_Transformers_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Borrowing Knowledge from Pre-Trained Language Model: A New Data-Efficient Visual Learning Paradigm | [![GitHub](https://img.shields.io/github/stars/BIT-DA/BorLan?style=flat)](https://github.com/BIT-DA/BorLan) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Borrowing_Knowledge_From_Pre-trained_Language_Model_A_New_Data-efficient_Visual_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| CLR: Channel-Wise Lightweight Reprogramming for Continual Learning | [![GitHub](https://img.shields.io/github/stars/gyhandy/Channel-wise-Lightweight-Reprogramming?style=flat)](https://github.com/gyhandy/Channel-wise-Lightweight-Reprogramming) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_CLR_Channel-wise_Lightweight_Reprogramming_for_Continual_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11386-b31b1b.svg)](https://arxiv.org/abs/2307.11386) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hmOtuNC1ANU) |
| Multi-Modal Continual Test-Time Adaptation for 3D Semantic Segmentation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/mmcotta) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Continual_Test-Time_Adaptation_for_3D_Semantic_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10457-b31b1b.svg)](https://arxiv.org/abs/2303.10457) | :heavy_minus_sign: |
| First Session Adaptation: A Strong Replay-Free Baseline for Class-Incremental Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Panos_First_Session_Adaptation_A_Strong_Replay-Free_Baseline_for_Class-Incremental_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13199-b31b1b.svg)](https://arxiv.org/abs/2303.13199) | :heavy_minus_sign: |
| Domain Adaptive Few-Shot Open-Set Learning | [![GitHub](https://img.shields.io/github/stars/DebabrataPal7/DAFOSNET?style=flat)](https://github.com/DebabrataPal7/DAFOSNET) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pal_Domain_Adaptive_Few-Shot_Open-Set_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.12814-b31b1b.svg)](https://arxiv.org/abs/2309.12814) | :heavy_minus_sign: |
| Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Rethinking_the_Role_of_Pre-Trained_Networks_in_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07585-b31b1b.svg)](https://arxiv.org/abs/2212.07585) | :heavy_minus_sign: |
| Rapid Adaptation in Online Continual Learning: Are we Evaluating it Right? | [![GitHub](https://img.shields.io/github/stars/drimpossible/EvalOCL?style=flat)](https://github.com/drimpossible/EvalOCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Al_Kader_Hammoud_Rapid_Adaptation_in_Online_Continual_Learning_Are_We_Evaluating_It_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.09275-b31b1b.svg)](https://arxiv.org/abs/2305.09275) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=H8Cyh-7xltg) |
| Multi-Grained Temporal Prototype Learning for Few-Shot Video Object Segmentation | [![GitHub](https://img.shields.io/github/stars/nankepan/VIPMT?style=flat)](https://github.com/nankepan/VIPMT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-grained_Temporal_Prototype_Learning_for_Few-shot_Video_Object_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.11160-b31b1b.svg)](https://arxiv.org/abs/2309.11160) | :heavy_minus_sign: |
| A Low-Shot Object Counting Network with Iterative Prototype Adaptation | [![GitHub](https://img.shields.io/github/stars/djukicn/loca?style=flat)](https://github.com/djukicn/loca) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dukic_A_Low-Shot_Object_Counting_Network_With_Iterative_Prototype_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.08217-b31b1b.svg)](https://arxiv.org/abs/2211.08217) | :heavy_minus_sign: |
| Towards Better Robustness against Common Corruptions for Unsupervised Domain Adaptation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Towards_Better_Robustness_against_Common_Corruptions_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Alleviating Catastrophic Forgetting of Incremental Object Detection via Within-Class and Between-Class Knowledge Distillation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Alleviating_Catastrophic_Forgetting_of_Incremental_Object_Detection_via_Within-Class_and_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Class-Aware Patch Embedding Adaptation for Few-Shot Image Classification | [![GitHub](https://img.shields.io/github/stars/FushengHao/CPEA?style=flat)](https://github.com/FushengHao/CPEA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Order-Preserving Consistency Regularization for Domain Adaptation and Generalization | [![GitHub](https://img.shields.io/github/stars/TL-UESTC/OCR_MindSpore?style=flat)](https://github.com/TL-UESTC/OCR_MindSpore) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jing_Order-preserving_Consistency_Regularization_for_Domain_Adaptation_and_Generalization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13258-b31b1b.svg)](https://arxiv.org/abs/2309.13258) | :heavy_minus_sign: |
| Domain-Specificity Inducing Transformers for Source-Free Domain Adaptation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://val.cds.iisc.ac.in/DSiT-SFDA/) <br /> [![GitHub](https://img.shields.io/github/stars/val-iisc/DSiT-SFDA?style=flat)](https://github.com/val-iisc/DSiT-SFDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sanyal_Domain-Specificity_Inducing_Transformers_for_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14023-b31b1b.svg)](https://arxiv.org/abs/2308.14023) | :heavy_minus_sign: |
| Diffusion Model as Representation Learner | [![GitHub](https://img.shields.io/github/stars/Adamdad/Repfusion?style=flat)](https://github.com/Adamdad/Repfusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Diffusion_Model_as_Representation_Learner_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10916-b31b1b.svg)](https://arxiv.org/abs/2308.10916) | :heavy_minus_sign: |
| Ïƒ-Adaptive Decoupled Prototype for Few-Shot Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Du_s-Adaptive_Decoupled_Prototype_for_Few-Shot_Object_Detection_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Growing a Brain with Sparsity-Inducing Generation for Continual Learning | [![GitHub](https://img.shields.io/github/stars/Jin0316/GrowBrain?style=flat)](https://github.com/Jin0316/GrowBrain) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Growing_a_Brain_with_Sparsity-Inducing_Generation_for_Continual_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| DomainAdaptor: A Novel Approach to Test-Time Adaptation | [![GitHub](https://img.shields.io/github/stars/koncle/DomainAdaptor?style=flat)](https://github.com/koncle/DomainAdaptor) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DomainAdaptor_A_Novel_Approach_to_Test-time_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10297-b31b1b.svg)](https://arxiv.org/abs/2308.10297) | :heavy_minus_sign: |
| Reconciling Object-Level and Global-Level Objectives for Long-Tail Detection | [![GitHub](https://img.shields.io/github/stars/EricZsy/ROG?style=flat)](https://github.com/EricZsy/ROG) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Reconciling_Object-Level_and_Global-Level_Objectives_for_Long-Tail_Detection_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Domain Generalization via Balancing Training Difficulty and Model Capability | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.00844-b31b1b.svg)](https://arxiv.org/abs/2309.00844) | :heavy_minus_sign: |
| Understanding Hessian Alignment for Domain Generalization | [![GitHub](https://img.shields.io/github/stars/huawei-noah/Federated-Learning?style=flat)](https://github.com/huawei-noah/Federated-Learning) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hemati_Understanding_Hessian_Alignment_for_Domain_Generalization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11778-b31b1b.svg)](https://arxiv.org/abs/2308.11778) | :heavy_minus_sign: |
| Vision Transformer Adapters for Generalizable Multitask Learning | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ivrl.github.io/VTAGML/) <br /> [![GitHub](https://img.shields.io/github/stars/IVRL/VTAGML?style=flat)](https://github.com/IVRL/VTAGML) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bhattacharjee_Vision_Transformer_Adapters_for_Generalizable_Multitask_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12372-b31b1b.svg)](https://arxiv.org/abs/2308.12372) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MED5nbn9ACM) |
| Focus on Your Target: A Dual Teacher-Student Framework for Domain-Adaptive Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/xinyuehuo/DTS?style=flat)](https://github.com/xinyuehuo/DTS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huo_Focus_on_Your_Target_A_Dual_Teacher-Student_Framework_for_Domain-Adaptive_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09083-b31b1b.svg)](https://arxiv.org/abs/2303.09083) | :heavy_minus_sign: |
| Masked Retraining Teacher-Student Framework for Domain Adaptive Object Detection | [![GitHub](https://img.shields.io/github/stars/JeremyZhao1998/MRT-release?style=flat)](https://github.com/JeremyZhao1998/MRT-release) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Masked_Retraining_Teacher-Student_Framework_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GGhBn6akViU) |
| DandelionNet: Domain Composition with Instance Adaptive Classification for Domain Generalization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DandelionNet_Domain_Composition_with_Instance_Adaptive_Classification_for_Domain_Generalization_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| CAFA: Class-Aware Feature Alignment for Test-Time Adaptation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jung_CAFA_Class-Aware_Feature_Alignment_for_Test-Time_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.00205-b31b1b.svg)](https://arxiv.org/abs/2206.00205) | :heavy_minus_sign: |
| Image-Free Classifier Injection for Zero-Shot Classification | [![GitHub](https://img.shields.io/github/stars/ExplainableML/ImageFreeZSL?style=flat)](https://github.com/ExplainableML/ImageFreeZSL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Christensen_Image-Free_Classifier_Injection_for_Zero-Shot_Classification_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10599-b31b1b.svg)](https://arxiv.org/abs/2308.10599) | :heavy_minus_sign: |
| CBA: Improving Online Continual Learning via Continual Bias Adaptor | [![GitHub](https://img.shields.io/github/stars/wqza/CBA-online-CL?style=flat)](https://github.com/wqza/CBA-online-CL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CBA_Improving_Online_Continual_Learning_via_Continual_Bias_Adaptor_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06925-b31b1b.svg)](https://arxiv.org/abs/2308.06925) | :heavy_minus_sign: |
| Masked Autoencoders are Efficient Class Incremental Learners | [![GitHub](https://img.shields.io/github/stars/scok30/MAE-CIL?style=flat)](https://github.com/scok30/MAE-CIL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Masked_Autoencoders_are_Efficient_Class_Incremental_Learners_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12510-b31b1b.svg)](https://arxiv.org/abs/2308.12510) | :heavy_minus_sign: |
| DomainDrop: Suppressing Domain-Sensitive Channels for Domain Generalization | [![GitHub](https://img.shields.io/github/stars/lingeringlight/DomainDrop?style=flat)](https://github.com/lingeringlight/DomainDrop) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_DomainDrop_Suppressing_Domain-Sensitive_Channels_for_Domain_Generalization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10285-b31b1b.svg)](https://arxiv.org/abs/2308.10285) | :heavy_minus_sign: |
| Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models | [![GitHub](https://img.shields.io/github/stars/Thunderbeee/ZSCL?style=flat)](https://github.com/Thunderbeee/ZSCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Preventing_Zero-Shot_Transfer_Degradation_in_Continual_Learning_of_Vision-Language_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06628-b31b1b.svg)](https://arxiv.org/abs/2303.06628) | :heavy_minus_sign: |
| Incremental Generalized Category Discovery | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://bzhao.me/iNatIGCD/) <br /> [![GitHub](https://img.shields.io/github/stars/DTennant/Incremental-Generalized-Category-Discovery?style=flat)](https://github.com/DTennant/Incremental-Generalized-Category-Discovery) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Incremental_Generalized_Category_Discovery_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14310-b31b1b.svg)](https://arxiv.org/abs/2304.14310) | :heavy_minus_sign: |
| SLCA: Slow Learner with Classifier Alignment for Continual Learning on a Pre-Trained Model | [![GitHub](https://img.shields.io/github/stars/GengDavid/SLCA?style=flat)](https://github.com/GengDavid/SLCA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SLCA_Slow_Learner_with_Classifier_Alignment_for_Continual_Learning_on_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05118-b31b1b.svg)](https://arxiv.org/abs/2303.05118) | :heavy_minus_sign: |
| Efficient Model Personalization in Federated Learning via Client-Specific Prompt Generation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Efficient_Model_Personalization_in_Federated_Learning_via_Client-Specific_Prompt_Generation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.15367-b31b1b.svg)](https://arxiv.org/abs/2308.15367) | :heavy_minus_sign: |
| iDAG: Invariant DAG Searching for Domain Generalization | [![GitHub](https://img.shields.io/github/stars/lccurious/iDAG?style=flat)](https://github.com/lccurious/iDAG) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_iDAG_Invariant_DAG_Searching_for_Domain_Generalization_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| SSDA: Secure Source-Free Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/ML-Security-Research-LAB/SSDA?style=flat)](https://github.com/ML-Security-Research-LAB/SSDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ahmed_SSDA_Secure_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Learning Pseudo-Relations for Cross-Domain Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/DZhaoXd/RTea?style=flat)](https://github.com/DZhaoXd/RTea) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Pseudo-Relations_for_Cross-domain_Semantic_Segmentation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Self-Organizing Pathway Expansion for Non-Exemplar Class-Incremental Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Self-Organizing_Pathway_Expansion_for_Non-Exemplar_Class-Incremental_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Improved Knowledge Transfer for Semi-Supervised Domain Adaptation via Trico Training Strategy | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ngo_Improved_Knowledge_Transfer_for_Semi-Supervised_Domain_Adaptation_via_Trico_Training_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Few-Shot Continual Infomax Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Few-shot_Continual_Infomax_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| EDAPS: Enhanced Domain-Adaptive Panoptic Segmentation | [![GitHub](https://img.shields.io/github/stars/susaha/edaps?style=flat)](https://github.com/susaha/edaps) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Saha_EDAPS_Enhanced_Domain-Adaptive_Panoptic_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14291-b31b1b.svg)](https://arxiv.org/abs/2304.14291) | :heavy_minus_sign: |
| Label-Efficient Online Continual Object Detection in Streaming Video | [![GitHub](https://img.shields.io/github/stars/showlab/Efficient-CLS?style=flat)](https://github.com/showlab/Efficient-CLS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Label-Efficient_Online_Continual_Object_Detection_in_Streaming_Video_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.00309-b31b1b.svg)](https://arxiv.org/abs/2206.00309) | :heavy_minus_sign: |
| Prototypical Kernel Learning and Open-Set Foreground Perception for Generalized Few-Shot Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04952-b31b1b.svg)](https://arxiv.org/abs/2308.04952) | :heavy_minus_sign: |
| MSI: Maximize Support-Set Information for Few-Shot Segmentation | [![GitHub](https://img.shields.io/github/stars/moonsh/MSI-Maximize-Support-Set-Information-ICCV2023?style=flat)](https://github.com/moonsh/MSI-Maximize-Support-Set-Information-ICCV2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_MSI_Maximize_Support-Set_Information_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04673-b31b1b.svg)](https://arxiv.org/abs/2212.04673) | :heavy_minus_sign: |
| AREA: Adaptive Reweighting via Effective Area for Long-Tailed Classification | [![GitHub](https://img.shields.io/github/stars/xiaohua-chen/AREA?style=flat)](https://github.com/xiaohua-chen/AREA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AREA_Adaptive_Reweighting_via_Effective_Area_for_Long-Tailed_Classification_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| PASTA: Proportional Amplitude Spectrum Training Augmentation for Syn-to-Real Domain Generalization | [![GitHub](https://img.shields.io/github/stars/prithv1/PASTA?style=flat)](https://github.com/prithv1/PASTA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chattopadhyay_PASTA_Proportional_Amplitude_Spectrum_Training_Augmentation_for_Syn-to-Real_Domain_Generalization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00979-b31b1b.svg)](https://arxiv.org/abs/2212.00979) | :heavy_minus_sign: |
| Personalized Semantics Excitation for Federated Image Classification | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Personalized_Semantics_Excitation_for_Federated_Image_Classification_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Few-Shot Video Classification via Representation Fusion and Promotion Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Few-Shot_Video_Classification_via_Representation_Fusion_and_Promotion_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Segmenting known Objects and Unseen Unknowns without Prior Knowledge | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://holisticseg.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gasperini_Segmenting_Known_Objects_and_Unseen_Unknowns_without_Prior_Knowledge_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.05407-b31b1b.svg)](https://arxiv.org/abs/2209.05407) | :heavy_minus_sign: |

<!-- | AdaptGuard: Defending Against Universal Attacks for Model Adaptation |  |  |  | -->