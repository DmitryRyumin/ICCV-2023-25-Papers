# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/navigation-and-autonomous-driving.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/motion-estimation-matching-and-tracking.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## 3D from a Single Image and Shape-from-X

![Section Papers](https://img.shields.io/badge/Section%20Papers-68-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-58-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-45-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-18-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Aggregating Feature Point Cloud for Depth Completion | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Aggregating_Feature_Point_Cloud_for_Depth_Completion_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Coordinate Transformer: Achieving Single-Stage Multi-Person Mesh Recovery from Videos | [![GitHub](https://img.shields.io/github/stars/Li-Hao-yuan/CoordFormer?style=flat)](https://github.com/Li-Hao-yuan/CoordFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Coordinate_Transformer_Achieving_Single-stage_Multi-person_Mesh_Recovery_from_Videos_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10334-b31b1b.svg)](https://arxiv.org/abs/2308.10334) | :heavy_minus_sign: |
| MAMo: Leveraging Memory and Attention for Monocular Video Depth Estimation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yasarla_MAMo_Leveraging_Memory_and_Attention_for_Monocular_Video_Depth_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.14336-b31b1b.svg)](https://arxiv.org/abs/2307.14336) | :heavy_minus_sign: |
| SlaBins: Fisheye Depth Estimation using Slanted Bins on Road Environments | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://syniez.github.io/SlaBins/) <br /> [![GitHub](https://img.shields.io/github/stars/Syniez/SlaBins?style=flat)](https://github.com/Syniez/SlaBins) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yasarla_MAMo_Leveraging_Memory_and_Attention_for_Monocular_Video_Depth_Estimation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Creative Birds: Self-Supervised Single-View 3D Style Transfer | [![GitHub](https://img.shields.io/github/stars/wrk226/creative_birds?style=flat)](https://github.com/wrk226/creative_birds) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Creative_Birds_Self-Supervised_Single-View_3D_Style_Transfer_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.14127-b31b1b.svg)](https://arxiv.org/abs/2307.14127) | :heavy_minus_sign: |
| Dynamic PlenOctree for Adaptive Sampling Refinement in Explicit NeRF | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vlislab22.github.io/DOT/) <br /> [![GitHub](https://img.shields.io/github/stars/hbai98/DOT?style=flat)](https://github.com/hbai98/DOT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Dynamic_PlenOctree_for_Adaptive_Sampling_Refinement_in_Explicit_NeRF_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15333-b31b1b.svg)](https://arxiv.org/abs/2307.15333) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=i9MnoFhH8Ec) |
| CORE: Co-Planarity Regularized Monocular Geometry Estimation with Weak Supervision | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CORE_Co-planarity_Regularized_Monocular_Geometry_Estimation_with_Weak_Supervision_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Relightify: Relightable 3D Faces from a Single Image via Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://foivospar.github.io/Relightify/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Papantoniou_Relightify_Relightable_3D_Faces_from_a_Single_Image_via_Diffusion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.06077-b31b1b.svg)](https://arxiv.org/abs/2305.06077) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=N5pSN4Pc0JM) |
| GLA-GCN: Global-Local Adaptive Graph Convolutional Network for 3D Human Pose Estimation from Monocular Video | [![GitHub](https://img.shields.io/github/stars/bruceyo/GLA-GCN?style=flat)](https://github.com/bruceyo/GLA-GCN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_GLA-GCN_Global-local_Adaptive_Graph_Convolutional_Network_for_3D_Human_Pose_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.05853-b31b1b.svg)](https://arxiv.org/abs/2307.05853) | :heavy_minus_sign: |
| Calibrating Panoramic Depth Estimation for Practical Localization and Mapping | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Calibrating_Panoramic_Depth_Estimation_for_Practical_Localization_and_Mapping_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14005-b31b1b.svg)](https://arxiv.org/abs/2308.14005) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KXz8IwrtJWg) |
| SimNP: Learning Self-Similarity Priors between Neural Points | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wewer_SimNP_Learning_Self-Similarity_Priors_Between_Neural_Points_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03809-b31b1b.svg)](https://arxiv.org/abs/2309.03809) | :heavy_minus_sign: |
| AGG-Net: Attention Guided Gated-Convolutional Network for Depth Image Completion | [![GitHub](https://img.shields.io/github/stars/htx0601/AGG-Net?style=flat)](https://github.com/htx0601/AGG-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.01624-b31b1b.svg)](https://arxiv.org/abs/2309.01624) | :heavy_minus_sign: |
| Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D Data | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://szymanowiczs.github.io/viewset-diffusion) <br /> [![GitHub](https://img.shields.io/github/stars/szymanowiczs/viewset-diffusion?style=flat)](https://github.com/szymanowiczs/viewset-diffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_3D_Generative_Models_from_2D_Data_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07881-b31b1b.svg)](https://arxiv.org/abs/2306.07881) | :heavy_minus_sign: |
| CVSformer: Cross-View Synthesis Transformer for Semantic Scene Completion | [![GitHub](https://img.shields.io/github/stars/donghaotian123/CVSformer?style=flat)](https://github.com/donghaotian123/CVSformer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_CVSformer_Cross-View_Synthesis_Transformer_for_Semantic_Scene_Completion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.07938-b31b1b.svg)](https://arxiv.org/abs/2307.07938) | :heavy_minus_sign: |
| U-RED: Unsupervised 3D Shape Retrieval and Deformation for Partial Point Clouds | [![GitHub](https://img.shields.io/github/stars/ZhangCYG/U-RED?style=flat)](https://github.com/ZhangCYG/U-RED) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Di_U-RED_Unsupervised_3D_Shape_Retrieval_and_Deformation_for_Partial_Point_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06383-b31b1b.svg)](https://arxiv.org/abs/2308.06383) | :heavy_minus_sign: |
| Single Depth-Image 3D Reflection Symmetry and Shape Prediction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Single_Depth-image_3D_Reflection_Symmetry_and_Shape_Prediction_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Self-Supervised Monocular Depth Estimation: Let's Talk About the Weather | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kieran514.github.io/Robust-Depth-Project/) <br /> [![GitHub](https://img.shields.io/github/stars/kieran514/robustdepth?style=flat)](https://github.com/kieran514/robustdepth) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Saunders_Self-supervised_Monocular_Depth_Estimation_Lets_Talk_About_The_Weather_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08357-b31b1b.svg)](https://arxiv.org/abs/2307.08357) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zGXzpJAWjcQ&t=3s) |
| Mesh2Tex: Generating Mesh Textures from Image Queries | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://alexeybokhovkin.github.io/mesh2tex/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bokhovkin_Mesh2Tex_Generating_Mesh_Textures_from_Image_Queries_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.05868-b31b1b.svg)](https://arxiv.org/abs/2304.05868) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tY6pPHN5v9Q) |
| Sketch and Text Guided Diffusion Model for Colored Point Cloud Generation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Sketch_and_Text_Guided_Diffusion_Model_for_Colored_Point_Cloud_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.02874-b31b1b.svg)](https://arxiv.org/abs/2308.02874) | :heavy_minus_sign: |
| Learning a Room with the Occ-SDF Hybrid: Signed Distance Function Mingled with Occupancy Aids Scene Representation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://shawlyu.github.io/Occ-SDF-Hybrid/) <br /> [![GitHub](https://img.shields.io/github/stars/shawLyu/Occ-SDF-Hybrid?style=flat)](https://github.com/shawLyu/Occ-SDF-Hybrid) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Learning_a_Room_with_the_Occ-SDF_Hybrid_Signed_Distance_Function_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09152-b31b1b.svg)](https://arxiv.org/abs/2303.09152) | :heavy_minus_sign: |
| Robust Geometry-Preserving Depth Estimation using Differentiable Rendering | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Geometry-Preserving_Depth_Estimation_Using_Differentiable_Rendering_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.09724-b31b1b.svg)](https://arxiv.org/abs/2309.09724) | :heavy_minus_sign: |
| FeatureNeRF: Learning Generalizable NeRFs by Distilling Foundation Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://jianglongye.com/featurenerf/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_FeatureNeRF_Learning_Generalizable_NeRFs_by_Distilling_Foundation_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12786-b31b1b.svg)](https://arxiv.org/abs/2303.12786) | :heavy_minus_sign: |
| One-Shot Implicit Animatable Avatars with Model-based Priors | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://huangyangyi.github.io/ELICIT/) <br /> [![GitHub](https://img.shields.io/github/stars/huangyangyi/ELICIT?style=flat)](https://github.com/huangyangyi/ELICIT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_One-shot_Implicit_Animatable_Avatars_with_Model-based_Priors_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02469-b31b1b.svg)](https://arxiv.org/abs/2212.02469) | :heavy_minus_sign: |
| VeRi3D: Generative Vertex-based Radiance Fields for 3D Controllable Human Image Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xdimlab.github.io/VeRi3d/) <br /> [![GitHub](https://img.shields.io/github/stars/XinyaChen21/Veri3d?style=flat)](https://github.com/XinyaChen21/Veri3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_VeRi3D_Generative_Vertex-based_Radiance_Fields_for_3D_Controllable_Human_Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.04800-b31b1b.svg)](https://arxiv.org/abs/2309.04800) | :heavy_minus_sign: |
| Diffuse3D: Wide-Angle 3D Photography via Bilateral Diffusion | [![GitHub](https://img.shields.io/github/stars/yutaojiang1/Diffuse3D?style=flat)](https://github.com/yutaojiang1/Diffuse3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Diffuse3D_Wide-Angle_3D_Photography_via_Bilateral_Diffusion_ICCV_2023_paper.pdf) <br /> [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://csyhquan.github.io/manuscript/23-iccv-Diffuse3D%20Wide-Angle%203D%20Photography%20via%20Bilateral%20Diffusion.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5mL6AMEvPSQ) |
| AutoSynth: Learning to Generate 3D Training Data for Object Point Cloud Registration | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dang_AutoSynth_Learning_to_Generate_3D_Training_Data_for_Object_Point_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.11170-b31b1b.svg)](https://arxiv.org/abs/2309.11170) | :heavy_minus_sign: |
| Body Knowledge and Uncertainty Modeling for Monocular 3D Human Body Reconstruction | [![GitHub](https://img.shields.io/github/stars/zhangy76/KNOWN?style=flat)](https://github.com/zhangy76/KNOWN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Body_Knowledge_and_Uncertainty_Modeling_for_Monocular_3D_Human_Body_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.00799-b31b1b.svg)](https://arxiv.org/abs/2308.00799) | :heavy_minus_sign: |
| Accurate 3D Face Reconstruction with Facial Component Tokens | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Accurate_3D_Face_Reconstruction_with_Facial_Component_Tokens_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Metric3D: Towards Zero-Shot Metric 3D Prediction from a Single Image | [![GitHub](https://img.shields.io/github/stars/YvanYin/Metric3D?style=flat)](https://github.com/YvanYin/Metric3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Metric3D_Towards_Zero-shot_Metric_3D_Prediction_from_A_Single_Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.10984-b31b1b.svg)](https://arxiv.org/abs/2307.10984) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=I3PkukQ3_F8) |
| Reconstructing Interacting Hands with Interaction Prior from Monocular Images | [![GitHub](https://img.shields.io/github/stars/binghui-z/InterPrior_pytorch?style=flat)](https://github.com/binghui-z/InterPrior_pytorch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zuo_Reconstructing_Interacting_Hands_with_Interaction_Prior_from_Monocular_Images_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14082-b31b1b.svg)](https://arxiv.org/abs/2308.14082) | :heavy_minus_sign: |
| SparseNeRF: Distilling Depth Ranking for Few-Shot Novel View Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sparsenerf.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/Wanggcong/SparseNeRF?style=flat)](https://github.com/Wanggcong/SparseNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SparseNeRF_Distilling_Depth_Ranking_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16196-b31b1b.svg)](https://arxiv.org/abs/2303.16196) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=V0yCTakA964) |
| Beyond the Limitation of Monocular 3D Detector via Knowledge Distillation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| HiFace: High-Fidelity 3D Face Reconstruction by Learning Static and Dynamic Details | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://project-hiface.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_HiFace_High-Fidelity_3D_Face_Reconstruction_by_Learning_Static_and_Dynamic_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11225-b31b1b.svg)](https://arxiv.org/abs/2303.11225) | :heavy_minus_sign: |
| Animal3D: A Comprehensive Dataset of 3D Animal Pose and Shape | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xujiacong.github.io/Animal3D/) <br /> [![GitHub](https://img.shields.io/github/stars/XuJiacong/Animal3D?style=flat)](https://github.com/XuJiacong/Animal3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Animal3D_A_Comprehensive_Dataset_of_3D_Animal_Pose_and_Shape_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11737-b31b1b.svg)](https://arxiv.org/abs/2308.11737) | :heavy_minus_sign: |
| JOTR: 3D Joint Contrastive Learning with Transformers for Occluded Human Mesh Recovery | [![GitHub](https://img.shields.io/github/stars/xljh0520/JOTR?style=flat)](https://github.com/xljh0520/JOTR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_JOTR_3D_Joint_Contrastive_Learning_with_Transformers_for_Occluded_Human_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.16377-b31b1b.svg)](https://arxiv.org/abs/2307.16377) | :heavy_minus_sign: |
| D-IF: Uncertainty-Aware Human Digitization via Implicit Distribution Field | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yxt7979.github.io/idf/) <br /> [![GitHub](https://img.shields.io/github/stars/psyai-net/D-IF_release?style=flat)](https://github.com/psyai-net/D-IF_release) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_D-IF_Uncertainty-aware_Human_Digitization_via_Implicit_Distribution_Field_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.08857-b31b1b.svg)](https://arxiv.org/abs/2308.08857) | :heavy_minus_sign: |
| 3D Distillation: Improving Self-Supervised Monocular Depth Estimation on Reflective Surfaces | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| DeformToon3D: Deformable Neural Radiance Fields for 3D Toonification | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.mmlab-ntu.com/project/deformtoon3d/) <br /> [![GitHub](https://img.shields.io/github/stars/junzhezhang/DeformToon3D?style=flat)](https://github.com/junzhezhang/DeformToon3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DeformToon3D_Deformable_Neural_Radiance_Fields_for_3D_Toonification_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.04410-b31b1b.svg)](https://arxiv.org/abs/2309.04410) | :heavy_minus_sign: |
| MonoDETR: Depth-Guided Transformer for Monocular 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/ZrrSkywalker/MonoDETR?style=flat)](https://github.com/ZrrSkywalker/MonoDETR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MonoDETR_Depth-guided_Transformer_for_Monocular_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2203.13310-b31b1b.svg)](https://arxiv.org/abs/2203.13310) | :heavy_minus_sign: |
| ReLeaPS: Reinforcement Learning-based Illumination Planning for Generalized Photometric Stereo | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jhchan0805.github.io/ReLeaPS/) <br /> [![GitHub](https://img.shields.io/github/stars/jhchan0805/ReLeaPS?style=flat)](https://github.com/jhchan0805/ReLeaPS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_ReLeaPS__Reinforcement_Learning-based_Illumination_Planning_for_Generalized_Photometric_Stereo_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5D4NBlf-L3w) |
| Convex Decomposition of Indoor Scenes | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Vavilala_Convex_Decomposition_of_Indoor_Scenes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.04246-b31b1b.svg)](https://arxiv.org/abs/2307.04246) | :heavy_minus_sign: |
| NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zubair-irshad.github.io/projects/neo360.html) <br /> [![GitHub](https://img.shields.io/github/stars/zubair-irshad/NeO-360?style=flat)](https://github.com/zubair-irshad/NeO-360) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Irshad_NeO_360_Neural_Fields_for_Sparse_View_Synthesis_of_Outdoor_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12967-b31b1b.svg)](https://arxiv.org/abs/2308.12967) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=avmylyL_V8c) |
| UrbanGIRAFFE: Representing Urban Scenes as Compositional Generative Neural Feature Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lv3d.github.io/urbanGIRAFFE/) <br /> [![GitHub](https://img.shields.io/github/stars/freemty/urbanGIRAFFE?style=flat)](https://github.com/freemty/urbanGIRAFFE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_UrbanGIRAFFE_Representing_Urban_Scenes_as_Compositional_Generative_Neural_Feature_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14167-b31b1b.svg)](https://arxiv.org/abs/2303.14167) | :heavy_minus_sign: |
| Efficient Converted Spiking Neural Network for 3D and 2D Classification | :heavy_minus_sign: |  [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lan_Efficient_Converted_Spiking_Neural_Network_for_3D_and_2D_Classification_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Distribution-Aligned Diffusion for Human Mesh Recovery | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gongjia0208.github.io/HMDiff/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Foo_Distribution-Aligned_Diffusion_for_Human_Mesh_Recovery_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13369-b31b1b.svg)](https://arxiv.org/abs/2308.13369) | :heavy_minus_sign: |
| Towards Zero-Shot Scale-Aware Monocular Depth Estimation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/tri-zerodepth) <br /> [![GitHub](https://img.shields.io/github/stars/tri-ml/vidar?style=flat)](https://github.com/tri-ml/vidar) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Guizilini_Towards_Zero-Shot_Scale-Aware_Monocular_Depth_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.17253-b31b1b.svg)](https://arxiv.org/abs/2306.17253) | :heavy_minus_sign: |
| Learning Depth Estimation for Transparent and Mirror Surfaces | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cvlab-unibo.github.io/Depth4ToM/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Costanzino_Learning_Depth_Estimation_for_Transparent_and_Mirror_Surfaces_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15052-b31b1b.svg)](https://arxiv.org/abs/2307.15052) | :heavy_minus_sign: |
| Uni-3D: A Universal Model for Panoptic 3D Scene Reconstruction | [![GitHub](https://img.shields.io/github/stars/mlpc-ucsd/Uni-3D?style=flat)](https://github.com/mlpc-ucsd/Uni-3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Uni-3D_A_Universal_Model_for_Panoptic_3D_Scene_Reconstruction_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| 3D VR Sketch Guided 3D Shape Prototyping and Exploration | [![GitHub](https://img.shields.io/github/stars/Rowl1ng/3Dsketch2shape?style=flat)](https://github.com/Rowl1ng/3Dsketch2shape) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_3D_VR_Sketch_Guided_3D_Shape_Prototyping_and_Exploration_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.10830-b31b1b.svg)](https://arxiv.org/abs/2306.10830) | :heavy_minus_sign: |
| Transparent Shape from a Single View Polarization Image | [![GitHub](https://img.shields.io/github/stars/shaomq2187/TransSfP?style=flat)](https://github.com/shaomq2187/TransSfP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2204.06331-b31b1b.svg)](https://arxiv.org/abs/2204.06331) | :heavy_minus_sign: |
| Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using Pixel-Aligned Reconstruction Priors | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://x-zhangyang.github.io/2023_Get3DHuman/) <br /> [![GitHub](https://img.shields.io/github/stars/X-zhangyang/Get3DHuman?style=flat)](https://github.com/X-zhangyang/Get3DHuman) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Get3DHuman_Lifting_StyleGAN-Human_into_a_3D_Generative_Model_Using_Pixel-Aligned_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.01162-b31b1b.svg)](https://arxiv.org/abs/2302.01162) | :heavy_minus_sign: |
| Zero-1-to-3: Zero-Shot One Image to 3D Object | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://zero123.cs.columbia.edu/) <br /> [![GitHub](https://img.shields.io/github/stars/cvlab-columbia/zero123?style=flat)](https://github.com/cvlab-columbia/zero123) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-Demo-FFD21F.svg)](https://huggingface.co/spaces/cvlab/zero123-live) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11328-b31b1b.svg)](https://arxiv.org/abs/2303.11328) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=EzcclEHqUBI) |
| FrozenRecon: Pose-Free 3D Scene Reconstruction with Frozen Depth Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://aim-uofa.github.io/FrozenRecon/) <br /> [![GitHub](https://img.shields.io/github/stars/aim-uofa/FrozenRecon?style=flat)](https://github.com/aim-uofa/FrozenRecon) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_FrozenRecon_Pose-free_3D_Scene_Reconstruction_with_Frozen_Depth_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.05733-b31b1b.svg)](https://arxiv.org/abs/2308.05733) | :heavy_minus_sign: |
| LIST: Learning Implicitly from Spatial Transformers for Single-View 3D Reconstruction | [![GitHub](https://img.shields.io/github/stars/robotic-vision-lab/Learning-Implicitly-From-Spatial-Transformers-Network?style=flat)](https://github.com/robotic-vision-lab/Learning-Implicitly-From-Spatial-Transformers-Network) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Arshad_LIST_Learning_Implicitly_from_Spatial_Transformers_for_Single-View_3D_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12194-b31b1b.svg)](https://arxiv.org/abs/2307.12194) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gUn5i6FgWWE) |
| 3DMiner: Discovering Shapes from Large-Scale Unannotated Image Datasets | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ttchengab.github.io/3dminerOfficial/) <br /> [![GitHub](https://img.shields.io/github/stars/ttchengab/3DMiner?style=flat)](https://github.com/ttchengab/3DMiner) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_3DMiner_Discovering_Shapes_from_Large-Scale_Unannotated_Image_Datasets_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.19188-b31b1b.svg)](https://arxiv.org/abs/2310.19188) | :heavy_minus_sign: |
| Nonrigid Object Contact Estimation with Regional Unwrapping Transformer | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Nonrigid_Object_Contact_Estimation_With_Regional_Unwrapping_Transformer_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14074-b31b1b.svg)](https://arxiv.org/abs/2308.14074) | :heavy_minus_sign: |
| SHERF: Generalizable Human NeRF from a Single Image | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://skhu101.github.io/SHERF/) <br /> [![GitHub](https://img.shields.io/github/stars/skhu101/SHERF?style=flat)](https://github.com/skhu101/SHERF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_SHERF_Generalizable_Human_NeRF_from_a_Single_Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12791-b31b1b.svg)](https://arxiv.org/abs/2303.12791) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xyiv-cW6VcI) |
| Full-Body Articulated Human-Object Interaction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jnnan.github.io/project/chairs/) <br /> [![GitHub](https://img.shields.io/github/stars/jnnan/chairs?style=flat)](https://github.com/jnnan/chairs) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Full-Body_Articulated_Human-Object_Interaction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.10621-b31b1b.svg)](https://arxiv.org/abs/2212.10621) | :heavy_minus_sign: |
| PlaneRecTR: Unified Query Learning for 3D Plane Recovery from a Single View | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sjingjia.github.io/PlaneRecTR/) <br /> [![GitHub](https://img.shields.io/github/stars/SJingjia/PlaneRecTR?style=flat)](https://github.com/SJingjia/PlaneRecTR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PlaneRecTR_Unified_Query_Learning_for_3D_Plane_Recovery_from_a_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13756-b31b1b.svg)](https://arxiv.org/abs/2307.13756) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YBB7totHGJg) |
| SceneRF: Self-Supervised Monocular 3D Scene Reconstruction with Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://astra-vision.github.io/SceneRF/) <br /> [![GitHub](https://img.shields.io/github/stars/astra-vision/SceneRF?style=flat)](https://github.com/astra-vision/SceneRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_SceneRF_Self-Supervised_Monocular_3D_Scene_Reconstruction_with_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02501-b31b1b.svg)](https://arxiv.org/abs/2212.02501) | :heavy_minus_sign: |
| 3D-Aware Neural Body Fitting for Occlusion Robust 3D Human Pose Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://3dnbf.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/edz-o/3DNBF?style=flat)](https://github.com/edz-o/3DNBF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_3D-Aware_Neural_Body_Fitting_for_Occlusion_Robust_3D_Human_Pose_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10123-b31b1b.svg)](https://arxiv.org/abs/2308.10123) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LO80Am0Sb0Y) |
| Two-in-One Depth: Bridging the Gap between Monocular and Binocular Self-Supervised Depth Estimation | [![GitHub](https://img.shields.io/github/stars/ZM-Zhou/TiO-Depth_pytorch?style=flat)](https://github.com/ZM-Zhou/TiO-Depth_pytorch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Two-in-One_Depth_Bridging_the_Gap_Between_Monocular_and_Binocular_Self-Supervised_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.00933-b31b1b.svg)](https://arxiv.org/abs/2309.00933) | :heavy_minus_sign: |
| LRRU: Long-Short Range Recurrent Updating Networks for Depth Completion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://npucvr.github.io/LRRU/) <br /> [![GitHub](https://img.shields.io/github/stars/YufeiWang777/LRRU?style=flat)](https://github.com/YufeiWang777/LRRU) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_LRRU_Long-short_Range_Recurrent_Updating_Networks_for_Depth_Completion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.08956-b31b1b.svg)](https://arxiv.org/abs/2310.08956) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KBU0asJ8J2Y) |
| OccFormer: Dual-Path Transformer for Vision-based 3D Semantic Occupancy Prediction | [![GitHub](https://img.shields.io/github/stars/zhangyp15/OccFormer?style=flat)](https://github.com/zhangyp15/OccFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_OccFormer_Dual-path_Transformer_for_Vision-based_3D_Semantic_Occupancy_Prediction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.05316-b31b1b.svg)](https://arxiv.org/abs/2304.05316) | :heavy_minus_sign: |
| CHORD: Category-Level Hand-Held Object Reconstruction via Shape Deformation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kailinli.github.io/CHORD/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CHORD_Category-level_Hand-held_Object_Reconstruction_via_Shape_Deformation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10574-b31b1b.svg)](https://arxiv.org/abs/2308.10574) | :heavy_minus_sign: |
| NDC-Scene: Boost Monocular 3D Semantic Scene Completion in Normalized Device Coordinates Space | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jiawei-yao0812.github.io/NDC-Scene/) <br /> [![GitHub](https://img.shields.io/github/stars/Jiawei-Yao0812/NDCScene?style=flat)](https://github.com/Jiawei-Yao0812/NDCScene) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_NDC-Scene_Boost_Monocular_3D_Semantic_Scene_Completion_in_Normalized_Device_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.14616-b31b1b.svg)](https://arxiv.org/abs/2309.14616) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hEpxgMSijUc) |
| Neural Video Depth Stabilizer | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://raymondwang987.github.io/NVDS/) <br /> [![GitHub](https://img.shields.io/github/stars/RaymondWang987/NVDS?style=flat)](https://github.com/RaymondWang987/NVDS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Neural_Video_Depth_Stabilizer_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08695-b31b1b.svg)](https://arxiv.org/abs/2307.08695) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SNV9F-60xrE) |
| DiLiGenT-Pi: Photometric Stereo for Planar Surfaces with Rich Details - Benchmark Dataset and Beyond | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://photometricstereo.github.io/diligentpi.html) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DiLiGenT-Pi_Photometric_Stereo_for_Planar_Surfaces_with_Rich_Details_-_ICCV_2023_paper.pdf) <br /> [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://photometricstereo.github.io/imgs/diligentpi/paper.pdf) | :heavy_minus_sign: |
