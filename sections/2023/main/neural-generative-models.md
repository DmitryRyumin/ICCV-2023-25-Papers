# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/explainable-ai-for-cv.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/vision-and-language.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Neural Generative Models

![Section Papers](https://img.shields.io/badge/Section%20Papers-34-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-28-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-22-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-7-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://energy-based-model.github.io/unsupervised-concept-discovery/) <br /> [![GitHub](https://img.shields.io/github/stars/nanlliu/Unsupervised-Compositional-Concepts-Discovery?style=flat)](https://github.com/nanlliu/Unsupervised-Compositional-Concepts-Discovery) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Unsupervised_Compositional_Concepts_Discovery_with_Text-to-Image_Generative_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.05357-b31b1b.svg)](https://arxiv.org/abs/2306.05357) | :heavy_minus_sign: |
| Human Preference Score: Better Aligning Text-to-Image Models with Human Preference | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tgxs002.github.io/align_sd_web/) <br /> [![GitHub](https://img.shields.io/github/stars/tgxs002/align_sd?style=flat)](https://github.com/tgxs002/align_sd) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14420-b31b1b.svg)](https://arxiv.org/abs/2303.14420) | :heavy_minus_sign: |
| DLT: Conditioned Layout Generation with Joint Discrete-Continuous Diffusion Layout Transformer | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wix-incubator.github.io/DLT/) <br /> [![GitHub](https://img.shields.io/github/stars/wix-incubator/DLT?style=flat)](https://github.com/wix-incubator/DLT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Levi_DLT_Conditioned_layout_generation_with_Joint_Discrete-Continuous_Diffusion_Layout_Transformer_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.03755-b31b1b.svg)](https://arxiv.org/abs/2303.03755) | :heavy_minus_sign: |
| Anti-DreamBooth: Protecting users from Personalized Text-to-Image Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://anti-dreambooth.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/VinAIResearch/Anti-DreamBooth?style=flat)](https://github.com/VinAIResearch/Anti-DreamBooth) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15433-b31b1b.svg)](https://arxiv.org/abs/2303.15433) | :heavy_minus_sign: |
| GECCO: Geometrically-Conditioned Point Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jatentaki.github.io/publication/10-03-2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tyszkiewicz_GECCO_Geometrically-Conditioned_Point_Diffusion_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05916-b31b1b.svg)](https://arxiv.org/abs/2303.05916) | :heavy_minus_sign: |
| DiffDreamer: Towards Consistent Unsupervised Single-View Scene Extrapolation with Conditional Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://primecai.github.io/diffdreamer) <br /> [![GitHub](https://img.shields.io/github/stars/primecai/DiffDreamer?style=flat)](https://github.com/primecai/DiffDreamer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_DiffDreamer_Towards_Consistent_Unsupervised_Single-view_Scene_Extrapolation_with_Conditional_Diffusion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12131-b31b1b.svg)](https://arxiv.org/abs/2211.12131) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UukyiAqlwcw) |
| Guided Motion Diffusion for Controllable Human Motion Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://korrawe.github.io/gmd-project/) <br /> [![GitHub](https://img.shields.io/github/stars/korrawe/guided-motion-diffusion?style=flat)](https://github.com/korrawe/guided-motion-diffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Karunratanakul_Guided_Motion_Diffusion_for_Controllable_Human_Motion_Synthesis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.12577-b31b1b.svg)](https://arxiv.org/abs/2305.12577) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=giw0pLIKdsA) |
| COOP: Decoupling and Coupling of Whole-Body Grasping Pose Generation | [![GitHub](https://img.shields.io/github/stars/zhengyanzhao1997/COOP?style=flat)](https://github.com/zhengyanzhao1997/COOP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_COOP_Decoupling_and_Coupling_of_Whole-Body_Grasping_Pose_Generation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Zero-Shot Spatial Layout Conditioning for Text-to-Image Diffusion Models | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.13754-b31b1b.svg)](https://arxiv.org/abs/2306.13754) | :heavy_minus_sign: |
| StyleDomain: Efficient and Lightweight Parameterizations of StyleGAN for One-Shot and Few-Shot Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/AIRI-Institute/StyleDomain?style=flat)](https://github.com/AIRI-Institute/StyleDomain) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Alanov_StyleDomain_Efficient_and_Lightweight_Parameterizations_of_StyleGAN_for_One-shot_and_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.10229-b31b1b.svg)](https://arxiv.org/abs/2212.10229) | :heavy_minus_sign: |
| GRAM-HD: 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jeffreyxiang.github.io/GRAM-HD/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.07255-b31b1b.svg)](https://arxiv.org/abs/2206.07255) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Uqzs4uN6v8M) |
| Your Diffusion Model is Secretly a Zero-Shot Classifier | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://diffusion-classifier.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/diffusion-classifier/diffusion-classifier?style=flat)](https://github.com/diffusion-classifier/diffusion-classifier) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Your_Diffusion_Model_is_Secretly_a_Zero-Shot_Classifier_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16203-b31b1b.svg)](https://arxiv.org/abs/2303.16203) | :heavy_minus_sign: |
| Learning Hierarchical Features with Joint Latent Space Energy-based Prior | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jcui1224.github.io/hierarchical-representation-ebm-proj/) <br /> [![GitHub](https://img.shields.io/github/stars/jcui1224/hierarchical-representation-ebm?style=flat)](https://github.com/jcui1224/hierarchical-representation-ebm) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Learning_Hierarchical_Features_with_Joint_Latent_Space_Energy-Based_Prior_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.09604-b31b1b.svg)](https://arxiv.org/abs/2310.09604) | :heavy_minus_sign: |
| ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D Human Motion Generation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ActFormer_A_GAN-based_Transformer_towards_General_Action-Conditioned_3D_Human_Motion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2203.07706-b31b1b.svg)](https://arxiv.org/abs/2203.07706) | :heavy_minus_sign: |
| Landscape Learning for Neural Network Inversion | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Landscape_Learning_for_Neural_Network_Inversion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.09027-b31b1b.svg)](https://arxiv.org/abs/2206.09027) | :heavy_minus_sign: |
| Diffusion in Style | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ivrl.github.io/diffusion-in-style/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Everaert_Diffusion_in_Style_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3Ge98E4x4JA) |
| Diffusion-SDF: Conditional Generative Modeling of Signed Distance Functions | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://light.princeton.edu/publication/diffusion-sdf/) <br /> [![GitHub](https://img.shields.io/github/stars/princeton-computational-imaging/Diffusion-SDF?style=flat)](https://github.com/princeton-computational-imaging/Diffusion-SDF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chou_Diffusion-SDF_Conditional_Generative_Modeling_of_Signed_Distance_Functions_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.13757-b31b1b.svg)](https://arxiv.org/abs/2211.13757) | :heavy_minus_sign: |
| GETAvatar: Generative Textured Meshes for Animatable Human Avatars | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://getavatar.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/magic-research/GETAvatar?style=flat)](https://github.com/magic-research/GETAvatar) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GETAvatar_Generative_Textured_Meshes_for_Animatable_Human_Avatars_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| A-STAR: Test-Time <i>A</i>ttention <i>S</i>egrega<i>t</i>ion and <i>R</i>etention for Text-to-Image Synthesis | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.14544-b31b1b.svg)](https://arxiv.org/abs/2306.14544) | :heavy_minus_sign: |
| TF-ICON: Diffusion-based Training-Free Cross-Domain Image Composition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://shilin-lu.github.io/tf-icon.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/Shilin-LU/TF-ICON?style=flat)](https://github.com/Shilin-LU/TF-ICON) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12493-b31b1b.svg)](https://arxiv.org/abs/2307.12493) | :heavy_minus_sign: |
| Breaking The Limits of Text-Conditioned 3D Motion Synthesis with Elaborative Descriptions | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Breaking_The_Limits_of_Text-conditioned_3D_Motion_Synthesis_with_Elaborative_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://barquerogerman.github.io/BeLFusion/) <br /> [![GitHub](https://img.shields.io/github/stars/BarqueroGerman/BeLFusion?style=flat)](https://github.com/BarqueroGerman/BeLFusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Barquero_BeLFusion_Latent_Diffusion_for_Behavior-Driven_Human_Motion_Prediction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14304-b31b1b.svg)](https://arxiv.org/abs/2211.14304) | :heavy_minus_sign: |
| Delta Denoising Score | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://delta-denoising-score.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hertz_Delta_Denoising_Score_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.07090-b31b1b.svg)](https://arxiv.org/abs/2304.07090) | :heavy_minus_sign: |
| Mimic3D: Thriving 3D-Aware GANs via 3D-to-2D Imitation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://seanchenxy.github.io/Mimic3DWeb/) <br /> [![GitHub](https://img.shields.io/github/stars/SeanChenxy/Mimic3D?style=flat)](https://github.com/SeanChenxy/Mimic3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Mimic3D_Thriving_3D-Aware_GANs_via_3D-to-2D_Imitation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09036-b31b1b.svg)](https://arxiv.org/abs/2303.09036) | :heavy_minus_sign: |
| DreamBooth3D: Subject-Driven Text-to-3D Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dreambooth3d.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_Generation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13508-b31b1b.svg)](https://arxiv.org/abs/2303.13508) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kKVDrbfvOoA) |
| Feature Proliferation - the "Cancer" in StyleGAN and its Treatments | [![GitHub](https://img.shields.io/github/stars/songc42/Feature-proliferation?style=flat)](https://github.com/songc42/Feature-proliferation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Feature_Proliferation_--_the_Cancer_in_StyleGAN_and_its_Treatments_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.08921-b31b1b.svg)](https://arxiv.org/abs/2310.08921) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aXiGRakMu3k) |
| Unsupervised Facial Performance Editing via Vector-Quantized StyleGAN Representations | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kicanaoglu_Unsupervised_Facial_Performance_Editing_via_Vector-Quantized_StyleGAN_Representations_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| 3D-Aware Image Generation using 2D Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jeffreyxiang.github.io/ivid/) <br /> [![GitHub](https://img.shields.io/github/stars/JeffreyXiang/ivid?style=flat)](https://github.com/JeffreyXiang/ivid) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17905-b31b1b.svg)](https://arxiv.org/abs/2303.17905) | :heavy_minus_sign: |
| Neural Collage Transfer: Artistic Reconstruction via Material Manipulation | [![GitHub](https://img.shields.io/github/stars/northadventure/CollageRL?style=flat)](https://github.com/northadventure/CollageRL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Neural_Collage_Transfer_Artistic_Reconstruction_via_Material_Manipulation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.02202-b31b1b.svg)](https://arxiv.org/abs/2311.02202) | :heavy_minus_sign: |
| Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption | [![GitHub](https://img.shields.io/github/stars/sjtuplayer/few-shot-diffusion?style=flat)](https://github.com/sjtuplayer/few-shot-diffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03729-b31b1b.svg)](https://arxiv.org/abs/2309.03729) | :heavy_minus_sign: |
| Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lakonik.github.io/ssdnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/Lakonik/SSDNeRF?style=flat)](https://github.com/Lakonik/SSDNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Single-Stage_Diffusion_NeRF_A_Unified_Approach_to_3D_Generation_and_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06714-b31b1b.svg)](https://arxiv.org/abs/2304.06714) | :heavy_minus_sign: |
| Erasing Concepts from Diffusion Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://erasing.baulab.info/) <br /> [![GitHub](https://img.shields.io/github/stars/rohitgandikota/erasing?style=flat)](https://github.com/rohitgandikota/erasing) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gandikota_Erasing_Concepts_from_Diffusion_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07345-b31b1b.svg)](https://arxiv.org/abs/2303.07345) | :heavy_minus_sign: |
| Make Encoder Great Again in 3D GAN Inversion through Geometry and Occlusion-Aware Encoding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://eg3d-goae.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/jiangyzy/GOAE?style=flat)](https://github.com/jiangyzy/GOAE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Make_Encoder_Great_Again_in_3D_GAN_Inversion_through_Geometry_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12326-b31b1b.svg)](https://arxiv.org/abs/2303.12326) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CptQDMqM9Pc) |
| HairNeRF: Geometry-Aware Image Synthesis for Hairstyle Transfer | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_HairNeRF_Geometry-Aware_Image_Synthesis_for_Hairstyle_Transfer_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
