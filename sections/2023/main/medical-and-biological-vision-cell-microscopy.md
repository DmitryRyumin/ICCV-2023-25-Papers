# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/faces-and-gestures.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/scene-analysis-and-understanding.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Medical and Biological Vision; Cell Microscopy

![Section Papers](https://img.shields.io/badge/Section%20Papers-40-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-25-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-32-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-3-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| CO-PILOT: Dynamic Top-Down Point Cloud with Conditional Neighborhood Aggregation for Multi-Gigapixel Histopathology Image Representation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakhli_CO-PILOT_Dynamic_Top-Down_Point_Cloud_with_Conditional_Neighborhood_Aggregation_for_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| SKiT: A Fast Key Information Video Transformer for Online Surgical Phase Recognition | [![GitHub](https://img.shields.io/github/stars/MRUIL/SKiT?style=flat)](https://github.com/MRUIL/SKiT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SKiT_a_Fast_Key_Information_Video_Transformer_for_Online_Surgical_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| XNet: Wavelet-based Low and High Frequency Fusion Networks for Fully- and Semi-Supervised Semantic Segmentation of Biomedical Images | [![GitHub](https://img.shields.io/github/stars/Yanfeng-Zhou/XNet?style=flat)](https://github.com/Yanfeng-Zhou/XNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_XNet_Wavelet-Based_Low_and_High_Frequency_Fusion_Networks_for_Fully-_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Probabilistic Modeling of Inter- and Intra-Observer Variability in Medical Image Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11397-b31b1b.svg)](https://arxiv.org/abs/2307.11397) | :heavy_minus_sign: |
| Learning Cross-Representation Affinity Consistency for Sparsely Supervised Biomedical Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/liuxy1103/CRAC?style=flat)](https://github.com/liuxy1103/CRAC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Cross-Representation_Affinity_Consistency_for_Sparsely_Supervised_Biomedical_Instance_Segmentation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Dual Meta-Learning with Longitudinally Consistent Regularization for One-Shot Brain Tissue Segmentation Across the Human Lifespan | [![GitHub](https://img.shields.io/github/stars/ladderlab-xjtu/DuMeta?style=flat)](https://github.com/ladderlab-xjtu/DuMeta) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Dual_Meta-Learning_with_Longitudinally_Consistent_Regularization_for_One-Shot_Brain_Tissue_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06774-b31b1b.svg)](https://arxiv.org/abs/2308.06774) | :heavy_minus_sign: |
| BlindHarmony: "Blind" Harmonization for MR Images via Flow Model | [![GitHub](https://img.shields.io/github/stars/Hwihuni/BlindHarmony?style=flat)](https://github.com/Hwihuni/BlindHarmony) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jeong_BlindHarmony_Blind_Harmonization_for_MR_Images_via_Flow_Model_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.10732-b31b1b.svg)](https://arxiv.org/abs/2305.10732) | :heavy_minus_sign: |
| Continual Segment: Towards a Single, Unified and Non-Forgetting Continual Segmentation Model of 143 Whole-Body Organs in CT Scans | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Continual_Segment_Towards_a_Single_Unified_and_Non-forgetting_Continual_Segmentation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection | [![GitHub](https://img.shields.io/github/stars/ljwztc/CLIP-Driven-Universal-Model?style=flat)](https://github.com/ljwztc/CLIP-Driven-Universal-Model) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.00785-b31b1b.svg)](https://arxiv.org/abs/2301.00785) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=D1pNk2z3aiQ) |
| LIMITR: Leveraging Local Information for Medical Image-Text Representation | [![GitHub](https://img.shields.io/github/stars/gefend/LIMITR?style=flat)](https://github.com/gefend/LIMITR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dawidowicz_LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11755-b31b1b.svg)](https://arxiv.org/abs/2303.11755) | :heavy_minus_sign: |
| Taxonomy Adaptive Cross-Domain Adaptation in Medical Imaging via Optimization Trajectory Distillation | [![GitHub](https://img.shields.io/github/stars/camwew/TADA-MI?style=flat)](https://github.com/camwew/TADA-MI) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Taxonomy_Adaptive_Cross-Domain_Adaptation_in_Medical_Imaging_via_Optimization_Trajectory_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.14709-b31b1b.svg)](https://arxiv.org/abs/2307.14709) | :heavy_minus_sign: |
| CuNeRF: Cube-based Neural Radiance Field for Zero-Shot Medical Image Arbitrary-Scale Super Resolution | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://narcissusex.github.io/CuNeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/NarcissusEx/CuNeRF?style=flat)](https://github.com/NarcissusEx/CuNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16242-b31b1b.svg)](https://arxiv.org/abs/2303.16242) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=6m1I88hGmYU) |
| Learning to Distill Global Representation for Sparse-View CT | [![GitHub](https://img.shields.io/github/stars/longzilicart/GloReDi?style=flat)](https://github.com/longzilicart/GloReDi) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_to_Distill_Global_Representation_for_Sparse-View_CT_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.08463-b31b1b.svg)](https://arxiv.org/abs/2308.08463) | :heavy_minus_sign: |
| Preserving Tumor Volumes for Unsupervised Medical Image Registration | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dddraxxx.github.io/Volume-Preserving-Registration/) <br /> [![GitHub](https://img.shields.io/github/stars/dddraxxx/Medical-Reg-with-Volume-Preserving?style=flat)](https://github.com/dddraxxx/Medical-Reg-with-Volume-Preserving) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Preserving_Tumor_Volumes_for_Unsupervised_Medical_Image_Registration_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.10153-b31b1b.svg)](https://arxiv.org/abs/2309.10153) | :heavy_minus_sign: |
| ÂµSplit: Image Decomposition for Fluorescence Microscopy | [![GitHub](https://img.shields.io/github/stars/juglab/uSplit?style=flat)](https://github.com/juglab/uSplit) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.pdf)  <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12872-b31b1b.svg)](https://arxiv.org/abs/2211.12872) | :heavy_minus_sign: |
| Rethinking Multi-Contrast MRI Super-Resolution: Rectangle-Window Cross-Attention Transformer and Arbitrary-Scale Upsampling | [![GitHub](https://img.shields.io/github/stars/GuangYuanKK/McASSR?style=flat)](https://github.com/GuangYuanKK/McASSR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Rethinking_Multi-Contrast_MRI_Super-Resolution_Rectangle-Window_Cross-Attention_Transformer_and_Arbitrary-Scale_Upsampling_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Multimodal Optimal Transport-based Co-Attention Transformer with Global Structure Consistency for Survival Prediction | [![GitHub](https://img.shields.io/github/stars/Innse/MOTCat?style=flat)](https://github.com/Innse/MOTCat) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multimodal_Optimal_Transport-based_Co-Attention_Transformer_with_Global_Structure_Consistency_for_ICCV_2023_paper.pdf)  <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.08330-b31b1b.svg)](https://arxiv.org/abs/2306.08330) | :heavy_minus_sign: |
| 4D Myocardium Reconstruction with Decoupled Motion and Shape Model | [![GitHub](https://img.shields.io/github/stars/yuan-xiaohan/4D-Myocardium-Reconstruction-with-Decoupled-Motion-and-Shape-Model?style=flat)](https://github.com/yuan-xiaohan/4D-Myocardium-Reconstruction-with-Decoupled-Motion-and-Shape-Model) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_4D_Myocardium_Reconstruction_with_Decoupled_Motion_and_Shape_Model_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14083-b31b1b.svg)](https://arxiv.org/abs/2308.14083) | :heavy_minus_sign: |
| Unsupervised Learning of Object-Centric Embeddings for Cell Instance Segmentation in Microscopy Images | [![GitHub](https://img.shields.io/github/stars/funkelab/cellulus?style=flat)](https://github.com/funkelab/cellulus) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wolf_Unsupervised_Learning_of_Object-Centric_Embeddings_for_Cell_Instance_Segmentation_in_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.08501-b31b1b.svg)](https://arxiv.org/abs/2310.08501) | :heavy_minus_sign: |
| LightDepth: Single-View Depth Self-Supervision from Illumination Decline | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Rodriguez-Puigvert_LightDepth_Single-View_Depth_Self-Supervision_from_Illumination_Decline_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10525-b31b1b.svg)](https://arxiv.org/abs/2308.10525) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Jrzzy2JjOCQ) |
| BoMD: Bag of Multi-Label Descriptors for Noisy Chest X-Ray Classification | [![GitHub](https://img.shields.io/github/stars/cyh-0/BoMD?style=flat)](https://github.com/cyh-0/BoMD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_BoMD_Bag_of_Multi-label_Descriptors_for_Noisy_Chest_X-ray_Classification_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2203.01937-b31b1b.svg)](https://arxiv.org/abs/2203.01937) | :heavy_minus_sign: |
| Decomposition-based Variational Network for Multi-Contrast MRI Super-Resolution and Reconstruction | [![GitHub](https://img.shields.io/github/stars/lpcccc-cv/MC-VarNet?style=flat)](https://github.com/lpcccc-cv/MC-VarNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Decomposition-Based_Variational_Network_for_Multi-Contrast_MRI_Super-Resolution_and_Reconstruction_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| TopoSeg: Topology-Aware Nuclear Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/hhlisme/toposeg?style=flat)](https://github.com/hhlisme/toposeg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/He_TopoSeg_Topology-Aware_Nuclear_Instance_Segmentation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Scratch Each Other's Back: Incomplete Multi-Modal Brain Tumor Segmentation via Category Aware Group Self-Support Learning | [![GitHub](https://img.shields.io/github/stars/qysgithubopen/GSS?style=flat)](https://github.com/qysgithubopen/GSS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Scratch_Each_Others_Back_Incomplete_Multi-Modal_Brain_Tumor_Segmentation_via_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers using a Large Collection of CT Scans | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CancerUniT_Towards_a_Single_Unified_Model_for_Effective_Detection_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.12291-b31b1b.svg)](https://arxiv.org/abs/2301.12291) | :heavy_minus_sign: |
| Gram-based Attentive Neural Ordinary Differential Equations Network for Video Nystagmography Classification | [![GitHub](https://img.shields.io/github/stars/XiheQiu/Gram-AODE?style=flat)](https://github.com/XiheQiu/Gram-AODE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Gram-based_Attentive_Neural_Ordinary_Differential_Equations_Network_for_Video_Nystagmography_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| ConSlide: Asynchronous Hierarchical Interaction Transformer with Breakup-Reorganize Rehearsal for Continual Whole Slide Image Analysis | [![GitHub](https://img.shields.io/github/stars/HKU-MedAI/ConSlide?style=flat)](https://github.com/HKU-MedAI/ConSlide) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13324-b31b1b.svg)](https://arxiv.org/abs/2308.13324) | :heavy_minus_sign: |
| PRIOR: Prototype Representation Joint Learning from Medical Images and Reports | [![GitHub](https://img.shields.io/github/stars/QtacierP/PRIOR?style=flat)](https://github.com/QtacierP/PRIOR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_PRIOR_Prototype_Representation_Joint_Learning_from_Medical_Images_and_Reports_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12577-b31b1b.svg)](https://arxiv.org/abs/2307.12577) | :heavy_minus_sign: |
| MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training for X-Ray Diagnosis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chaoyi-wu.github.io/MedKLIP/) <br /> [![GitHub](https://img.shields.io/github/stars/MediaBrain-SJTU/MedKLIP?style=flat)](https://github.com/MediaBrain-SJTU/MedKLIP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.02228-b31b1b.svg)](https://arxiv.org/abs/2301.02228) | :heavy_minus_sign: |
| Affine-Consistent Transformer for Multi-Class Cell Nuclei Detection | [![GitHub](https://img.shields.io/github/stars/LL3RD/ACFormer?style=flat)](https://github.com/LL3RD/ACFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Affine-Consistent_Transformer_for_Multi-Class_Cell_Nuclei_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.14154-b31b1b.svg)](https://arxiv.org/abs/2310.14154) | :heavy_minus_sign: |
| A Skeletonization Algorithm for Gradient-based Optimization | [![GitHub](https://img.shields.io/github/stars/martinmenten/skeletonization-for-gradient-based-optimization?style=flat)](https://github.com/martinmenten/skeletonization-for-gradient-based-optimization) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Menten_A_Skeletonization_Algorithm_for_Gradient-Based_Optimization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02527-b31b1b.svg)](https://arxiv.org/abs/2309.02527) | :heavy_minus_sign: |
| Improving Representation Learning for Histopathologic Images with Cluster Constraints | [![GitHub](https://img.shields.io/github/stars/wwyi1828/CluSiam?style=flat)](https://github.com/wwyi1828/CluSiam) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Improving_Representation_Learning_for_Histopathologic_Images_with_Cluster_Constraints_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.12334-b31b1b.svg)](https://arxiv.org/abs/2310.12334) | :heavy_minus_sign: |
| Enhancing Modality-Agnostic Representations via Meta-Learning for Brain Tumor Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Konwer_Enhancing_Modality-Agnostic_Representations_via_Meta-Learning_for_Brain_Tumor_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.04308-b31b1b.svg)](https://arxiv.org/abs/2302.04308) | :heavy_minus_sign: |
| CauSSL: Causality-Inspired Semi-Supervised Learning for Medical Image Segmentation | [![GitHub](https://img.shields.io/github/stars/JuzhengMiao/CauSSL?style=flat)](https://github.com/JuzhengMiao/CauSSL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| UniverSeg: Universal Medical Image Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://universeg.csail.mit.edu/) <br /> [![GitHub](https://img.shields.io/github/stars/JJGO/UniverSeg?style=flat)](https://github.com/JJGO/UniverSeg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06131-b31b1b.svg)](https://arxiv.org/abs/2304.06131) | :heavy_minus_sign: |
| MRM: Masked Relation Modeling for Medical Image Pre-Training with Genetics | [![GitHub](https://img.shields.io/github/stars/CityU-AIM-Group/MRM?style=flat)](https://github.com/CityU-AIM-Group/MRM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Boosting whole Slide Image Classification from the Perspectives of Distribution, Correlation and Magnification | [![GitHub](https://img.shields.io/github/stars/miccaiif/MILBooster?style=flat)](https://github.com/miccaiif/MILBooster) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Boosting_Whole_Slide_Image_Classification_from_the_Perspectives_of_Distribution_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Adaptive Template Transformer for Mitochondria Segmentation in Electron Microscopy Images | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Adaptive_Template_Transformer_for_Mitochondria_Segmentation_in_Electron_Microscopy_Images_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Cross-Modal Translation and Alignment for Survival Analysis | [![GitHub](https://img.shields.io/github/stars/FT-ZHOU-ZZZ/CMTA?style=flat)](https://github.com/FT-ZHOU-ZZZ/CMTA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Cross-Modal_Translation_and_Alignment_for_Survival_Analysis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.12855-b31b1b.svg)](https://arxiv.org/abs/2309.12855) | :heavy_minus_sign: |
| LNPL-MIL: Learning from Noisy Pseudo Labels for Promoting Multiple Instance Learning in whole Slide Image | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_LNPL-MIL_Learning_from_Noisy_Pseudo_Labels_for_Promoting_Multiple_Instance_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
