# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/3d-shape-modeling-and-processing.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/transfer-low-shot-and-continual-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Human Pose/Shape Estimation

![Section Papers](https://img.shields.io/badge/Section%20Papers-47-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-38-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-35-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-19-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| EMDB: The Electromagnetic Database of Global 3D Human Pose and Shape in the Wild | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://eth-ait.github.io/emdb/) <br /> [![GitHub](https://img.shields.io/github/stars/eth-ait/emdb?style=flat)](https://github.com/eth-ait/emdb) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kaufmann_EMDB_The_Electromagnetic_Database_of_Global_3D_Human_Pose_and_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.16894-b31b1b.svg)](https://arxiv.org/abs/2308.16894) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=H66-YE4GUHI) |
| ReFit: Recurrent Fitting Network for 3D Human Recovery | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yufu-wang.github.io/refit_humans/) <br /> [![GitHub](https://img.shields.io/github/stars/yufu-wang/ReFit?style=flat)](https://github.com/yufu-wang/ReFit) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ReFit_Recurrent_Fitting_Network_for_3D_Human_Recovery_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11184-b31b1b.svg)](https://arxiv.org/abs/2308.11184) | :heavy_minus_sign: |
| Global Adaptation Meets Local Generalization: Unsupervised Domain Adaptation for 3D Human Pose Estimation | [![GitHub](https://img.shields.io/github/stars/rese1f/PoseDA?style=flat)](https://github.com/rese1f/PoseDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_Global_Adaptation_Meets_Local_Generalization_Unsupervised_Domain_Adaptation_for_3D_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16456-b31b1b.svg)](https://arxiv.org/abs/2303.16456) | :heavy_minus_sign: |
| Spectral Graphormer: Spectral Graph-based Transformer for Egocentric Two-Hand Reconstruction using Multi-View Color Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://eldentse.github.io/Spectral-Graphormer/) <br /> [![GitHub](https://img.shields.io/github/stars/eldentse/Spectral-Graphormer?style=flat)](https://github.com/eldentse/Spectral-Graphormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tse_Spectral_Graphormer_Spectral_Graph-Based_Transformer_for_Egocentric_Two-Hand_Reconstruction_using_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11015-b31b1b.svg)](https://arxiv.org/abs/2308.11015) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cfsk5e5C_Xs) |
| Realistic Full-Body Tracking from Sparse Observations via Joint-Level Modeling | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zxz267.github.io/AvatarJLM/) <br /> [![GitHub](https://img.shields.io/github/stars/zxz267/AvatarJLM?style=flat)](https://github.com/zxz267/AvatarJLM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Realistic_Full-Body_Tracking_from_Sparse_Observations_via_Joint-Level_Modeling_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.08855-b31b1b.svg)](https://arxiv.org/abs/2308.08855) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=H2sPFL0T3yk) |
| Rethinking Pose Estimation in Crowds: Overcoming the Detection Information Bottleneck and Ambiguity | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://amathislab.github.io/BUCTD/) <br /> [![GitHub](https://img.shields.io/github/stars/amathislab/BUCTD?style=flat)](https://github.com/amathislab/BUCTD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07879-b31b1b.svg)](https://arxiv.org/abs/2306.07879) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=BHZnA-CZeZY) |
| HDG-ODE: A Hierarchical Continuous-Time Model for Human Pose Forecasting | [![GitHub](https://img.shields.io/github/stars/SBU-YCX/HDG-ODE?style=flat)](https://github.com/SBU-YCX/HDG-ODE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xing_HDG-ODE_A_Hierarchical_Continuous-Time_Model_for_Human_Pose_Forecasting_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| AffordPose: A Large-Scale Dataset of Hand-Object Interactions with Affordance-Driven Hand Pose | [![GitHub](https://img.shields.io/github/stars/GentlesJan/AffordPose?style=flat)](https://github.com/GentlesJan/AffordPose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_AffordPose_A_Large-Scale_Dataset_of_Hand-Object_Interactions_with_Affordance-Driven_Hand_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08942-b31b1b.svg)](https://arxiv.org/abs/2309.08942) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s89tlzoM_M0) |
| PhaseMP: Robust 3D Pose Estimation via Phase-Conditioned Human Motion Prior | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PhaseMP_Robust_3D_Pose_Estimation_via_Phase-conditioned_Human_Motion_Prior_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Synthesizing Diverse Human Motions in 3D Indoor Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zkf1997.github.io/DIMOS/) <br /> [![GitHub](https://img.shields.io/github/stars/zkf1997/DIMOS?style=flat)](https://github.com/zkf1997/DIMOS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Synthesizing_Diverse_Human_Motions_in_3D_Indoor_Scenes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.12411-b31b1b.svg)](https://arxiv.org/abs/2305.12411) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=O3VpvETNjcw) |
| TEMPO: Efficient Multi-View Pose Estimation, Tracking, and Forecasting | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rccchoudhury.github.io/tempo2023/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Choudhury_TEMPO_Efficient_Multi-View_Pose_Estimation_Tracking_and_Forecasting_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.07910-b31b1b.svg)](https://arxiv.org/abs/2309.07910) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jxmBQqmVkIw) |
| Diffusion-based 3D Human Pose Estimation with Multi-Hypothesis Aggregation | [![GitHub](https://img.shields.io/github/stars/paTRICK-swk/D3DP?style=flat)](https://github.com/paTRICK-swk/D3DP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shan_Diffusion-Based_3D_Human_Pose_Estimation_with_Multi-Hypothesis_Aggregation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11579-b31b1b.svg)](https://arxiv.org/abs/2303.11579) | :heavy_minus_sign: |
| Towards Robust and Smooth 3D Multi-Person Pose Estimation from Monocular Videos in the Wild | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Towards_Robust_and_Smooth_3D_Multi-Person_Pose_Estimation_from_Monocular_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08644-b31b1b.svg)](https://arxiv.org/abs/2309.08644) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=d8z8DOE6s4I) |
| Humans in 4D: Reconstructing and Tracking Humans with Transformers | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://shubham-goel.github.io/4dhumans/) <br /> [![GitHub](https://img.shields.io/github/stars/shubham-goel/4D-Humans?style=flat)](https://github.com/shubham-goel/4D-Humans) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-demo-FFD21F.svg)](https://huggingface.co/spaces/brjathu/HMR2.0) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Humans_in_4D_Reconstructing_and_Tracking_Humans_with_Transformers_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.20091-b31b1b.svg)](https://arxiv.org/abs/2305.20091) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=v6viHm2-uY4) |
| NPC: Neural Point Characters from Video | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lemonatsu.github.io/npc/) <br /> [![GitHub](https://img.shields.io/github/stars/LemonATsu/NPC-pytorch?style=flat)](https://github.com/LemonATsu/NPC-pytorch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Su_NPC_Neural_Point_Characters_from_Video_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02013-b31b1b.svg)](https://arxiv.org/abs/2304.02013) | :heavy_minus_sign: |
| Priority-Centric Human Motion Generation in Discrete Latent Space | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Priority-Centric_Human_Motion_Generation_in_Discrete_Latent_Space_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14480-b31b1b.svg)](https://arxiv.org/abs/2308.14480) | :heavy_minus_sign: |
| NCHO: Unsupervised Learning for Neural 3D Composition of Humans and Objects | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://taeksuu.github.io/ncho/) <br /> [![GitHub](https://img.shields.io/github/stars/taeksuu/ncho?style=flat)](https://github.com/taeksuu/ncho) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_NCHO_Unsupervised_Learning_for_Neural_3D_Composition_of_Humans_and_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.14345-b31b1b.svg)](https://arxiv.org/abs/2305.14345) | :heavy_minus_sign: |
| Cyclic Test-Time Adaptation on Monocular Video for 3D Human Mesh Reconstruction | [![GitHub](https://img.shields.io/github/stars/hygenie1228/CycleAdapt_RELEASE?style=flat)](https://github.com/hygenie1228/CycleAdapt_RELEASE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nam_Cyclic_Test-Time_Adaptation_on_Monocular_Video_for_3D_Human_Mesh_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06554-b31b1b.svg)](https://arxiv.org/abs/2308.06554) | :heavy_minus_sign: |
| MHEntropy: Entropy Meets Multiple Hypotheses for Pose and Shape Recovery | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gloryyrolg.github.io/MHEntropy/) <br /> [![GitHub](https://img.shields.io/github/stars/gloryyrolg/MHEntropy?style=flat)](https://github.com/gloryyrolg/MHEntropy) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MHEntropy_Entropy_Meets_Multiple_Hypotheses_for_Pose_and_Shape_Recovery_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0riX3iJeVyM) |
| Probabilistic Triangulation for Uncalibrated Multi-View 3D Human Pose Estimation | [![GitHub](https://img.shields.io/github/stars/bymaths/probabilistic_triangulation?style=flat)](https://github.com/bymaths/probabilistic_triangulation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Probabilistic_Triangulation_for_Uncalibrated_Multi-View_3D_Human_Pose_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.04756-b31b1b.svg)](https://arxiv.org/abs/2309.04756) | :heavy_minus_sign: |
| DiffPose: SpatioTemporal Diffusion Model for Video-Based Human Pose Estimation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_DiffPose_SpatioTemporal_Diffusion_Model_for_Video-Based_Human_Pose_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.16687-b31b1b.svg)](https://arxiv.org/abs/2307.16687) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TC1szijh2aw) |
| Reconstructing Groups of People with Hypergraph Relational Reasoning | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.yangangwang.com/papers/iccv2023-grouprec/HUANG-GROUPREC-2023-07.html) <br /> [![GitHub](https://img.shields.io/github/stars/boycehbz/GroupRec?style=flat)](https://github.com/boycehbz/GroupRec) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Reconstructing_Groups_of_People_with_Hypergraph_Relational_Reasoning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.15844-b31b1b.svg)](https://arxiv.org/abs/2308.15844) | :heavy_minus_sign: |
| MixSynthFormer: A Transformer Encoder-Like Structure with Mixed Synthetic Self-Attention for Efficient Human Pose Estimation | [![GitHub](https://img.shields.io/github/stars/ireneesun/MixSynthFormer?style=flat)](https://github.com/ireneesun/MixSynthFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_MixSynthFormer_A_Transformer_Encoder-like_Structure_with_Mixed_Synthetic_Self-attention_for_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8hkw3H2dlqc) |
| Dynamic Hyperbolic Attention Network for Fine Hand-Object Reconstruction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Leng_Dynamic_Hyperbolic_Attention_Network_for_Fine_Hand-object_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02965-b31b1b.svg)](https://arxiv.org/abs/2309.02965) | :heavy_minus_sign: |
| Human from Blur: Human Pose Tracking from Blurry Images | [![GitHub](https://img.shields.io/github/stars/rozumden/HumanFromBlur?style=flat)](https://github.com/rozumden/HumanFromBlur) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Human_from_Blur_Human_Pose_Tracking_from_Blurry_Images_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17209-b31b1b.svg)](https://arxiv.org/abs/2303.17209) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=i7Mr5gIrvXg) |
| AG3D: Learning to Generate 3D Avatars from 2D Image Collections | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zj-dong.github.io/AG3D/) <br /> [![GitHub](https://img.shields.io/github/stars/zj-dong/AG3D?style=flat)](https://github.com/zj-dong/AG3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_AG3D_Learning_to_Generate_3D_Avatars_from_2D_Image_Collections_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.02312-b31b1b.svg)](https://arxiv.org/abs/2305.02312) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=niP1YhJXEBE) |
| InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sirui-xu.github.io/InterDiff/) <br /> [![GitHub](https://img.shields.io/github/stars/Sirui-Xu/InterDiff?style=flat)](https://github.com/Sirui-Xu/InterDiff) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_InterDiff_Generating_3D_Human-Object_Interactions_with_Physics-Informed_Diffusion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.16905-b31b1b.svg)](https://arxiv.org/abs/2308.16905) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ako1n9HEGBo) |
| SEFD: Learning to Distill Complex Pose and Occlusion | [![GitHub](https://img.shields.io/github/stars/YangChangHee/ICCV2023_SEFD_RELEASE?style=flat)](https://github.com/YangChangHee/ICCV2023_SEFD_RELEASE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SEFD_Learning_to_Distill_Complex_Pose_and_Occlusion_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| 3D Human Mesh Recovery with Sequentially Global Rotation Estimation | [![GitHub](https://img.shields.io/github/stars/kennethwdk/SGRE?style=flat)](https://github.com/kennethwdk/SGRE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_3D_Human_Mesh_Recovery_with_Sequentially_Global_Rotation_Estimation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kasvii.github.io/PMCE/) <br /> [![GitHub](https://img.shields.io/github/stars/kasvii/PMCE?style=flat)](https://github.com/kasvii/PMCE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/You_Co-Evolution_of_Pose_and_Mesh_for_3D_Human_Body_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10305-b31b1b.svg)](https://arxiv.org/abs/2308.10305) | :heavy_minus_sign: |
| PHRIT: Parametric Hand Representation with Implicit Template | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_PHRIT_Parametric_Hand_Representation_with_Implicit_Template_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.14916-b31b1b.svg)](https://arxiv.org/abs/2309.14916) | :heavy_minus_sign: |
| HopFIR: Hop-Wise GraphFormer with Intragroup Joint Refinement for 3D Human Pose Estimation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_HopFIR_Hop-wise_GraphFormer_with_Intragroup_Joint_Refinement_for_3D_Human_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14581-b31b1b.svg)](https://arxiv.org/abs/2302.14581) | :heavy_minus_sign: |
| Prior-Guided Source-Free Domain Adaptation for Human Pose Estimation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Raychaudhuri_Prior-guided_Source-free_Domain_Adaptation_for_Human_Pose_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13954-b31b1b.svg)](https://arxiv.org/abs/2308.13954) | :heavy_minus_sign: |
| Cloth2Body: Generating 3D Human Body Mesh from 2D Clothing | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_Cloth2Body_Generating_3D_Human_Body_Mesh_from_2D_Clothing_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.16189-b31b1b.svg)](https://arxiv.org/abs/2309.16189) | :heavy_minus_sign: |
| PoseFix: Correcting 3D Human Poses with Natural Language | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://europe.naverlabs.com/research/computer-vision/posefix/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Delmas_PoseFix_Correcting_3D_Human_Poses_with_Natural_Language_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08480-b31b1b.svg)](https://arxiv.org/abs/2309.08480) | :heavy_minus_sign: |
| Group Pose: A Simple Baseline for End-to-End Multi-Person Pose Estimation | [![GitHub](https://img.shields.io/github/stars/Michel-liu/GroupPose?style=flat)](https://github.com/Michel-liu/GroupPose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Group_Pose_A_Simple_Baseline_for_End-to-End_Multi-Person_Pose_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07313-b31b1b.svg)](https://arxiv.org/abs/2308.07313) | :heavy_minus_sign: |
| Make-an-Animation: Large-Scale Text-Conditional 3D Human Motion Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://azadis.github.io/make-an-animation/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.09662-b31b1b.svg)](https://arxiv.org/abs/2305.09662) | :heavy_minus_sign: |
| NSF: Neural Surface Fields for Human Modeling from Monocular Depth | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://yuxuan-xue.com/nsf/) <br /> [![GitHub](https://img.shields.io/github/stars/YuxuanSnow/NeuralSurfaceField?style=flat)](https://github.com/YuxuanSnow/NeuralSurfaceField) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xue_NSF_Neural_Surface_Fields_for_Human_Modeling_from_Monocular_Depth_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14847-b31b1b.svg)](https://arxiv.org/abs/2308.14847) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iVPYQwsNTZM) |
| Hierarchical Generation of Human-Object Interactions with Diffusion Probabilistic Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zju3dv.github.io/hghoi/) <br /> [![GitHub](https://img.shields.io/github/stars/zju3dv/hghoi?style=flat)](https://github.com/zju3dv/hghoi) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pi_Hierarchical_Generation_of_Human-Object_Interactions_with_Diffusion_Probabilistic_Models_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Dynamic Mesh Recovery from Partial Point Cloud Sequence | [![GitHub](https://img.shields.io/github/stars/hojunJang17/DynamicMeshRecovery?style=flat)](https://github.com/hojunJang17/DynamicMeshRecovery) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Dynamic_Mesh_Recovery_from_Partial_Point_Cloud_Sequence_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OgineYrkgRE) |
| MotionBERT: A Unified Perspective on Learning Human Motion Representations | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://motionbert.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/Walter0807/MotionBERT?style=flat)](https://github.com/Walter0807/MotionBERT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_MotionBERT_A_Unified_Perspective_on_Learning_Human_Motion_Representations_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.06551-b31b1b.svg)](https://arxiv.org/abs/2210.06551) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=slSPQ9hNLjM) |
| Novel-View Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://iscas3dv.github.io/HO-NeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/iscas3dv/HO-NeRF?style=flat)](https://github.com/iscas3dv/HO-NeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Novel-View_Synthesis_and_Pose_Estimation_for_Hand-Object_Interaction_from_Sparse_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11198-b31b1b.svg)](https://arxiv.org/abs/2308.11198) | :heavy_minus_sign: |
| OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision | [![GitHub](https://img.shields.io/github/stars/DeepWiSe888/OCHID-Fi?style=flat)](https://github.com/DeepWiSe888/OCHID-Fi) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_OCHID-Fi_Occlusion-Robust_Hand_Pose_Estimation_in_3D_via_RF-Vision_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10146-b31b1b.svg)](https://arxiv.org/abs/2308.10146) | :heavy_minus_sign: |
| Neural Interactive Keypoint Detection | [![GitHub](https://img.shields.io/github/stars/IDEA-Research/Click-Pose?style=flat)](https://github.com/IDEA-Research/Click-Pose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Neural_Interactive_Keypoint_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10174-b31b1b.svg)](https://arxiv.org/abs/2308.10174) | :heavy_minus_sign: |
| Plausible Uncertainties for Human Pose Regression | [![GitHub](https://img.shields.io/github/stars/biggzlar/plausible-uncertainties?style=flat)](https://github.com/biggzlar/plausible-uncertainties) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bramlage_Plausible_Uncertainties_for_Human_Pose_Regression_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mMEeU1Zm3iY) |
| TORE: Token Reduction for Efficient Human Mesh Recovery with Transformer | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://frank-zy-dou.github.io/projects/Tore/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/Frank-ZY-Dou/TORE?style=flat)](https://github.com/Frank-ZY-Dou/TORE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dou_TORE_Token_Reduction_for_Efficient_Human_Mesh_Recovery_with_Transformer_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.10705-b31b1b.svg)](https://arxiv.org/abs/2211.10705) | :heavy_minus_sign: |
| Weakly-Supervised 3D Pose Transfer with Keypoints | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jinnan-chen.github.io/ws3dpt/) <br /> [![GitHub](https://img.shields.io/github/stars/jinnan-chen/3D-Pose-Transfer?style=flat)](https://github.com/jinnan-chen/3D-Pose-Transfer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Weakly-supervised_3D_Pose_Transfer_with_Keypoints_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13459-b31b1b.svg)](https://arxiv.org/abs/2307.13459) | :heavy_minus_sign: |
