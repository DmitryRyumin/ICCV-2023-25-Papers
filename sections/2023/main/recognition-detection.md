# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/deep-learning-architectures-and-techniques.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/image-and-video-synthesis.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Recognition: Detection

![Section Papers](https://img.shields.io/badge/Section%20Papers-73-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-58-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-50-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Random Boxes are Open-World Object Detectors | [![GitHub](https://img.shields.io/github/stars/scuwyh2000/RandBox?style=flat)](https://github.com/scuwyh2000/RandBox) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Random_Boxes_Are_Open-world_Object_Detectors_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08249-b31b1b.svg)](https://arxiv.org/abs/2307.08249) | :heavy_minus_sign: |
| Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection | [![GitHub](https://img.shields.io/github/stars/hustvl/MIMDet?style=flat)](https://github.com/hustvl/MIMDet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2204.02964-b31b1b.svg)](https://arxiv.org/abs/2204.02964) | :heavy_minus_sign: |
| CoIn: Contrastive Instance Feature Mining for Outdoor 3D Object Detection with Very Limited Annotations | [![GitHub](https://img.shields.io/github/stars/xmuqimingxia/CoIn?style=flat)](https://github.com/xmuqimingxia/CoIn) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> | :heavy_minus_sign: |
| A Dynamic Dual-Processing Object Detection Framework Inspired by the Brain's Recognition Mechanism | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Dynamic_Dual-Processing_Object_Detection_Framework_Inspired_by_the_Brains_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Anchor-Intermediate Detector: Decoupling and Coupling Bounding Boxes for Accurate Object Detection | [![GitHub](https://img.shields.io/github/stars/YilongLv/AID?style=flat)](https://github.com/YilongLv/AID) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lv_Anchor-Intermediate_Detector_Decoupling_and_Coupling_Bounding_Boxes_for_Accurate_Object_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.05666-b31b1b.svg)](https://arxiv.org/abs/2310.05666) | :heavy_minus_sign: |
| Inter-Realization Channels: Unsupervised Anomaly Detection Beyond One-Class Classification | [![GitHub](https://img.shields.io/github/stars/DeclanMcIntosh/InReaCh?style=flat)](https://github.com/DeclanMcIntosh/InReaCh) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/McIntosh_Inter-Realization_Channels_Unsupervised_Anomaly_Detection_Beyond_One-Class_Classification_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Deep Equilibrium Object Detection | [![GitHub](https://img.shields.io/github/stars/MCG-NJU/DEQDet?style=flat)](https://github.com/MCG-NJU/DEQDet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Equilibrium_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09564-b31b1b.svg)](https://arxiv.org/abs/2308.09564) | :heavy_minus_sign: |
| RecursiveDet: End-to-End Region-based Recursive Object Detection | [![GitHub](https://img.shields.io/github/stars/bravezzzzzz/RecursiveDet?style=flat)](https://github.com/bravezzzzzz/RecursiveDet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_RecursiveDet_End-to-End_Region-Based_Recursive_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13619-b31b1b.svg)](https://arxiv.org/abs/2307.13619) | :heavy_minus_sign: |
| Small Object Detection via Coarse-to-Fine Proposal Generation and Imitation Learning | [![GitHub](https://img.shields.io/github/stars/shaunyuan22/CFINet?style=flat)](https://github.com/shaunyuan22/CFINet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Small_Object_Detection_via_Coarse-to-fine_Proposal_Generation_and_Imitation_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09534-b31b1b.svg)](https://arxiv.org/abs/2308.09534) | :heavy_minus_sign: |
| ASAG: Building Strong One-Decoder-Layer Sparse Detectors via Adaptive Sparse Anchor Generation | [![GitHub](https://img.shields.io/github/stars/iSEE-Laboratory/ASAG?style=flat)](https://github.com/iSEE-Laboratory/ASAG) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_ASAG_Building_Strong_One-Decoder-Layer_Sparse_Detectors_via_Adaptive_Sparse_Anchor_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09242-b31b1b.svg)](https://arxiv.org/abs/2308.09242) | :heavy_minus_sign: |
| COCO-O: A Benchmark for Object Detectors under Natural Distribution Shifts | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://github.com/alibaba/easyrobust/tree/main/benchmarks/coco_o) <br /> [![GitHub](https://img.shields.io/github/stars/alibaba/easyrobust?style=flat)](https://github.com/alibaba/easyrobust) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12730-b31b1b.svg)](https://arxiv.org/abs/2307.12730) | :heavy_minus_sign: |
| Generative Prompt Model for Weakly Supervised Object Localization | [![GitHub](https://img.shields.io/github/stars/callsys/GenPromp?style=flat)](https://github.com/callsys/GenPromp) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Generative_Prompt_Model_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09756-b31b1b.svg)](https://arxiv.org/abs/2307.09756) | :heavy_minus_sign: |
| UniKD: Universal Knowledge Distillation for Mimicking Homogeneous or Heterogeneous Object Detectors | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_UniKD_Universal_Knowledge_Distillation_for_Mimicking_Homogeneous_or_Heterogeneous_Object_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| PNI: Industrial Anomaly Detection using Position and Neighborhood Information | [![GitHub](https://img.shields.io/github/stars/wogur110/PNI_Anomaly_Detection?style=flat)](https://github.com/wogur110/PNI_Anomaly_Detection) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bae_PNI__Industrial_Anomaly_Detection_using_Position_and_Neighborhood_Information_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12634-b31b1b.svg)](https://arxiv.org/abs/2211.12634) | :heavy_minus_sign: |
| Masked Autoencoders are Stronger Knowledge Distillers | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_Masked_Autoencoders_Are_Stronger_Knowledge_Distillers_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| GPA-3D: Geometry-Aware Prototype Alignment for Unsupervised Domain Adaptive 3D Object Detection from Point Clouds | [![GitHub](https://img.shields.io/github/stars/Liz66666/GPA3D?style=flat)](https://github.com/Liz66666/GPA3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_GPA-3D_Geometry-aware_Prototype_Alignment_for_Unsupervised_Domain_Adaptive_3D_Object_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.08140-b31b1b.svg)](https://arxiv.org/abs/2308.08140) | :heavy_minus_sign: |
| ADNet: Lane Shape Prediction via Anchor Decomposition | [![GitHub](https://img.shields.io/github/stars/Sephirex-X/ADNet?style=flat)](https://github.com/Sephirex-X/ADNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_ADNet_Lane_Shape_Prediction_via_Anchor_Decomposition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10481-b31b1b.svg)](https://arxiv.org/abs/2308.10481) | :heavy_minus_sign: |
| Periodically Exchange Teacher-Student for Source-Free Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Periodically_Exchange_Teacher-Student_for_Source-Free_Object_Detection_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Towards Fair and Comprehensive Comparisons for Image-based 3D Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Towards_Fair_and_Comprehensive_Comparisons_for_Image-Based_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.05447-b31b1b.svg)](https://arxiv.org/abs/2310.05447) | :heavy_minus_sign: |
| Monocular 3D Object Detection with Bounding Box Denoising in 3D by Perceiver | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xianpeng919.github.io/monoxiver/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Monocular_3D_Object_Detection_with_Bounding_Box_Denoising_in_3D_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01289-b31b1b.svg)](https://arxiv.org/abs/2304.01289) | :heavy_minus_sign: |
| Template-Guided Hierarchical Feature Restoration for Anomaly Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Template-guided_Hierarchical_Feature_Restoration_for_Anomaly_Detection_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| ALWOD: Active Learning for Weakly-Supervised Object Detection | [![GitHub](https://img.shields.io/github/stars/seqam-lab/ALWOD?style=flat)](https://github.com/seqam-lab/ALWOD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ALWOD_Active_Learning_for_Weakly-Supervised_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.07914-b31b1b.svg)](https://arxiv.org/abs/2309.07914) | :heavy_minus_sign: |
| ProtoFL: Unsupervised Federated Learning via Prototypical Distillation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_ProtoFL_Unsupervised_Federated_Learning_via_Prototypical_Distillation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12450-b31b1b.svg)](https://arxiv.org/abs/2307.12450) | :heavy_minus_sign: |
| Efficient Adaptive Human-Object Interaction Detection with Concept-Guided Memory | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ltttpku.github.io/ADA-CM/) <br /> [![GitHub](https://img.shields.io/github/stars/ltttpku/ADA-CM?style=flat)](https://github.com/ltttpku/ADA-CM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Efficient_Adaptive_Human-Object_Interaction_Detection_with_Concept-guided_Memory_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03696-b31b1b.svg)](https://arxiv.org/abs/2309.03696) | :heavy_minus_sign: |
| Detection Transformer with Stable Matching | [![GitHub](https://img.shields.io/github/stars/IDEA-Research/Stable-DINO?style=flat)](https://github.com/IDEA-Research/Stable-DINO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Detection_Transformer_with_Stable_Matching_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04742-b31b1b.svg)](https://arxiv.org/abs/2304.04742) | :heavy_minus_sign: |
| Distilling DETR with Visual-Linguistic Knowledge for Open-Vocabulary Object Detection | [![GitHub](https://img.shields.io/github/stars/hikvision-research/opera?style=flat)](https://github.com/hikvision-research/opera) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilling_DETR_with_Visual-Linguistic_Knowledge_for_Open-Vocabulary_Object_Detection_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Anomaly Detection Under Distribution Shift | [![GitHub](https://img.shields.io/github/stars/mala-lab/ADShift?style=flat)](https://github.com/mala-lab/ADShift) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Anomaly_Detection_Under_Distribution_Shift_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13845-b31b1b.svg)](https://arxiv.org/abs/2303.13845) | :heavy_minus_sign: |
| Detecting Objects with Context-Likelihood Graphs and Graph Refinement | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bhowmik_Detecting_Objects_with_Context-Likelihood_Graphs_and_Graph_Refinement_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.12395-b31b1b.svg)](https://arxiv.org/abs/2212.12395) | :heavy_minus_sign: |
| Unsupervised Object Localization with Representer Point Selection | [![GitHub](https://img.shields.io/github/stars/yeonghwansong/UOLwRPS?style=flat)](https://github.com/yeonghwansong/UOLwRPS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Unsupervised_Object_Localization_with_Representer_Point_Selection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.04172-b31b1b.svg)](https://arxiv.org/abs/2309.04172) | :heavy_minus_sign: |
| DETR does not Need Multi-Scale or Locality Design | [![GitHub](https://img.shields.io/github/stars/impiga/Plain-DETR?style=flat)](https://github.com/impiga/Plain-DETR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_DETR_Does_Not_Need_Multi-Scale_or_Locality_Design_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.01904-b31b1b.svg)](https://arxiv.org/abs/2308.01904) | :heavy_minus_sign: |
| Deep Directly-Trained Spiking Neural Networks for Object Detection | [![GitHub](https://img.shields.io/github/stars/BICLab/EMS-YOLO?style=flat)](https://github.com/BICLab/EMS-YOLO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Deep_Directly-Trained_Spiking_Neural_Networks_for_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11411-b31b1b.svg)](https://arxiv.org/abs/2307.11411) | :heavy_minus_sign: |
| GACE: Geometry Aware Confidence Enhancement for Black-Box 3D Object Detectors on LiDAR-Data | [![GitHub](https://img.shields.io/github/stars/dschinagl/gace?style=flat)](https://github.com/dschinagl/gace) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Schinagl_GACE_Geometry_Aware_Confidence_Enhancement_for_Black-Box_3D_Object_Detectors_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.20319-b31b1b.svg)](https://arxiv.org/abs/2310.20319) | :heavy_minus_sign: |
| StageInteractor: Query-based Object Detector with Cross-Stage Interaction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Teng_StageInteractor_Query-based_Object_Detector_with_Cross-stage_Interaction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04978-b31b1b.svg)](https://arxiv.org/abs/2304.04978) | :heavy_minus_sign: |
| Adaptive Rotated Convolution for Rotated Object Detection | [![GitHub](https://img.shields.io/github/stars/LeapLabTHU/ARC?style=flat)](https://github.com/LeapLabTHU/ARC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pu_Adaptive_Rotated_Convolution_for_Rotated_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07820-b31b1b.svg)](https://arxiv.org/abs/2303.07820) | :heavy_minus_sign: |
| Decoupled DETR: Spatially Disentangling Localization and Classification for Improved End-to-End Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Decoupled_DETR_Spatially_Disentangling_Localization_and_Classification_for_Improved_End-to-End_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.15955-b31b1b.svg)](https://arxiv.org/abs/2310.15955) | :heavy_minus_sign: |
| Exploring Transformers for Open-World Instance Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Transformers_for_Open-world_Instance_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04206-b31b1b.svg)](https://arxiv.org/abs/2308.04206) | :heavy_minus_sign: |
| DDG-Net: Discriminability-Driven Graph Network for Weakly-Supervised Temporal Action Localization | [![GitHub](https://img.shields.io/github/stars/XiaojunTang22/ICCV2023-DDGNet?style=flat)](https://github.com/XiaojunTang22/ICCV2023-DDGNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_DDG-Net_Discriminability-Driven_Graph_Network_for_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.16415-b31b1b.svg)](https://arxiv.org/abs/2307.16415) | :heavy_minus_sign: |
| Group DETR: Fast DETR Training with Group-Wise One-to-Many Assignment | [![GitHub](https://img.shields.io/github/stars/Atten4Vis/GroupDETR?style=flat)](https://github.com/Atten4Vis/GroupDETR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Group_DETR_Fast_DETR_Training_with_Group-Wise_One-to-Many_Assignment_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2207.13085-b31b1b.svg)](https://arxiv.org/abs/2207.13085) | :heavy_minus_sign: |
| Category-Aware Allocation Transformer for Weakly Supervised Object Localization | [![GitHub](https://img.shields.io/github/stars/zhiweichen0012/CATR?style=flat)](https://github.com/zhiweichen0012/CATR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Category-aware_Allocation_Transformer_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| The Devil is in the Crack Orientation: A New Perspective for Crack Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_The_Devil_is_in_the_Crack_Orientation_A_New_Perspective_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Clusterformer: Cluster-based Transformer for 3D Object Detection in Point Clouds | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pei_Clusterformer_Cluster-based_Transformer_for_3D_Object_Detection_in_Point_Clouds_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Less is more: Focus Attention for Efficient DETR | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://github.com/huawei-noah/noah-research/tree/master/Focus-DETR) <br /> [![Gitee Page](https://img.shields.io/badge/Gitee-Page-303643.svg)](https://gitee.com/mindspore/models/tree/master/research/cv/Focus-DETR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12612-b31b1b.svg)](https://arxiv.org/abs/2307.12612) | :heavy_minus_sign: |
| DFA3D: 3D Deformable Attention for 2D-to-3D Feature Lifting | [![GitHub](https://img.shields.io/github/stars/IDEA-Research/3D-deformable-attention?style=flat)](https://github.com/IDEA-Research/3D-deformable-attention) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DFA3D_3D_Deformable_Attention_For_2D-to-3D_Feature_Lifting_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12972-b31b1b.svg)](https://arxiv.org/abs/2307.12972) | :heavy_minus_sign: |
| Multi-Label Self-Supervised Learning with Scene Images | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Multi-Label_Self-Supervised_Learning_with_Scene_Images_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03286-b31b1b.svg)](https://arxiv.org/abs/2308.03286) | :heavy_minus_sign: |
| Cascade-DETR: Delving into High-Quality Universal Object Detection | [![GitHub](https://img.shields.io/github/stars/SysCV/cascade-detr?style=flat)](https://github.com/SysCV/cascade-detr) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Cascade-DETR_Delving_into_High-Quality_Universal_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11035-b31b1b.svg)](https://arxiv.org/abs/2307.11035) | :heavy_minus_sign: |
| Representation Disparity-Aware Distillation for 3D Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Representation_Disparity-aware_Distillation_for_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10308-b31b1b.svg)](https://arxiv.org/abs/2308.10308) | :heavy_minus_sign: |
| FeatEnHancer: Enhancing Hierarchical Features for Object Detection and Beyond Under Low-Light Vision | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://khurramhashmi.github.io/FeatEnHancer/) <br /> [![GitHub](https://img.shields.io/github/stars/khurramHashmi/FeatEnHancer?style=flat)](https://github.com/khurramHashmi/FeatEnHancer)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hashmi_FeatEnHancer_Enhancing_Hierarchical_Features_for_Object_Detection_and_Beyond_Under_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03594-b31b1b.svg)](https://arxiv.org/abs/2308.03594) | :heavy_minus_sign: |
| DetZero: Rethinking Offboard 3D Object Detection with Long-Term Sequential Point Clouds | [![GitHub](https://img.shields.io/github/stars/PJLab-ADG/DetZero?style=flat)](https://github.com/PJLab-ADG/DetZero) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_DetZero_Rethinking_Offboard_3D_Object_Detection_with_Long-term_Sequential_Point_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.06023-b31b1b.svg)](https://arxiv.org/abs/2306.06023) | :heavy_minus_sign: |
| DETRs with Collaborative Hybrid Assignments Training | [![GitHub](https://img.shields.io/github/stars/Sense-X/Co-DETR?style=flat)](https://github.com/Sense-X/Co-DETR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12860-b31b1b.svg)](https://arxiv.org/abs/2211.12860) | :heavy_minus_sign: |
| Open-Vocabulary Object Detection with an Open Corpus | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Open-Vocabulary_Object_Detection_With_an_Open_Corpus_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| SparseDet: Improving Sparsely Annotated Object Detection with Pseudo-Positive Mining | [![GitHub](https://img.shields.io/github/stars/saksham-s/SparseDet?style=flat)](https://github.com/saksham-s/SparseDet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Suri_SparseDet_Improving_Sparsely_Annotated_Object_Detection_with_Pseudo-positive_Mining_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2201.04620-b31b1b.svg)](https://arxiv.org/abs/2201.04620) | :heavy_minus_sign: |
| Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model | [![GitHub](https://img.shields.io/github/stars/Loco-Roco/DiffAD?style=flat)](https://github.com/Loco-Roco/DiffAD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Unsupervised_Surface_Anomaly_Detection_with_Diffusion_Probabilistic_Model_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| UniTR: A Unified and Efficient Multi-Modal Transformer for Bird's-Eye-View Representation | [![GitHub](https://img.shields.io/github/stars/Haiyang-W/UniTR?style=flat)](https://github.com/Haiyang-W/UniTR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UniTR_A_Unified_and_Efficient_Multi-Modal_Transformer_for_Birds-Eye-View_Representation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07732-b31b1b.svg)](https://arxiv.org/abs/2308.07732) | :heavy_minus_sign: |
| Focus the Discrepancy: Intra- and Inter-Correlation Learning for Image Anomaly Detection | [![GitHub](https://img.shields.io/github/stars/xcyao00/FOD?style=flat)](https://github.com/xcyao00/FOD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Focus_the_Discrepancy_Intra-_and_Inter-Correlation_Learning_for_Image_Anomaly_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.02983-b31b1b.svg)](https://arxiv.org/abs/2308.02983) | :heavy_minus_sign: |
| MonoNeRD: NeRF-Like Representations for Monocular 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/cskkxjk/MonoNeRD?style=flat)](https://github.com/cskkxjk/MonoNeRD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MonoNeRD_NeRF-like_Representations_for_Monocular_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09421-b31b1b.svg)](https://arxiv.org/abs/2308.09421) | :heavy_minus_sign: |
| Integrally Migrating Pre-Trained Transformer Encoder-Decoders for Visual Object Detection | [![GitHub](https://img.shields.io/github/stars/LiewFeng/imTED?style=flat)](https://github.com/LiewFeng/imTED) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Integrally_Migrating_Pre-trained_Transformer_Encoder-decoders_for_Visual_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2205.09613-b31b1b.svg)](https://arxiv.org/abs/2205.09613) | :heavy_minus_sign: |
| Generating Dynamic Kernels via Transformers for Lane Detection | [![GitHub](https://img.shields.io/github/stars/czyczyyzc/CondLSTR?style=flat)](https://github.com/czyczyyzc/CondLSTR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Generating_Dynamic_Kernels_via_Transformers_for_Lane_Detection_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Meta-ZSDETR: Zero-Shot DETR with Meta-Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Meta-ZSDETR_Zero-shot_DETR_with_Meta-learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09540-b31b1b.svg)](https://arxiv.org/abs/2308.09540) | :heavy_minus_sign: |
| Spatial Self-Distillation for Object Detection with Inaccurate Bounding Boxes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det) <br /> [![GitHub](https://img.shields.io/github/stars/ucas-vg/PointTinyBenchmark?style=flat)](https://github.com/ucas-vg/PointTinyBenchmark) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial_Self-Distillation_for_Object_Detection_with_Inaccurate_Bounding_Boxes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12101-b31b1b.svg)](https://arxiv.org/abs/2307.12101) | :heavy_minus_sign: |
| AlignDet: Aligning Pre-Training and Fine-Tuning in Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://liming-ai.github.io/AlignDet) <br /> [![GitHub](https://img.shields.io/github/stars/liming-ai/AlignDet?style=flat)](https://github.com/liming-ai/AlignDet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AlignDet_Aligning_Pre-training_and_Fine-tuning_in_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11077-b31b1b.svg)](https://arxiv.org/abs/2307.11077) | :heavy_minus_sign: |
| MULLER: Multilayer Laplacian Resizer for Vision | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://github.com/google-research/google-research/tree/master/muller) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_MULLER_Multilayer_Laplacian_Resizer_for_Vision_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02859-b31b1b.svg)](https://arxiv.org/abs/2304.02859) | :heavy_minus_sign: |
| Unilaterally Aggregated Contrastive Learning with Hierarchical Augmentation for Anomaly Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unilaterally_Aggregated_Contrastive_Learning_with_Hierarchical_Augmentation_for_Anomaly_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10155-b31b1b.svg)](https://arxiv.org/abs/2308.10155) | :heavy_minus_sign: |
| DETRDistill: A Universal Knowledge Distillation Framework for DETR-Families | [![GitHub](https://img.shields.io/github/stars/BIVLab-USTC/DETRDistill?style=flat)](https://github.com/BIVLab-USTC/DETRDistill) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_DETRDistill_A_Universal_Knowledge_Distillation_Framework_for_DETR-families_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.10156-b31b1b.svg)](https://arxiv.org/abs/2211.10156) | :heavy_minus_sign: |
| Delving into Motion-Aware Matching for Monocular 3D Object Tracking | [![GitHub](https://img.shields.io/github/stars/kuanchihhuang/MoMA-M3T?style=flat)](https://github.com/kuanchihhuang/MoMA-M3T) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Delving_into_Motion-Aware_Matching_for_Monocular_3D_Object_Tracking_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11607-b31b1b.svg)](https://arxiv.org/abs/2308.11607) | :heavy_minus_sign: |
| FB-BEV: BEV Representation from Forward-Backward View Transformations | [![GitHub](https://img.shields.io/github/stars/NVlabs/FB-BEV?style=flat)](https://github.com/NVlabs/FB-BEV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_FB-BEV_BEV_Representation_from_Forward-Backward_View_Transformations_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.02236-b31b1b.svg)](https://arxiv.org/abs/2308.02236) | :heavy_minus_sign: |
| Learning from Noisy Data for Semi-Supervised 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/zehuichen123/NoiseDet?style=flat)](https://github.com/zehuichen123/NoiseDet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Learning_from_Noisy_Data_for_Semi-Supervised_3D_Object_Detection_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Boosting Long-Tailed Object Detection via Step-Wise Learning on Smooth-Tail Data | [![GitHub](https://img.shields.io/github/stars/dongnana777/Long-tailed-object-detection?style=flat)](https://github.com/dongnana777/Long-tailed-object-detection) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Boosting_Long-tailed_Object_Detection_via_Step-wise_Learning_on_Smooth-tail_Data_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.12833-b31b1b.svg)](https://arxiv.org/abs/2305.12833) | :heavy_minus_sign: |
| Objects do not Disappear: Video Object Detection by Single-Frame Object Location Anticipation | [![GitHub](https://img.shields.io/github/stars/L-KID/Video-object-detection-by-location-anticipation?style=flat)](https://github.com/L-KID/Video-object-detection-by-location-anticipation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Objects_Do_Not_Disappear_Video_Object_Detection_by_Single-Frame_Object_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04770-b31b1b.svg)](https://arxiv.org/abs/2308.04770) | :heavy_minus_sign: |
| Unified Visual Relationship Detection with Vision and Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://github.com/google-research/scenic/tree/main/scenic/projects/univrd) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Unified_Visual_Relationship_Detection_with_Vision_and_Language_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08998-b31b1b.svg)](https://arxiv.org/abs/2303.08998) | :heavy_minus_sign: |
| Universal Domain Adaptation via Compressive Attention Matching | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Universal_Domain_Adaptation_via_Compressive_Attention_Matching_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11862-b31b1b.svg)](https://arxiv.org/abs/2304.11862) | :heavy_minus_sign: |
| Unsupervised Domain Adaptive Detection with Network Stability Analysis | [![GitHub](https://img.shields.io/github/stars/tiankongzhang/NSA?style=flat)](https://github.com/tiankongzhang/NSA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Unsupervised_Domain_Adaptive_Detection_with_Network_Stability_Analysis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.08182-b31b1b.svg)](https://arxiv.org/abs/2308.08182) | :heavy_minus_sign: |
| ImGeoNet: Image-Induced Geometry-Aware Voxel Representation for Multi-View 3D Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ttaoretw.github.io/imgeonet/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_ImGeoNet_Image-induced_Geometry-aware_Voxel_Representation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09098-b31b1b.svg)](https://arxiv.org/abs/2308.09098) | :heavy_minus_sign: |
| Cyclic-Bootstrap Labeling for Weakly Supervised Object Detection | [![GitHub](https://img.shields.io/github/stars/Yinyf0804/WSOD-CBL?style=flat)](https://github.com/Yinyf0804/WSOD-CBL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Cyclic-Bootstrap_Labeling_for_Weakly_Supervised_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.05991-b31b1b.svg)](https://arxiv.org/abs/2308.05991) | :heavy_minus_sign: |
