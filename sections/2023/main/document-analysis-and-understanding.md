# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/machine-learning-other-than-deep-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/biometrics.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Document Analysis and Understanding

![Section Papers](https://img.shields.io/badge/Section%20Papers-13-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-12-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-9-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| A Benchmark for Chinese-English Scene Text Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/mjq11302010044/Real-CE?style=flat)](https://github.com/mjq11302010044/Real-CE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03262-b31b1b.svg)](https://arxiv.org/abs/2308.03262) | :heavy_minus_sign: |
| Vision Grid Transformer for Document Layout Analysis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/VGT) <br /> [![GitHub](https://img.shields.io/github/stars/AlibabaResearch/AdvancedLiterateMachinery?style=flat)](https://github.com/AlibabaResearch/AdvancedLiterateMachinery) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Da_Vision_Grid_Transformer_for_Document_Layout_Analysis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14978-b31b1b.svg)](https://arxiv.org/abs/2308.14978) | :heavy_minus_sign: |
| Self-Supervised Character-to-Character Distillation for Text Recognition | [![GitHub](https://img.shields.io/github/stars/TongkunGuan/CCD?style=flat)](https://github.com/TongkunGuan/CCD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_Self-Supervised_Character-to-Character_Distillation_for_Text_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.00288-b31b1b.svg)](https://arxiv.org/abs/2211.00288) | :heavy_minus_sign: |
| ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction | [![GitHub](https://img.shields.io/github/stars/MAEHCM/ICL-D3IE?style=flat)](https://github.com/MAEHCM/ICL-D3IE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/He_ICL-D3IE_In-Context_Learning_with_Diverse_Demonstrations_Updating_for_Document_Information_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05063-b31b1b.svg)](https://arxiv.org/abs/2303.05063) | :heavy_minus_sign: |
| ESTextSpotter: Towards Better Scene Text Spotting with Explicit Synergy in Transformer | [![GitHub](https://img.shields.io/github/stars/mxin262/ESTextSpotter?style=flat)](https://github.com/mxin262/ESTextSpotter) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ESTextSpotter_Towards_Better_Scene_Text_Spotting_with_Explicit_Synergy_in_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10147-b31b1b.svg)](https://arxiv.org/abs/2308.10147) | :heavy_minus_sign: |
| Few Shot Font Generation via Transferring Similarity Guided Global Style and Quantization Local Style | [![GitHub](https://img.shields.io/github/stars/awei669/VQ-Font?style=flat)](https://github.com/awei669/VQ-Font) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Few_Shot_Font_Generation_Via_Transferring_Similarity_Guided_Global_Style_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.00827-b31b1b.svg)](https://arxiv.org/abs/2309.00827) | :heavy_minus_sign: |
| Attention where it Matters: Rethinking Visual Document Understanding with Selective Region Concentration | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Attention_Where_It_Matters_Rethinking_Visual_Document_Understanding_with_Selective_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.01131-b31b1b.svg)](https://arxiv.org/abs/2309.01131) | :heavy_minus_sign: |
| Document Understanding Dataset and Evaluation (DUDE) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Landeghem_Document_Understanding_Dataset_and_Evaluation_DUDE_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.08455-b31b1b.svg)](https://arxiv.org/abs/2305.08455) | :heavy_minus_sign: |
| LISTER: Neighbor Decoding for Length-Insensitive Scene Text Recognition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/LISTER) <br /> [![GitHub](https://img.shields.io/github/stars/AlibabaResearch/AdvancedLiterateMachinery?style=flat)](https://github.com/AlibabaResearch/AdvancedLiterateMachinery) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LISTER_Neighbor_Decoding_for_Length-Insensitive_Scene_Text_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12774-b31b1b.svg)](https://arxiv.org/abs/2308.12774) | :heavy_minus_sign: |
| MolGrapher: Graph-based Visual Recognition of Chemical Structures | [![GitHub](https://img.shields.io/github/stars/DS4SD/MolGrapher?style=flat)](https://github.com/DS4SD/MolGrapher) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Morin_MolGrapher_Graph-based_Visual_Recognition_of_Chemical_Structures_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12234-b31b1b.svg)](https://arxiv.org/abs/2308.12234) | :heavy_minus_sign: |
| SCOB: Universal Text Understanding via Character-Wise Supervised Contrastive Learning with Online Text Rendering for Bridging Domain Gap | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_SCOB_Universal_Text_Understanding_via_Character-wise_Supervised_Contrastive_Learning_with_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.12382-b31b1b.svg)](https://arxiv.org/abs/2309.12382) | :heavy_minus_sign: |
| Foreground and Text-Lines Aware Document Image Rectification | [![GitHub](https://img.shields.io/github/stars/xiaomore/Document-Image-Dewarping?style=flat)](https://github.com/xiaomore/Document-Image-Dewarping) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Foreground_and_Text-lines_Aware_Document_Image_Rectification_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| DocTr: Document Transformer for Structured Information Extraction in Documents | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_DocTr_Document_Transformer_for_Structured_Information_Extraction_in_Documents_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.07929-b31b1b.svg)](https://arxiv.org/abs/2307.07929) | :heavy_minus_sign: |
