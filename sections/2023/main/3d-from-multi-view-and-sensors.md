# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/adversarial-attack-and-defense.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## 3D from Multi-View and Sensors

![Section Papers](https://img.shields.io/badge/Section%20Papers-173-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-136-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-110-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-37-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Multi-Modal Neural Radiance Field for Monocular Dense SLAM with a Light-Weight ToF Sensor | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zju3dv.github.io/tof_slam/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-Modal_Neural_Radiance_Field_for_Monocular_Dense_SLAM_with_a_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14383-b31b1b.svg)](https://arxiv.org/abs/2308.14383) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7aJvVG7OLLQ) |
| ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cy94.github.io/scannetpp/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yeshwanth_ScanNet_A_High-Fidelity_Dataset_of_3D_Indoor_Scenes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11417-b31b1b.svg)](https://arxiv.org/abs/2308.11417) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=E6P9e2r6M8I) |
| Translating Images to Road Network: A Non-Autoregressive Sequence-to-Sequence Approach | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Translating_Images_to_Road_Network_A_Non-Autoregressive_Sequence-to-Sequence_Approach_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Doppelgangers: Learning to Disambiguate Images of Similar Structures | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://doppelgangers-3d.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/RuojinCai/Doppelgangers?style=flat)](https://github.com/RuojinCai/Doppelgangers) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Doppelgangers_Learning_to_Disambiguate_Images_of_Similar_Structures_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02420-b31b1b.svg)](https://arxiv.org/abs/2309.02420) | :heavy_minus_sign: |
| EgoLoc: Revisiting 3D Object Localization from Egocentric Videos with Visual Queries | [![GitHub](https://img.shields.io/github/stars/Wayne-Mai/EgoLoc?style=flat)](https://github.com/Wayne-Mai/EgoLoc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.06969-b31b1b.svg)](https://arxiv.org/abs/2212.06969) | :heavy_minus_sign: |
| ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via an Indirect Recording Solution | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| EMR-MSF: Self-Supervised Recurrent Monocular Scene Flow Exploiting Ego-Motion Rigidity | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_EMR-MSF_Self-Supervised_Recurrent_Monocular_Scene_Flow_Exploiting_Ego-Motion_Rigidity_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| ENVIDR: Implicit Differentiable Renderer with Neural Environment Lighting | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nexuslrf.github.io/ENVIDR/) <br /> [![GitHub](https://img.shields.io/github/stars/nexuslrf/ENVIDR?style=flat)](https://github.com/nexuslrf/ENVIDR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_ENVIDR_Implicit_Differentiable_Renderer_with_Neural_Environment_Lighting_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13022-b31b1b.svg)](https://arxiv.org/abs/2303.13022) | [![Google Drive](https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white)](https://drive.google.com/file/d/18kU-IWVxboCG8SCGgrBA5JHC0JIgPCS8/view?t=17s) |
| Learning a more Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection | [![GitHub](https://img.shields.io/github/stars/junshengzhou/LevelSetUDF?style=flat)](https://github.com/junshengzhou/LevelSetUDF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_a_More_Continuous_Zero_Level_Set_in_Unsigned_Distance_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11441-b31b1b.svg)](https://arxiv.org/abs/2308.11441) | :heavy_minus_sign: |
| Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer with Mixture-of-View-Experts | [![GitHub](https://img.shields.io/github/stars/VITA-Group/GNT-MOVE?style=flat)](https://github.com/VITA-Group/GNT-MOVE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cong_Enhancing_NeRF_akin_to_Enhancing_LLMs_Generalizable_NeRF_Transformer_with_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11793-b31b1b.svg)](https://arxiv.org/abs/2308.11793) | :heavy_minus_sign: |
| MatrixCity: A Large-Scale City Dataset for City-Scale Neural Rendering and Beyond | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://city-super.github.io/matrixcity/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MatrixCity_A_Large-scale_City_Dataset_for_City-scale_Neural_Rendering_and_ICCV_2023_paper.pdf) <br /> [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://city-super.github.io/matrixcity/img/matrixcity_camera_ready.pdf) | :heavy_minus_sign: |
| R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.vis.xyz/pub/r3d3/) <br /> [![GitHub](https://img.shields.io/github/stars/SysCV/r3d3?style=flat)](https://github.com/SysCV/r3d3) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Schmied_R3D3_Dense_3D_Reconstruction_of_Dynamic_Scenes_from_Multiple_Cameras_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14713-b31b1b.svg)](https://arxiv.org/abs/2308.14713) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lkU0lDq9HHw) |
| ClimateNeRF: Extreme Weather Synthesis in Neural Radiance Field | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://climatenerf.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_ClimateNeRF_Extreme_Weather_Synthesis_in_Neural_Radiance_Field_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.13226-b31b1b.svg)](https://arxiv.org/abs/2211.13226) | :heavy_minus_sign: |
| Rendering Humans from Object-Occluded Monocular Videos | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cs.stanford.edu/~xtiange/projects/occnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/tiangexiang/OccNeRF?style=flat)](https://github.com/tiangexiang/OccNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Rendering_Humans_from_Object-Occluded_Monocular_Videos_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04622-b31b1b.svg)](https://arxiv.org/abs/2308.04622) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-LHyNdWGqTM) |
| AssetField: Assets Mining and Reconfiguration in Ground Feature Plane Representation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://city-super.github.io/assetfield/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiangli_AssetField_Assets_Mining_and_Reconfiguration_in_Ground_Feature_Plane_Representation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13953-b31b1b.svg)](https://arxiv.org/abs/2303.13953) | :heavy_minus_sign: |
| PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images | [![GitHub](https://img.shields.io/github/stars/megvii-research/PETR?style=flat)](https://github.com/megvii-research/PETR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PETRv2_A_Unified_Framework_for_3D_Perception_from_Multi-Camera_Images_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.01256-b31b1b.svg)](https://arxiv.org/abs/2206.01256) | :heavy_minus_sign: |
| MIMO-NeRF: Fast Neural Rendering with Multi-Input Multi-Output Neural Radiance Fields | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kaneko_MIMO-NeRF_Fast_Neural_Rendering_with_Multi-input_Multi-output_Neural_Radiance_Fields_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Adaptive Positional Encoding for Bundle-Adjusting Neural Radiance Fields | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Positional_Encoding_for_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| NeuS2: Fast Learning of Neural Implicit Surfaces for Multi-View Reconstruction | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://vcai.mpi-inf.mpg.de/projects/NeuS2/) <br /> [![GitHub](https://img.shields.io/github/stars/19reborn/NeuS2?style=flat)](https://github.com/19reborn/NeuS2) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_NeuS2_Fast_Learning_of_Neural_Implicit_Surfaces_for_Multi-view_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.05231-b31b1b.svg)](https://arxiv.org/abs/2212.05231) | :heavy_minus_sign: |
| Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition | [![GitHub](https://img.shields.io/github/stars/wqtwjt1996/SUM-L?style=flat)](https://github.com/wqtwjt1996/SUM-L) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_from_Semantic_Alignment_between_Unpaired_Multiviews_for_Egocentric_Video_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11489-b31b1b.svg)](https://arxiv.org/abs/2308.11489) | :heavy_minus_sign: |
| Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jing_Uncertainty_Guided_Adaptive_Warping_for_Robust_and_Efficient_Stereo_Matching_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.14071-b31b1b.svg)](https://arxiv.org/abs/2307.14071) | :heavy_minus_sign: |
| Compatibility of Fundamental Matrices for Complete Viewing Graphs | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bratelund_Compatibility_of_Fundamental_Matrices_for_Complete_Viewing_Graphs_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10658-b31b1b.svg)](https://arxiv.org/abs/2303.10658) | :heavy_minus_sign: |
| ProtoTransfer: Cross-Modal Prototype Transfer for Point Cloud Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_ProtoTransfer_Cross-Modal_Prototype_Transfer_for_Point_Cloud_Segmentation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| SA-BEV: Generating Semantic-Aware Bird's-Eye-View Feature for Multi-View 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/mengtan00/SA-BEV?style=flat)](https://github.com/mengtan00/SA-BEV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SA-BEV_Generating_Semantic-Aware_Birds-Eye-View_Feature_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11477-b31b1b.svg)](https://arxiv.org/abs/2307.11477) | :heavy_minus_sign: |
| GraphAlign: Enhancing Accurate Feature Alignment by Graph matching for Multi-Modal 3D Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_GraphAlign_Enhancing_Accurate_Feature_Alignment_by_Graph_matching_for_Multi-Modal_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Tangent Sampson Error: Fast Approximate Two-View Reprojection Error for Central Camera Models | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Terekhov_Tangent_Sampson_Error_Fast_Approximate_Two-view_Reprojection_Error_for_Central_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/valeoai/WaffleIron?style=flat)](https://github.com/valeoai/WaffleIron) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Puy_Using_a_Waffle_Iron_for_Automotive_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.10100-b31b1b.svg)](https://arxiv.org/abs/2301.10100) | :heavy_minus_sign: |
| Fast Globally Optimal Surface Normal Estimation from an Affine Correspondence | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hajder_Fast_Globally_Optimal_Surface_Normal_Estimation_from_an_Affine_Correspondence_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Preface: A Data-driven Volumetric Prior for Few-shot Ultra High-resolution Face Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://syntec-research.github.io/Preface/) <br /> [![GitHub](https://img.shields.io/github/stars/syntec-research/Preface?style=flat)](https://github.com/syntec-research/Preface) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Buhler_Preface_A_Data-driven_Volumetric_Prior_for_Few-shot_Ultra_High-resolution_Face_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oSprm3QTeLc) |
| Canonical Factors for Hybrid Neural Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://brentyi.github.io/tilted/) <br /> [![GitHub](https://img.shields.io/github/stars/brentyi/tilted?style=flat)](https://github.com/brentyi/tilted) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Canonical_Factors_for_Hybrid_Neural_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.15461-b31b1b.svg)](https://arxiv.org/abs/2308.15461) | :heavy_minus_sign: |
| Center-based Decoupled Point-Cloud Registration for 6D Object Pose Estimation | [![GitHub](https://img.shields.io/github/stars/Jiang-HB/CenterReg?style=flat)](https://github.com/Jiang-HB/CenterReg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Center-Based_Decoupled_Point-cloud_Registration_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Deep Geometry-Aware Camera Self-Calibration from Video | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hagemann_Deep_Geometry-Aware_Camera_Self-Calibration_from_Video_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| V-FUSE: Volumetric Depth Map Fusion with Long-Range Constraints | [![GitHub](https://img.shields.io/github/stars/nburgdorfer/V-FUSE?style=flat)](https://github.com/nburgdorfer/V-FUSE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Burgdorfer_V-FUSE_Volumetric_Depth_Map_Fusion_with_Long-Range_Constraints_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.08715-b31b1b.svg)](https://arxiv.org/abs/2308.08715) | :heavy_minus_sign: |
| Consistent Depth Prediction for Transparent Object Reconstruction from RGB-D Camera | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Consistent_Depth_Prediction_for_Transparent_Object_Reconstruction_from_RGB-D_Camera_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| FaceCLIPNeRF: Text-Driven 3D Face Manipulation using Deformable Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://faceclipnerf.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_FaceCLIPNeRF_Text-driven_3D_Face_Manipulation_using_Deformable_Neural_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11418-b31b1b.svg)](https://arxiv.org/abs/2307.11418) | :heavy_minus_sign: |
| HollowNeRF: Pruning Hashgrid-based NeRFs with Trainable Collision Mitigation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_HollowNeRF_Pruning_Hashgrid-Based_NeRFs_with_Trainable_Collision_Mitigation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10122-b31b1b.svg)](https://arxiv.org/abs/2308.10122) | :heavy_minus_sign: |
| ICE-NeRF: Interactive Color Editing of NeRFs via Decomposition-Aware Weight Optimization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_ICE-NeRF_Interactive_Color_Editing_of_NeRFs_via_Decomposition-Aware_Weight_Optimization_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| FULLER: Unified Multi-Modality Multi-Task 3D Perception via Multi-Level Gradient Calibration | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_FULLER_Unified_Multi-modality_Multi-task_3D_Perception_via_Multi-level_Gradient_Calibration_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.16617-b31b1b.svg)](https://arxiv.org/abs/2307.16617) | :heavy_minus_sign: |
| Neural Fields for Structured Lighting | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shandilya_Neural_Fields_for_Structured_Lighting_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| CO-Net: Learning Multiple Point Cloud Tasks at Once with a Cohesive Network | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_CO-Net_Learning_Multiple_Point_Cloud_Tasks_at_Once_with_A_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Pose-Free Neural Radiance Fields via Implicit Pose Regularization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Pose-Free_Neural_Radiance_Fields_via_Implicit_Pose_Regularization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.15049-b31b1b.svg)](https://arxiv.org/abs/2308.15049) | :heavy_minus_sign: |
| TransHuman: A Transformer-based Human Representation for Generalizable Neural Human Rendering | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pansanity666.github.io/TransHuman/) <br /> [![GitHub](https://img.shields.io/github/stars/pansanity666/TransHuman?style=flat)](https://github.com/pansanity666/TransHuman) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_TransHuman_A_Transformer-based_Human_Representation_for_Generalizable_Neural_Human_Rendering_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12291-b31b1b.svg)](https://arxiv.org/abs/2307.12291) | :heavy_minus_sign: |
| S-VolSDF: Sparse Multi-View Stereo Regularization of Neural Implicit Surfaces | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://hao-yu-wu.github.io/s-volsdf/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_S-VolSDF_Sparse_Multi-View_Stereo_Regularization_of_Neural_Implicit_Surfaces_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17712-b31b1b.svg)](https://arxiv.org/abs/2303.17712) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3_4PeVHWliY) |
| DPS-Net: Deep Polarimetric Stereo Depth Estimation | [![GitHub](https://img.shields.io/github/stars/Ethereal-Tian/DPS_Net?style=flat)](https://github.com/Ethereal-Tian/DPS_Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_DPS-Net_Deep_Polarimetric_Stereo_Depth_Estimation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| 3DPPE: 3D Point Positional Encoding for Transformer-based Multi-Camera 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/drilistbox/3DPPE?style=flat)](https://github.com/drilistbox/3DPPE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shu_3DPPE_3D_Point_Positional_Encoding_for_Transformer-based_Multi-Camera_3D_Object_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14710-b31b1b.svg)](https://arxiv.org/abs/2211.14710) | :heavy_minus_sign: |
| Deformable Neural Radiance Fields using RGB and Event Cameras | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://qimaqi.github.io/DE-NeRF.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/qimaqi/DE-NeRF?style=flat)](https://github.com/qimaqi/DE-NeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Deformable_Neural_Radiance_Fields_using_RGB_and_Event_Cameras_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08416-b31b1b.svg)](https://arxiv.org/abs/2309.08416) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=K-hINgoSPKU) |
| NeILF++: Inter-Reflectable Light Fields for Geometry and Material Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yoyo000.github.io/NeILF_pp/) <br /> [![GitHub](https://img.shields.io/github/stars/apple/ml-neilfpp?style=flat)](https://github.com/apple/ml-neilfpp) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_NeILF_Inter-Reflectable_Light_Fields_for_Geometry_and_Material_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17147-b31b1b.svg)](https://arxiv.org/abs/2303.17147) | :heavy_minus_sign: |
| Hierarchical Prior Mining for Non-Local Multi-View Stereo | [![GitHub](https://img.shields.io/github/stars/CLinvx/HPM-MVS?style=flat)](https://github.com/CLinvx/HPM-MVS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Hierarchical_Prior_Mining_for_Non-local_Multi-View_Stereo_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09758-b31b1b.svg)](https://arxiv.org/abs/2303.09758) | :heavy_minus_sign: |
| Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/exiawsh/StreamPETR?style=flat)](https://github.com/exiawsh/StreamPETR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Exploring_Object-Centric_Temporal_Modeling_for_Efficient_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11926-b31b1b.svg)](https://arxiv.org/abs/2303.11926) | :heavy_minus_sign: |
| Re-ReND: Real-Time Rendering of NeRFs Across Devices | [![GitHub](https://img.shields.io/github/stars/sararoma95/Re-ReND?style=flat)](https://github.com/sararoma95/Re-ReND) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Rojas_Re-ReND_Real-Time_Rendering_of_NeRFs_across_Devices_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08717-b31b1b.svg)](https://arxiv.org/abs/2303.08717) | :heavy_minus_sign: |
| Learning Shape Primitives via Implicit Convexity Regularization | [![GitHub](https://img.shields.io/github/stars/seanywang0408/ICR?style=flat)](https://github.com/seanywang0408/ICR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Learning_Shape_Primitives_via_Implicit_Convexity_Regularization_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Geometry-Guided Feature Learning and Fusion for Indoor Scene Reconstruction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Geometry-guided_Feature_Learning_and_Fusion_for_Indoor_Scene_Reconstruction_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment | [![GitHub](https://img.shields.io/github/stars/zhangzw12319/lcps?style=flat)](https://github.com/zhangzw12319/lcps) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LiDAR-Camera_Panoptic_Segmentation_via_Geometry-Consistent_and_Semantic-Aware_Alignment_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.01686-b31b1b.svg)](https://arxiv.org/abs/2308.01686) | :heavy_minus_sign: |
| PivotNet: Vectorized Pivot Learning for End-to-end HD Map Construction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_PivotNet_Vectorized_Pivot_Learning_for_End-to-end_HD_Map_Construction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.16477-b31b1b.svg)](https://arxiv.org/abs/2308.16477) | :heavy_minus_sign: |
| Sat2Density: Faithful Density Learning from Satellite-Ground Image Pairs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sat2density.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/qianmingduowan/Sat2Density?style=flat)](https://github.com/qianmingduowan/Sat2Density) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Sat2Density_Faithful_Density_Learning_from_Satellite-Ground_Image_Pairs_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14672-b31b1b.svg)](https://arxiv.org/abs/2303.14672) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mf00PRXUpTU) |
| Mask-Attention-Free Transformer for 3D Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/dvlab-research/Mask-Attention-Free-Transformer?style=flat)](https://github.com/dvlab-research/Mask-Attention-Free-Transformer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_Mask-Attention-Free_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.01692-b31b1b.svg)](https://arxiv.org/abs/2309.01692) | :heavy_minus_sign: |
| Scene-Aware Feature Matching | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Scene-Aware_Feature_Matching_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09949-b31b1b.svg)](https://arxiv.org/abs/2308.09949) | :heavy_minus_sign: |
| Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-Balanced Pseudo-Labeling | [![GitHub](https://img.shields.io/github/stars/zhuoxiao-chen/ReDB-DA-3Ddet?style=flat)](https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Revisiting_Domain-Adaptive_3D_Object_Detection_by_Reliable_Diverse_and_Class-balanced_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.07944-b31b1b.svg)](https://arxiv.org/abs/2307.07944) | :heavy_minus_sign: |
| GO-SLAM: Global Optimization for Consistent 3D Instant Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://youmi-zym.github.io/projects/GO-SLAM/) <br /> [![GitHub](https://img.shields.io/github/stars/youmi-zym/GO-SLAM?style=flat)](https://github.com/youmi-zym/GO-SLAM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GO-SLAM_Global_Optimization_for_Consistent_3D_Instant_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02436-b31b1b.svg)](https://arxiv.org/abs/2309.02436) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MbGn94Y4l8Y) |
| BANSAC: A dynamic BAyesian Network for adaptive SAmple Consensus | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pmiraldo.github.io/projects/bansac/bansac.html) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Piedade_BANSAC_A_Dynamic_BAyesian_Network_for_Adaptive_SAmple_Consensus_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08690-b31b1b.svg)](https://arxiv.org/abs/2309.08690) | :heavy_minus_sign: |
| Theoretical and Numerical Analysis of 3D Reconstruction using Point and Line Incidences | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Rydell_Theoretical_and_Numerical_Analysis_of_3D_Reconstruction_Using_Point_and_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13593-b31b1b.svg)](https://arxiv.org/abs/2303.13593) | :heavy_minus_sign: |
| RealGraph: A Multiview Dataset for 4D Real-World Context Graph Generation | [![GitHub](https://img.shields.io/github/stars/THU-luvision/RealGraph?style=flat)](https://github.com/THU-luvision/RealGraph) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_RealGraph_A_Multiview_Dataset_for_4D_Real-world_Context_Graph_Generation_ICCV_2023_paper.pdf) <br /> [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://rqhuang88.github.io/html/RealGraph.html) | :heavy_minus_sign: |
| CL-MVSNet: Unsupervised Multi-View Stereo with Dual-Level Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/KaiqiangXiong/CL-MVSNet?style=flat)](https://github.com/KaiqiangXiong/CL-MVSNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_paper.pdf) <br /> [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://jianbojiao.com/pdfs/iccv23_clmvs.pdf) | :heavy_minus_sign: |
| Temporal Enhanced Training of Multi-View 3D Object Detector via Historical Object Prediction | [![GitHub](https://img.shields.io/github/stars/Sense-X/HoP?style=flat)](https://github.com/Sense-X/HoP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_Temporal_Enhanced_Training_of_Multi-view_3D_Object_Detector_via_Historical_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00967-b31b1b.svg)](https://arxiv.org/abs/2304.00967) | :heavy_minus_sign: |
| Object as Query: Lifting any 2D Object Detector to 3D Detection | [![GitHub](https://img.shields.io/github/stars/tusen-ai/MV2D?style=flat)](https://github.com/tusen-ai/MV2D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Object_as_Query_Lifting_Any_2D_Object_Detector_to_3D_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.02364-b31b1b.svg)](https://arxiv.org/abs/2301.02364) | :heavy_minus_sign: |
| PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_PARTNER_Level_up_the_Polar_Representation_for_LiDAR_3D_Object_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03982-b31b1b.svg)](https://arxiv.org/abs/2308.03982) | :heavy_minus_sign: |
| Not Every Side is Equal: Localization Uncertainty Estimation for Semi-Supervised 3D Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_Every_Side_Is_Equal_Localization_Uncertainty_Estimation_for_Semi-Supervised_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| LiveHand: Real-Time and Photorealistic Neural Hand Rendering | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://vcai.mpi-inf.mpg.de/projects/LiveHand/) <br /> [![GitHub](https://img.shields.io/github/stars/amundra15/livehand?style=flat)](https://github.com/amundra15/livehand) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Mundra_LiveHand_Real-time_and_Photorealistic_Neural_Hand_Rendering_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.07672-b31b1b.svg)](https://arxiv.org/abs/2302.07672) | :heavy_minus_sign: |
| DG-Recon: Depth-Guided Neural 3D Scene Reconstruction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_DG-Recon_Depth-Guided_Neural_3D_Scene_Reconstruction_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos | [![GitHub](https://img.shields.io/github/stars/MCG-NJU/SparseBEV?style=flat)](https://github.com/MCG-NJU/SparseBEV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SparseBEV_High-Performance_Sparse_3D_Object_Detection_from_Multi-Camera_Videos_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09244-b31b1b.svg)](https://arxiv.org/abs/2308.09244) | :heavy_minus_sign: |
| Strivec: Sparse Tri-Vector Radiance Fields | [![GitHub](https://img.shields.io/github/stars/Zerg-Overmind/Strivec?style=flat)](https://github.com/Zerg-Overmind/Strivec) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Strivec_Sparse_Tri-Vector_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13226-b31b1b.svg)](https://arxiv.org/abs/2307.13226) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zQ5Uli553CY) |
| LDP-Feat: Image Features with Local Differential Privacy | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pittaluga_LDP-Feat_Image_Features_with_Local_Differential_Privacy_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11223-b31b1b.svg)](https://arxiv.org/abs/2308.11223) | :heavy_minus_sign: |
| SparseFusion: Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/yichen928/SparseFusion?style=flat)](https://github.com/yichen928/SparseFusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_SparseFusion_Fusing_Multi-Modal_Sparse_Representations_for_Multi-Sensor_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14340-b31b1b.svg)](https://arxiv.org/abs/2304.14340) | :heavy_minus_sign: |
| Strata-NeRF: Neural Radiance Fields for Stratified Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ankitatiisc.github.io/Strata-NeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/ankitatiisc/Strata-NeRF?style=flat)](https://github.com/ankitatiisc/Strata-NeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dhiman_Strata-NeRF__Neural_Radiance_Fields_for_Stratified_Scenes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10337-b31b1b.svg)](https://arxiv.org/abs/2308.10337) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=EzHlqoinwAg) |
| CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_CRN_Camera_Radar_Net_for_Accurate_Robust_Efficient_3D_Perception_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00670-b31b1b.svg)](https://arxiv.org/abs/2304.00670) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hMWe2yjzwQ0) |
| LightGlue: Local Feature Matching at Light Speed | [![GitHub](https://img.shields.io/github/stars/cvg/LightGlue?style=flat)](https://github.com/cvg/LightGlue) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lindenberger_LightGlue_Local_Feature_Matching_at_Light_Speed_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.13643-b31b1b.svg)](https://arxiv.org/abs/2306.13643) | :heavy_minus_sign: |
| ExBluRF: Efficient Radiance Fields for Extreme Motion Blurred Images | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_ExBluRF_Efficient_Radiance_Fields_for_Extreme_Motion_Blurred_Images_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08957-b31b1b.svg)](https://arxiv.org/abs/2309.08957) | :heavy_minus_sign: |
| Generalized Differentiable RANSAC | [![GitHub](https://img.shields.io/github/stars/weitong8591/differentiable_ransac?style=flat)](https://github.com/weitong8591/differentiable_ransac) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Generalized_Differentiable_RANSAC_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.13185-b31b1b.svg)](https://arxiv.org/abs/2212.13185) | :heavy_minus_sign: |
| Constraining Depth Map Geometry for Multi-View Stereo: A Dual-Depth Approach with Saddle-Shaped Depth Cells | [![GitHub](https://img.shields.io/github/stars/DIVE128/DMVSNet?style=flat)](https://github.com/DIVE128/DMVSNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Constraining_Depth_Map_Geometry_for_Multi-View_Stereo_A_Dual-Depth_Approach_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09160-b31b1b.svg)](https://arxiv.org/abs/2307.09160) | :heavy_minus_sign: |
| Total-Recon: Deformable Scene Reconstruction for Embodied View Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://andrewsonga.github.io/totalrecon/) <br /> [![GitHub](https://img.shields.io/github/stars/andrewsonga/Total-Recon?style=flat)](https://github.com/andrewsonga/Total-Recon) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Total-Recon_Deformable_Scene_Reconstruction_for_Embodied_View_Synthesis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.12317-b31b1b.svg)](https://arxiv.org/abs/2304.12317) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IpXw41cDYPU) |
| Seal-3D: Interactive Pixel-Level Editing for Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://windingwind.github.io/seal-3d/) <br /> [![GitHub](https://img.shields.io/github/stars/windingwind/seal-3d?style=flat)](https://github.com/windingwind/seal-3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Seal-3D_Interactive_Pixel-Level_Editing_for_Neural_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15131-b31b1b.svg)](https://arxiv.org/abs/2307.15131) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rm5aJl-9tmE) |
| PointMBF: A Multi-Scale Bidirectional Fusion Network for Unsupervised RGB-D Point Cloud Registration | [![GitHub](https://img.shields.io/github/stars/phdymz/PointMBF?style=flat)](https://github.com/phdymz/PointMBF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PointMBF_A_Multi-scale_Bidirectional_Fusion_Network_for_Unsupervised_RGB-D_Point_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04782-b31b1b.svg)](https://arxiv.org/abs/2308.04782) | :heavy_minus_sign: |
| PARF: Primitive-Aware Radiance Fusion for Indoor Scene Novel View Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://oceanying.github.io/PARF/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ying_PARF_Primitive-Aware_Radiance_Fusion_for_Indoor_Scene_Novel_View_Synthesis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.17190-b31b1b.svg)](https://arxiv.org/abs/2309.17190) | :heavy_minus_sign: |
| Rethinking Point Cloud Registration as Masking and Reconstruction | [![GitHub](https://img.shields.io/github/stars/CGuangyan-BIT/MRA?style=flat)](https://github.com/CGuangyan-BIT/MRA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Rethinking_Point_Cloud_Registration_as_Masking_and_Reconstruction_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Ada3D: Exploiting the Spatial Redundancy with Adaptive Inference for Efficient 3D Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://a-suozhang.xyz/ada3d.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/A-suozhang/ada3d?style=flat)](https://github.com/A-suozhang/ada3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Ada3D__Exploiting_the_Spatial_Redundancy_with_Adaptive_Inference_for_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08209-b31b1b.svg)](https://arxiv.org/abs/2307.08209) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=N_llpMqMJbk) |
| Delicate Textured Mesh Recovery from NeRF via Adaptive Surface Refinement | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://me.kiui.moe/nerf2mesh/) <br /> [![GitHub](https://img.shields.io/github/stars/ashawkey/nerf2mesh?style=flat)](https://github.com/ashawkey/nerf2mesh) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Delicate_Textured_Mesh_Recovery_from_NeRF_via_Adaptive_Surface_Refinement_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.02091-b31b1b.svg)](https://arxiv.org/abs/2303.02091) | :heavy_minus_sign: |
| CVRecon: Rethinking 3D Geometric Feature Learning for Neural Reconstruction | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cvrecon.ziyue.cool/) <br /> [![GitHub](https://img.shields.io/github/stars/fengziyue/CVRecon?style=flat)](https://github.com/fengziyue/CVRecon) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_CVRecon_Rethinking_3D_Geometric_Feature_Learning_For_Neural_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14633-b31b1b.svg)](https://arxiv.org/abs/2304.14633) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AVbbx4TBFf8) |
| RICO: Regularizing the Unobservable for Indoor Compositional Reconstruction | [![GitHub](https://img.shields.io/github/stars/kyleleey/RICO?style=flat)](https://github.com/kyleleey/RICO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RICO_Regularizing_the_Unobservable_for_Indoor_Compositional_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08605-b31b1b.svg)](https://arxiv.org/abs/2303.08605) | :heavy_minus_sign: |
| Multiscale Representation for Real-Time Anti-Aliasing Neural Rendering | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Multiscale_Representation_for_Real-Time_Anti-Aliasing_Neural_Rendering_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10075-b31b1b.svg)](https://arxiv.org/abs/2304.10075) | :heavy_minus_sign: |
| ELFNet: Evidential Local-Global Fusion for Stereo Matching | [![GitHub](https://img.shields.io/github/stars/jimmy19991222/ELFNet?style=flat)](https://github.com/jimmy19991222/ELFNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lou_ELFNet_Evidential_Local-global_Fusion_for_Stereo_Matching_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.00728-b31b1b.svg)](https://arxiv.org/abs/2308.00728) | :heavy_minus_sign: |
| GaPro: Box-Supervised 3D Point Cloud Instance Segmentation using Gaussian Processes as Pseudo Labelers | [![GitHub](https://img.shields.io/github/stars/VinAIResearch/GaPro?style=flat)](https://github.com/VinAIResearch/GaPro) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ngo_GaPro_Box-Supervised_3D_Point_Cloud_Instance_Segmentation_Using_Gaussian_Processes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13251-b31b1b.svg)](https://arxiv.org/abs/2307.13251) | :heavy_minus_sign: |
| Multi-Body Depth and Camera Pose Estimation from Multiple Views | [![GitHub](https://img.shields.io/github/stars/andreadalcin/MultiBodySfM?style=flat)](https://github.com/andreadalcin/MultiBodySfM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dal_Cin_Multi-body_Depth_and_Camera_Pose_Estimation_from_Multiple_Views_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Reference-Guided Controllable Inpainting of Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ashmrz.github.io/reference-guided-3d/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Mirzaei_Reference-guided_Controllable_Inpainting_of_Neural_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.09677-b31b1b.svg)](https://arxiv.org/abs/2304.09677) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=y7Tv3iN6OgY) |
| Retro-FPN: Retrospective Feature Pyramid Network for Point Cloud Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/AllenXiangX/Retro-FPN?style=flat)](https://github.com/AllenXiangX/Retro-FPN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Retro-FPN_Retrospective_Feature_Pyramid_Network_for_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09314-b31b1b.svg)](https://arxiv.org/abs/2308.09314) | :heavy_minus_sign: |
| GeoMIM: Towards Better 3D Knowledge Transfer via Masked Image Modeling for Multi-View 3D Understanding | [![GitHub](https://img.shields.io/github/stars/Sense-X/GeoMIM?style=flat)](https://github.com/Sense-X/GeoMIM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_GeoMIM_Towards_Better_3D_Knowledge_Transfer_via_Masked_Image_Modeling_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11325-b31b1b.svg)](https://arxiv.org/abs/2303.11325) | :heavy_minus_sign: |
| OpenOccupancy: A Large Scale Benchmark for Surrounding Semantic Occupancy Perception | [![GitHub](https://img.shields.io/github/stars/JeffWang987/OpenOccupancy?style=flat)](https://github.com/JeffWang987/OpenOccupancy) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_OpenOccupancy_A_Large_Scale_Benchmark_for_Surrounding_Semantic_Occupancy_Perception_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.03991-b31b1b.svg)](https://arxiv.org/abs/2303.03991) | :heavy_minus_sign: |
| Surface Normal Clustering for Implicit Representation of Manhattan Scenes | [![GitHub](https://img.shields.io/github/stars/nikola3794/normal-clustering-nerf?style=flat)](https://github.com/nikola3794/normal-clustering-nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Popovic_Surface_Normal_Clustering_for_Implicit_Representation_of_Manhattan_Scenes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.01331-b31b1b.svg)](https://arxiv.org/abs/2212.01331) | :heavy_minus_sign: |
| Spacetime Surface Regularization for Neural Dynamic Scene Reconstruction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Choe_Spacetime_Surface_Regularization_for_Neural_Dynamic_Scene_Reconstruction_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| LDL: Line Distance Functions for Panoramic Localization | [![GitHub](https://img.shields.io/github/stars/82magnolia/panoramic-localization?style=flat)](https://github.com/82magnolia/panoramic-localization) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_LDL_Line_Distance_Functions_for_Panoramic_Localization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13989-b31b1b.svg)](https://arxiv.org/abs/2308.13989) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cQ5l4rauNY0) |
| Learning Neural Implicit Surfaces with Object-Aware Radiance Fields | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Neural_Implicit_Surfaces_with_Object-Aware_Radiance_Fields_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| MonoNeRF: Learning a Generalizable Dynamic Radiance Field from Monocular Videos | [![GitHub](https://img.shields.io/github/stars/tianfr/MonoNeRF?style=flat)](https://github.com/tianfr/MonoNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_MonoNeRF_Learning_a_Generalizable_Dynamic_Radiance_Field_from_Monocular_Videos_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.13056-b31b1b.svg)](https://arxiv.org/abs/2212.13056) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=A6O4Q3PZZ18) |
| Neural Radiance Field with LiDAR Maps | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_Neural_Radiance_Field_with_LiDAR_maps_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Deformable Model-Driven Neural Rendering for High-Fidelity 3D Reconstruction of Human Heads Under Low-View Settings | [![GitHub](https://img.shields.io/github/stars/xubaixinxbx/3dheads?style=flat)](https://github.com/xubaixinxbx/3dheads) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Deformable_Model-Driven_Neural_Rendering_for_High-Fidelity_3D_Reconstruction_of_Human_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13855-b31b1b.svg)](https://arxiv.org/abs/2303.13855) | :heavy_minus_sign: |
| DeLiRa: Self-Supervised Depth, Light, and Radiance Fields | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/tri-delira) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Guizilini_DeLiRa_Self-Supervised_Depth_Light_and_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02797-b31b1b.svg)](https://arxiv.org/abs/2304.02797) | :heavy_minus_sign: |
| ATT3D: Amortized Text-to-3D Object Synthesis | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://research.nvidia.com/labs/toronto-ai/ATT3D/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lorraine_ATT3D_Amortized_Text-to-3D_Object_Synthesis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07349-b31b1b.svg)](https://arxiv.org/abs/2306.07349) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IWnap49eIwc) |
| ScatterNeRF: Seeing through Fog with Physically-based Inverse Neural Rendering | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://light.princeton.edu/publication/scatternerf/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ramazzina_ScatterNeRF_Seeing_Through_Fog_with_Physically-Based_Inverse_Neural_Rendering_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.02103-b31b1b.svg)](https://arxiv.org/abs/2305.02103) | :heavy_minus_sign: |
| CroCo v2: Improved Cross-View Completion Pre-Training for Stereo Matching and Optical Flow | [![GitHub](https://img.shields.io/github/stars/naver/croco?style=flat)](https://github.com/naver/croco) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Weinzaepfel_CroCo_v2_Improved_Cross-view_Completion_Pre-training_for_Stereo_Matching_and_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.10408-b31b1b.svg)](https://arxiv.org/abs/2211.10408) | :heavy_minus_sign: |
| Guiding Local Feature Matching with Surface Curvature | [![GitHub](https://img.shields.io/github/stars/AaltoVision/surface-curvature-estimator?style=flat)](https://github.com/AaltoVision/surface-curvature-estimator) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Guiding_Local_Feature_Matching_with_Surface_Curvature_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| NaviNeRF: NeRF-based 3D Representation Disentanglement by Latent Semantic Navigation | [![GitHub](https://img.shields.io/github/stars/Arlo0o/NaviNeRF?style=flat)](https://github.com/Arlo0o/NaviNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_NaviNeRF_NeRF-based_3D_Representation_Disentanglement_by_Latent_Semantic_Navigation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11342-b31b1b.svg)](https://arxiv.org/abs/2304.11342) | :heavy_minus_sign: |
| Efficient LiDAR Point Cloud Oversegmentation Network | [![GitHub](https://img.shields.io/github/stars/fpthink/SuperLiDAR?style=flat)](https://github.com/fpthink/SuperLiDAR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hui_Efficient_LiDAR_Point_Cloud_Oversegmentation_Network_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Iterative Superquadric Recomposition of 3D Objects from Multiple Views | [![GitHub](https://img.shields.io/github/stars/ExplainableML/ISCO?style=flat)](https://github.com/ExplainableML/ISCO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Alaniz_Iterative_Superquadric_Recomposition_of_3D_Objects_from_Multiple_Views_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02102-b31b1b.svg)](https://arxiv.org/abs/2309.02102) | :heavy_minus_sign: |
| S3IM: Stochastic Structural SIMilarity and its Unreasonable Effectiveness for Neural Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://madaoer.github.io/s3im_nerf/) <br /> [![GitHub](https://img.shields.io/github/stars/Madaoer/S3IM-Neural-Fields?style=flat)](https://github.com/Madaoer/S3IM-Neural-Fields) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_S3IM_Stochastic_Structural_SIMilarity_and_Its_Unreasonable_Effectiveness_for_Neural_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07032-b31b1b.svg)](https://arxiv.org/abs/2308.07032) | :heavy_minus_sign: |
| Neural-PBIR Reconstruction of Shape, Material, and Illumination | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://neural-pbir.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Neural-PBIR_Reconstruction_of_Shape_Material_and_Illumination_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.13445-b31b1b.svg)](https://arxiv.org/abs/2304.13445) | :heavy_minus_sign: |
| Predict to Detect: Prediction-Guided 3D Object Detection using Sequential Images | [![GitHub](https://img.shields.io/github/stars/sanmin0312/P2D?style=flat)](https://github.com/sanmin0312/P2D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Predict_to_Detect_Prediction-guided_3D_Object_Detection_using_Sequential_Images_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.08528-b31b1b.svg)](https://arxiv.org/abs/2306.08528) | :heavy_minus_sign: |
| ObjectFusion: Multi-Modal 3D Object Detection with Object-Centric Fusion | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_ObjectFusion_Multi-modal_3D_Object_Detection_with_Object-Centric_Fusion_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Domain Generalization of 3D Semantic Segmentation in Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/JulesSanchez/3DLabelProp?style=flat)](https://github.com/JulesSanchez/3DLabelProp) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sanchez_Domain_Generalization_of_3D_Semantic_Segmentation_in_Autonomous_Driving_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04245-b31b1b.svg)](https://arxiv.org/abs/2212.04245) | :heavy_minus_sign: |
| When Epipolar Constraint Meets Non-Local Operators in Multi-View Stereo | [![GitHub](https://img.shields.io/github/stars/TQTQliu/ET-MVSNet?style=flat)](https://github.com/TQTQliu/ET-MVSNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_When_Epipolar_Constraint_Meets_Non-Local_Operators_in_Multi-View_Stereo_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.17218-b31b1b.svg)](https://arxiv.org/abs/2309.17218) | :heavy_minus_sign: |
| Hierarchical Point-based Active Learning for Semi-Supervised Point Cloud Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/SmiletoE/HPAL?style=flat)](https://github.com/SmiletoE/HPAL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Hierarchical_Point-based_Active_Learning_for_Semi-supervised_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11166-b31b1b.svg)](https://arxiv.org/abs/2308.11166) | :heavy_minus_sign: |
| UniT3D: A Unified Transformer for 3D Dense Captioning and Visual Grounding | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_UniT3D_A_Unified_Transformer_for_3D_Dense_Captioning_and_Visual_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00836-b31b1b.svg)](https://arxiv.org/abs/2212.00836) | :heavy_minus_sign: |
| Nerfbusters: Removing Ghostly Artifacts from Casually Captured NeRFs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ethanweber.me/nerfbusters/) <br /> [![GitHub](https://img.shields.io/github/stars/ethanweber/nerfbusters?style=flat)](https://github.com/ethanweber/nerfbusters) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Warburg_Nerfbusters_Removing_Ghostly_Artifacts_from_Casually_Captured_NeRFs_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10532-b31b1b.svg)](https://arxiv.org/abs/2304.10532) | :heavy_minus_sign: |
| Clutter Detection and Removal in 3D Scenes with View-Consistent Inpainting | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://weify627.github.io/clutter/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Clutter_Detection_and_Removal_in_3D_Scenes_with_View-Consistent_Inpainting_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03763-b31b1b.svg)](https://arxiv.org/abs/2304.03763) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2rZtQTFFc-o) |
| PG-RCNN: Semantic Surface Point Generation for 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/quotation2520/PG-RCNN?style=flat)](https://github.com/quotation2520/PG-RCNN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Koo_PG-RCNN_Semantic_Surface_Point_Generation_for_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12637-b31b1b.svg)](https://arxiv.org/abs/2307.12637) | :heavy_minus_sign: |
| Distributed Bundle Adjustment with Block-based Sparse Matrix Compression for Super Large Scale Datasets |  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Distributed_Bundle_Adjustment_with_Block-Based_Sparse_Matrix_Compression_for_Super_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08383-b31b1b.svg)](https://arxiv.org/abs/2307.08383) | :heavy_minus_sign: |
| Adaptive Reordering Sampler with Neurally Guided MAGSAC | [![GitHub](https://img.shields.io/github/stars/weitong8591/ars_magsac?style=flat)](https://github.com/weitong8591/ars_magsac) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Adaptive_Reordering_Sampler_with_Neurally_Guided_MAGSAC_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2111.14093-b31b1b.svg)](https://arxiv.org/abs/2111.14093) | :heavy_minus_sign: |
| Privacy Preserving Localization via Coordinate Permutations | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Privacy_Preserving_Localization_via_Coordinate_Permutations_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nkJ3ylpWSdQ) |
| WaveNeRF: Wavelet-based Generalizable Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mxuai.github.io/WaveNeRF/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_WaveNeRF_Wavelet-based_Generalizable_Neural_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04826-b31b1b.svg)](https://arxiv.org/abs/2308.04826) | :heavy_minus_sign: |
| TransIFF: An Instance-Level Feature Fusion Framework for Vehicle-Infrastructure Cooperative 3D Detection with Transformers | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransIFF_An_Instance-Level_Feature_Fusion_Framework_for_Vehicle-Infrastructure_Cooperative_3D_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Density-Invariant Features for Distant Point Cloud Registration | [![GitHub](https://img.shields.io/github/stars/liuQuan98/GCL?style=flat)](https://github.com/liuQuan98/GCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Density-invariant_Features_for_Distant_Point_Cloud_Registration_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09788-b31b1b.svg)](https://arxiv.org/abs/2307.09788) | :heavy_minus_sign: |
| UMIFormer: Mining the Correlations between Similar Tokens for Multi-View 3D Reconstruction | [![GitHub](https://img.shields.io/github/stars/GaryZhu1996/UMIFormer?style=flat)](https://github.com/GaryZhu1996/UMIFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_UMIFormer_Mining_the_Correlations_between_Similar_Tokens_for_Multi-View_3D_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.13987-b31b1b.svg)](https://arxiv.org/abs/2302.13987) | :heavy_minus_sign: |
| Neural LiDAR Fields for Novel View Synthesis | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://research.nvidia.com/labs/toronto-ai/nfl/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Neural_LiDAR_Fields_for_Novel_View_Synthesis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.01643-b31b1b.svg)](https://arxiv.org/abs/2305.01643) | :heavy_minus_sign: |
| Learning Unified Decompositional and Compositional NeRF for Editable Novel View Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://w-ted.github.io/publications/udc-nerf/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Unified_Decompositional_and_Compositional_NeRF_for_Editable_Novel_View_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.02840-b31b1b.svg)](https://arxiv.org/abs/2308.02840) | :heavy_minus_sign: |
| Long-Range Grouping Transformer for Multi-View 3D Reconstruction | [![GitHub](https://img.shields.io/github/stars/LiyingCV/Long-Range-Grouping-Transformer?style=flat)](https://github.com/LiyingCV/Long-Range-Grouping-Transformer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Long-Range_Grouping_Transformer_for_Multi-View_3D_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.08724-b31b1b.svg)](https://arxiv.org/abs/2308.08724) | :heavy_minus_sign: |
| Cross Modal Transformer: Towards Fast and Robust 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/junjie18/CMT?style=flat)](https://github.com/junjie18/CMT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Cross_Modal_Transformer_Towards_Fast_and_Robust_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.01283-b31b1b.svg)](https://arxiv.org/abs/2301.01283) | :heavy_minus_sign: |
| KECOR: Kernel Coding Rate Maximization for Active 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/Luoyadan/KECOR-active-3Ddet?style=flat)](https://github.com/Luoyadan/KECOR-active-3Ddet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_KECOR_Kernel_Coding_Rate_Maximization_for_Active_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.07942-b31b1b.svg)](https://arxiv.org/abs/2307.07942) | :heavy_minus_sign: |
| C2F2NeUS: Cascade Cost Frustum Fusion for High Fidelity and Generalizable Neural Surface Reconstruction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_C2F2NeUS_Cascade_Cost_Frustum_Fusion_for_High_Fidelity_and_Generalizable_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.10003-b31b1b.svg)](https://arxiv.org/abs/2306.10003) | :heavy_minus_sign: |
| End-to-End 3D Tracking with Decoupled Queries | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/dqtrack) <br /> [![GitHub](https://img.shields.io/github/stars/NVlabs/DQTrack?style=flat)](https://github.com/NVlabs/DQTrack) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_End-to-end_3D_Tracking_with_Decoupled_Queries_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PHDKu3-iKfo) |
| LU-NeRF: Scene and Pose Estimation by Synchronizing Local Unposed NeRFs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zezhoucheng.github.io/lu-nerf/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LU-NeRF_Scene_and_Pose_Estimation_by_Synchronizing_Local_Unposed_NeRFs_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.05410-b31b1b.svg)](https://arxiv.org/abs/2306.05410) | :heavy_minus_sign: |
| GridPull: Towards Scalability in Learning Implicit Representations from 3D Point Clouds | [![GitHub](https://img.shields.io/github/stars/chenchao15/GridPull?style=flat)](https://github.com/chenchao15/GridPull) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_GridPull_Towards_Scalability_in_Learning_Implicit_Representations_from_3D_Point_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13175-b31b1b.svg)](https://arxiv.org/abs/2308.13175) | :heavy_minus_sign: |
| Robust e-NeRF: NeRF from Sparse & Noisy Events under Non-Uniform Motion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wengflow.github.io/robust-e-nerf/) <br /> [![GitHub](https://img.shields.io/github/stars/wengflow/robust-e-nerf?style=flat)](https://github.com/wengflow/robust-e-nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Low_Robust_e-NeRF_NeRF_from_Sparse__Noisy_Events_under_Non-Uniform_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08596-b31b1b.svg)](https://arxiv.org/abs/2309.08596) | :heavy_minus_sign: |
| Parameterized Cost Volume for Stereo Matching | [![GitHub](https://img.shields.io/github/stars/jiaxiZeng/Parameterized-Cost-Volume-for-Stereo-Matching?style=flat)](https://github.com/jiaxiZeng/Parameterized-Cost-Volume-for-Stereo-Matching) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_Parameterized_Cost_Volume_for_Stereo_Matching_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Coordinate Quantized Neural Implicit Representations for Multi-View Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://machineperceptionlab.github.io/CQ-NIR-page/) <br /> [![GitHub](https://img.shields.io/github/stars/MachinePerceptionLab/CQ-NIR?style=flat)](https://github.com/MachinePerceptionLab/CQ-NIR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Coordinate_Quantized_Neural_Implicit_Representations_for_Multi-view_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11025-b31b1b.svg)](https://arxiv.org/abs/2308.11025) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=n0X8cv-bDCo) |
| Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ymingxie.github.io/parq/) <br /> [![GitHub](https://img.shields.io/github/stars/ymingxie/parq?style=flat)](https://github.com/ymingxie/parq) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Pixel-Aligned_Recurrent_Queries_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.01401-b31b1b.svg)](https://arxiv.org/abs/2310.01401) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rIHsyEXjTN4) |
| Optimizing the Placement of Roadside LiDARs for Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/PJLab-ADG/PCSim?style=flat)](https://github.com/PJLab-ADG/PCSim) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Optimizing_the_Placement_of_Roadside_LiDARs_for_Autonomous_Driving_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07247-b31b1b.svg)](https://arxiv.org/abs/2310.07247) | :heavy_minus_sign: |
| ActorsNeRF: Animatable Few-Shot Human Rendering with Generalizable NeRFs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jitengmu.github.io/ActorsNeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/JitengMu/ActorsNeRF?style=flat)](https://github.com/JitengMu/ActorsNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Mu_ActorsNeRF_Animatable_Few-shot_Human_Rendering_with_Generalizable_NeRFs_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14401-b31b1b.svg)](https://arxiv.org/abs/2304.14401) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CH9f31jRNRA) |
| NeRFrac: Neural Radiance Fields through Refractive Surface | [![GitHub](https://img.shields.io/github/stars/Yifever20002/NeRFrac?style=flat)](https://github.com/Yifever20002/NeRFrac) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhan_NeRFrac_Neural_Radiance_Fields_through_Refractive_Surface_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| CPCM: Contextual Point Cloud Modeling for Weakly-Supervised Point Cloud Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CPCM_Contextual_Point_Cloud_Modeling_for_Weakly-supervised_Point_Cloud_Semantic_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.10316-b31b1b.svg)](https://arxiv.org/abs/2307.10316) | :heavy_minus_sign: |
| FineRecon: Depth-Aware Feed-Forward Network for Detailed 3D Reconstruction | [![GitHub](https://img.shields.io/github/stars/apple/ml-finerecon?style=flat)](https://github.com/apple/ml-finerecon) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Stier_FineRecon_Depth-aware_Feed-forward_Network_for_Detailed_3D_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01480-b31b1b.svg)](https://arxiv.org/abs/2304.01480) | :heavy_minus_sign: |
| Point-SLAM: Dense Neural Point Cloud-based SLAM | [![GitHub](https://img.shields.io/github/stars/eriksandstroem/Point-SLAM?style=flat)](https://github.com/eriksandstroem/Point-SLAM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sandstrom_Point-SLAM_Dense_Neural_Point_Cloud-based_SLAM_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04278-b31b1b.svg)](https://arxiv.org/abs/2304.04278) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QFjtL8XTxlU) |
| You Never Get a Second Chance to Make a Good First Impression: Seeding Active Learning for 3D Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/nerminsamet/seedal?style=flat)](https://github.com/nerminsamet/seedal) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Samet_You_Never_Get_a_Second_Chance_To_Make_a_Good_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11762-b31b1b.svg)](https://arxiv.org/abs/2304.11762) | :heavy_minus_sign: |
| Tetra-NeRF: Representing Neural Radiance Fields using Tetrahedra | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://jkulhanek.com/tetra-nerf/) <br /> [![GitHub](https://img.shields.io/github/stars/jkulhanek/tetra-nerf?style=flat)](https://github.com/jkulhanek/tetra-nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kulhanek_Tetra-NeRF_Representing_Neural_Radiance_Fields_Using_Tetrahedra_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.09987-b31b1b.svg)](https://arxiv.org/abs/2304.09987) | :heavy_minus_sign: |
| Active Stereo without Pattern Projector | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vppstereo.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/bartn8/vppstereo?style=flat)](https://github.com/bartn8/vppstereo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bartolomei_Active_Stereo_Without_Pattern_Projector_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.12315-b31b1b.svg)](https://arxiv.org/abs/2309.12315) | :heavy_minus_sign: |
| HOSNeRF: Dynamic Human-Object-Scene Neural Radiance Fields from a Single Video | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://showlab.github.io/HOSNeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/TencentARC/HOSNeRF?style=flat)](https://github.com/TencentARC/HOSNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_HOSNeRF_Dynamic_Human-Object-Scene_Neural_Radiance_Fields_from_a_Single_Video_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.12281-b31b1b.svg)](https://arxiv.org/abs/2304.12281) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wS5k5nNkPi4) |
| PlankAssembly: Robust 3D Reconstruction from Three Orthographic Views with Learnt Shape Programs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://manycore-research.github.io/PlankAssembly/) <br /> [![GitHub](https://img.shields.io/github/stars/manycore-research/PlankAssembly?style=flat)](https://github.com/manycore-research/PlankAssembly) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_PlankAssembly_Robust_3D_Reconstruction_from_Three_Orthographic_Views_with_Learnt_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.05744-b31b1b.svg)](https://arxiv.org/abs/2308.05744) | :heavy_minus_sign: |
| Efficient View Synthesis with Neural Radiance Distribution Field | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yushuang-wu.github.io/NeRDF/) <br /> [![GitHub](https://img.shields.io/github/stars/yushuang-wu/NeRDF?style=flat)](https://github.com/yushuang-wu/NeRDF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Efficient_View_Synthesis_with_Neural_Radiance_Distribution_Field_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11130-b31b1b.svg)](https://arxiv.org/abs/2308.11130) | :heavy_minus_sign: |
| Query Refinement Transformer for 3D Instance Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Query_Refinement_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| TrajectoryFormer: 3D Object Tracking Transformer with Predictive Trajectory Hypotheses | [![GitHub](https://img.shields.io/github/stars/V2AI/EFG?style=flat)](https://github.com/V2AI/EFG) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TrajectoryFormer_3D_Object_Tracking_Transformer_with_Predictive_Trajectory_Hypotheses_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.05888-b31b1b.svg)](https://arxiv.org/abs/2306.05888) | :heavy_minus_sign: |
| NerfAcc: Efficient Sampling Accelerates NeRFs | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.nerfacc.com/) <br /> [![GitHub](https://img.shields.io/github/stars/KAIR-BAIR/nerfacc?style=flat)](https://github.com/KAIR-BAIR/nerfacc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NerfAcc_Efficient_Sampling_Accelerates_NeRFs_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.04966-b31b1b.svg)](https://arxiv.org/abs/2305.04966) | :heavy_minus_sign: |
| NeTO: Neural Reconstruction of Transparent Objects with Self-Occlusion Aware Refraction-Tracing | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.xxlong.site/NeTO/) <br /> [![GitHub](https://img.shields.io/github/stars/xxlong0/NeTO?style=flat)](https://github.com/xxlong0/NeTO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NeTONeural_Reconstruction_of_Transparent_Objects_with_Self-Occlusion_Aware_Refraction-Tracing_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11219-b31b1b.svg)](https://arxiv.org/abs/2303.11219) | :heavy_minus_sign: |
| Text2Tex: Text-Driven Texture Synthesis via Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://daveredrum.github.io/Text2Tex/) <br /> [![GitHub](https://img.shields.io/github/stars/daveredrum/Text2Tex?style=flat)](https://github.com/daveredrum/Text2Tex) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Text2Tex_Text-driven_Texture_Synthesis_via_Diffusion_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11396-b31b1b.svg)](https://arxiv.org/abs/2303.11396) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2ve8tJ9LlcA) |
| Learning Long-Range Information with Dual-Scale Transformers for Indoor Scene Completion | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Long-Range_Information_with_Dual-Scale_Transformers_for_Indoor_Scene_Completion_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| NeRF-MS: Neural Radiance Fields with Multi-Sequence | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nerf-ms.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NeRF-MS_Neural_Radiance_Fields_with_Multi-Sequence_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Zip-NeRF: Anti-Aliased Grid-based Neural Radiance Fields | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://jonbarron.info/zipnerf/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Barron_Zip-NeRF_Anti-Aliased_Grid-Based_Neural_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06706-b31b1b.svg)](https://arxiv.org/abs/2304.06706) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xrrhynRzC8k) |
| Mixed Neural Voxels for Fast Multi-View Video Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://fengres.github.io/mixvoxels/) <br /> [![GitHub](https://img.shields.io/github/stars/fengres/mixvoxels?style=flat)](https://github.com/fengres/mixvoxels) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Mixed_Neural_Voxels_for_Fast_Multi-view_Video_Synthesis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00190-b31b1b.svg)](https://arxiv.org/abs/2212.00190) | :heavy_minus_sign: |
| Diffusion-Guided Reconstruction of Everyday Hand-Object Interaction Clips | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://judyye.github.io/diffhoi-www/) <br /> [![GitHub](https://img.shields.io/github/stars/JudyYe/diffhoi?style=flat)](https://github.com/JudyYe/diffhoi) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Diffusion-Guided_Reconstruction_of_Everyday_Hand-Object_Interaction_Clips_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.05663-b31b1b.svg)](https://arxiv.org/abs/2309.05663) | :heavy_minus_sign: |
| LERF: Language Embedded Radiance Fields | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.lerf.io/) <br /> [![GitHub](https://img.shields.io/github/stars/kerrj/lerf?style=flat)](https://github.com/kerrj/lerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kerr_LERF_Language_Embedded_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09553-b31b1b.svg)](https://arxiv.org/abs/2303.09553) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7Z2XqH40L08) |
| Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://instruct-nerf2nerf.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/ayaanzhaque/instruct-nerf2nerf?style=flat)](https://github.com/ayaanzhaque/instruct-nerf2nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Haque_Instruct-NeRF2NeRF_Editing_3D_Scenes_with_Instructions_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12789-b31b1b.svg)](https://arxiv.org/abs/2303.12789) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=D6KWAYU3rCA) |
| P1AC: Revisiting Absolute Pose from a Single Affine Correspondence | [![GitHub](https://img.shields.io/github/stars/jonathanventura/P1AC?style=flat)](https://github.com/jonathanventura/P1AC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ventura_P1AC_Revisiting_Absolute_Pose_From_a_Single_Affine_Correspondence_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2011.08790-b31b1b.svg)](https://arxiv.org/abs/2011.08790) | :heavy_minus_sign: |
| Neural Haircut: Prior-Guided Strand-based Hair Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://samsunglabs.github.io/NeuralHaircut/) <br /> [![GitHub](https://img.shields.io/github/stars/SamsungLabs/NeuralHaircut?style=flat)](https://github.com/SamsungLabs/NeuralHaircut) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sklyarova_Neural_Haircut_Prior-Guided_Strand-Based_Hair_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.05872-b31b1b.svg)](https://arxiv.org/abs/2306.05872) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-gg4GhWKuQs) |
| Tri-MipRF: Tri-Mip Representation for Efficient Anti-Aliasing Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wbhu.github.io/projects/Tri-MipRF/) <br /> [![GitHub](https://img.shields.io/github/stars/wbhu/Tri-MipRF?style=flat)](https://github.com/wbhu/Tri-MipRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Tri-MipRF_Tri-Mip_Representation_for_Efficient_Anti-Aliasing_Neural_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11335-b31b1b.svg)](https://arxiv.org/abs/2307.11335) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=eBgoul4F148) |
| LiDAR-UDA: Self-Ensembling through Time for Unsupervised LiDAR Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/JHLee0513/LiDARUDA?style=flat)](https://github.com/JHLee0513/LiDARUDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shaban_LiDAR-UDA_Self-ensembling_Through_Time_for_Unsupervised_LiDAR_Domain_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13523-b31b1b.svg)](https://arxiv.org/abs/2309.13523) | :heavy_minus_sign: |
| Tracking Everything Everywhere All at Once | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://omnimotion.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/qianqianwang68/omnimotion?style=flat)](https://github.com/qianqianwang68/omnimotion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Tracking_Everything_Everywhere_All_at_Once_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.05422-b31b1b.svg)](https://arxiv.org/abs/2306.05422) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KHoAG3gA024) |
| Ego-Humans: An Ego-Centric 3D Multi-Human Benchmark | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rawalkhirodkar.github.io/egohumans/) <br /> [![GitHub](https://img.shields.io/github/stars/rawalkhirodkar/egohumans?style=flat)](https://github.com/rawalkhirodkar/egohumans) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Khirodkar_Ego-Humans_An_Ego-Centric_3D_Multi-Human_Benchmark_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.16487-b31b1b.svg)](https://arxiv.org/abs/2305.16487) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TsLxINpWXR8) |
| Once Detected, Never Lost: Surpassing Human Performance in Offline LiDAR based 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/tusen-ai/SST?style=flat)](https://github.com/tusen-ai/SST) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Once_Detected_Never_Lost_Surpassing_Human_Performance_in_Offline_LiDAR_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.12315-b31b1b.svg)](https://arxiv.org/abs/2304.12315) | :heavy_minus_sign: |
