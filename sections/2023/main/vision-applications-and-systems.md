# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/geometric-deep-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/machine-learning-and-dataset.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Vision Applications and Systems

![Section Papers](https://img.shields.io/badge/Section%20Papers-36-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-26-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-21-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-4-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Democratising 2D Sketch to 3D Shape Retrieval through Pivoting | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iM1A81QEhfw) |
| Towards Instance-Adaptive Inference for Federated Learning | [![GitHub](https://img.shields.io/github/stars/chunmeifeng/FedIns?style=flat)](https://github.com/chunmeifeng/FedIns) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Towards_Instance-adaptive_Inference_for_Federated_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06051-b31b1b.svg)](https://arxiv.org/abs/2308.06051) | :heavy_minus_sign: |
| TransTIC: Transferring Transformer-based Image Compression from Human Perception to Machine Perception | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.05085-b31b1b.svg)](https://arxiv.org/abs/2306.05085) | :heavy_minus_sign: |
| Counting Crowds in Bad Weather | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://awccnet.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/awccnet/AWCC-Net?style=flat)](https://github.com/awccnet/AWCC-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Counting_Crowds_in_Bad_Weather_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.01209-b31b1b.svg)](https://arxiv.org/abs/2306.01209) | :heavy_minus_sign: |
| NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chenfengxu714.github.io/nerfdet/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/NeRF-Det?style=flat)](https://github.com/facebookresearch/NeRF-Det) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_NeRF-Det_Learning_Geometry-Aware_Volumetric_Representation_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.14620-b31b1b.svg)](https://arxiv.org/abs/2307.14620) | :heavy_minus_sign: |
| MEGA: Multimodal Alignment Aggregation and Distillation for Cinematic Video Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sadoughi_MEGA_Multimodal_Alignment_Aggregation_and_Distillation_For_Cinematic_Video_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11185-b31b1b.svg)](https://arxiv.org/abs/2308.11185) | :heavy_minus_sign: |
| Bring Clipart to Life | [![GitHub](https://img.shields.io/github/stars/dangsq/ClipFaceShop?style=flat)](https://github.com/dangsq/ClipFaceShop) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Bring_Clipart_to_Life_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| UpCycling: Semi-Supervised 3D Object Detection without Sharing Raw-Level Unlabeled Scenes | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_UpCycling_Semi-supervised_3D_Object_Detection_without_Sharing_Raw-level_Unlabeled_Scenes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11950-b31b1b.svg)](https://arxiv.org/abs/2211.11950) | :heavy_minus_sign: |
| Graph Matching with Bi-Level Noisy Correspondence | [![GitHub](https://img.shields.io/github/stars/XLearning-SCU/2023-ICCV-COMMON?style=flat)](https://github.com/XLearning-SCU/2023-ICCV-COMMON) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Graph_Matching_with_Bi-level_Noisy_Correspondence_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04085-b31b1b.svg)](https://arxiv.org/abs/2212.04085) | :heavy_minus_sign: |
| Anomaly Detection using Score-based Perturbation Resilience | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_Anomaly_Detection_using_Score-based_Perturbation_Resilience_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ydk122024.github.io/SCOPE/) <br /> [![GitHub](https://img.shields.io/github/stars/starfdu1418/SCOPE?style=flat)](https://github.com/starfdu1418/SCOPE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Spatio-Temporal_Domain_Awareness_for_Multi-Agent_Collaborative_Perception_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13929-b31b1b.svg)](https://arxiv.org/abs/2307.13929) | :heavy_minus_sign: |
| Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing | [![GitHub](https://img.shields.io/github/stars/aimagelab/multimodal-garment-designer?style=flat)](https://github.com/aimagelab/multimodal-garment-designer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02051-b31b1b.svg)](https://arxiv.org/abs/2304.02051) | :heavy_minus_sign: |
| Towards Unifying Medical Vision-and-Language Pre-Training via Soft Prompts | [![GitHub](https://img.shields.io/github/stars/zhjohnchan/ptunifier?style=flat)](https://github.com/zhjohnchan/ptunifier) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Towards_Unifying_Medical_Vision-and-Language_Pre-Training_via_Soft_Prompts_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.08958-b31b1b.svg)](https://arxiv.org/abs/2302.08958) | :heavy_minus_sign: |
| MAS: Towards Resource-Efficient Federated Multiple-Task Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhuang_MAS_Towards_Resource-Efficient_Federated_Multiple-Task_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11285-b31b1b.svg)](https://arxiv.org/abs/2307.11285) | :heavy_minus_sign: |
| Hierarchical Visual Categories Modeling: A Joint Representation Learning and Density Estimation Framework for Out-of-Distribution Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Hierarchical_Visual_Categories_Modeling_A_Joint_Representation_Learning_and_Density_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Improving Generalization in Visual Reinforcement Learning via Conflict-Aware Gradient Agreement Augmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Improving_Generalization_in_Visual_Reinforcement_Learning_via_Conflict-aware_Gradient_Agreement_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.01194-b31b1b.svg)](https://arxiv.org/abs/2308.01194) | :heavy_minus_sign: |
| Tiny Updater: Towards Efficient Neural Network-Driven Software Updating | [![GitHub](https://img.shields.io/github/stars/ArchipLab-LinfengZhang/TinyUpdater?style=flat)](https://github.com/ArchipLab-LinfengZhang/TinyUpdater) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Tiny_Updater_Towards_Efficient_Neural_Network-Driven_Software_Updating_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Multiple Planar Object Tracking | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://zzcheng.top/MPOT/) <br /> [![GitHub](https://img.shields.io/github/stars/nku-zhichengzhang/MPOT?style=flat)](https://github.com/nku-zhichengzhang/MPOT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multiple_Planar_Object_Tracking_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1kE_VJgM4u8) |
| OmnimatteRF: Robust Omnimatte with 3D Background Modeling | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://omnimatte-rf.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/OmnimatteRF?style=flat)](https://github.com/facebookresearch/OmnimatteRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.07749-b31b1b.svg)](https://arxiv.org/abs/2309.07749) | :heavy_minus_sign: |
| Ordinal Label Distribution Learning | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://downdric23.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Ordinal_Label_Distribution_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Re-Mine, Learn and Reason: Exploring the Cross-Modal Semantic Correlations for Language-Guided HOI Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Re-mine_Learn_and_Reason_Exploring_the_Cross-modal_Semantic_Correlations_for_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13529-b31b1b.svg)](https://arxiv.org/abs/2307.13529) | :heavy_minus_sign: |
| MUVA: A New Large-Scale Benchmark for Multi-View Amodal Instance Segmentation in the Shopping Scenario | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zhixuanli.github.io/project_2023_ICCV_MUVA/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MUVA_A_New_Large-Scale_Benchmark_for_Multi-View_Amodal_Instance_Segmentation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Editable Image Geometric Abstraction via Neural Primitive Assembly | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Editable_Image_Geometric_Abstraction_via_Neural_Primitive_Assembly_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| One-Shot Recognition of any Material Anywhere using Contrastive Learning with Physics-based Rendering | [![GitHub](https://img.shields.io/github/stars/ZuseZ4/MatSim-Dataset-Generator-Scripts-And-Neural-net?style=flat)](https://github.com/ZuseZ4/MatSim-Dataset-Generator-Scripts-And-Neural-net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Drehwald_One-Shot_Recognition_of_Any_Material_Anywhere_Using_Contrastive_Learning_with_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00648-b31b1b.svg)](https://arxiv.org/abs/2212.00648) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=sXN3jmqv2SM) |
| Fast Full-Frame Video Stabilization with Iterative Optimization | [![GitHub](https://img.shields.io/github/stars/zwyking/Fast-Stab?style=flat)](https://github.com/zwyking/Fast-Stab) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fast_Full-frame_Video_Stabilization_with_Iterative_Optimization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12774-b31b1b.svg)](https://arxiv.org/abs/2307.12774) | :heavy_minus_sign: |
| Two Birds, One Stone: A Unified Framework for Joint Learning of Image and Video Style Transfers | [![GitHub](https://img.shields.io/github/stars/NevSNev/UniST?style=flat)](https://github.com/NevSNev/UniST) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Two_Birds_One_Stone_A_Unified_Framework_for_Joint_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11335-b31b1b.svg)](https://arxiv.org/abs/2304.11335) | :heavy_minus_sign: |
| Multi-Modal Gated Mixture of Local-to-Global Experts for Dynamic Image Fusion | [![GitHub](https://img.shields.io/github/stars/SunYM2020/MoE-Fusion?style=flat)](https://github.com/SunYM2020/MoE-Fusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.01392-b31b1b.svg)](https://arxiv.org/abs/2302.01392) | :heavy_minus_sign: |
| SAFE: Sensitivity-Aware Features for Out-of-Distribution Object Detection | [![GitHub](https://img.shields.io/github/stars/SamWilso/SAFE_Official?style=flat)](https://github.com/SamWilso/SAFE_Official) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wilson_SAFE_Sensitivity-Aware_Features_for_Out-of-Distribution_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.13930-b31b1b.svg)](https://arxiv.org/abs/2208.13930) | :heavy_minus_sign: |
| GeT: Generative Target Structure Debiasing for Domain Adaptation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lulusindazc.github.io/getproject/) <br /> [![GitHub](https://img.shields.io/github/stars/lulusindazc/Get?style=flat)](https://github.com/lulusindazc/Get) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GeT_Generative_Target_Structure_Debiasing_for_Domain_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10205-b31b1b.svg)](https://arxiv.org/abs/2308.10205) | :heavy_minus_sign: |
| HairCLIPv2: Unifying Hair Editing via Proxy Feature Blending | [![GitHub](https://img.shields.io/github/stars/wty-ustc/HairCLIPv2?style=flat)](https://github.com/wty-ustc/HairCLIPv2) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_HairCLIPv2_Unifying_Hair_Editing_via_Proxy_Feature_Blending_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.10651-b31b1b.svg)](https://arxiv.org/abs/2310.10651) | :heavy_minus_sign: |
| Deformer: Dynamic Fusion Transformer for Robust Hand Pose Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://fuqichen1998.github.io/Deformer/) <br /> [![GitHub](https://img.shields.io/github/stars/fuqichen1998/Deformer?style=flat)](https://github.com/fuqichen1998/Deformer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Deformer_Dynamic_Fusion_Transformer_for_Robust_Hand_Pose_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.04991-b31b1b.svg)](https://arxiv.org/abs/2303.04991) | :heavy_minus_sign: |
| Improving Continuous Sign Language Recognition with Cross-Lingual Signs | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10809-b31b1b.svg)](https://arxiv.org/abs/2308.10809) | :heavy_minus_sign: |
| A Parse-then-Place Approach for Generating Graphic Layouts from Textual Descriptions | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_A_Parse-Then-Place_Approach_for_Generating_Graphic_Layouts_from_Textual_Descriptions_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12700-b31b1b.svg)](https://arxiv.org/abs/2308.12700) | :heavy_minus_sign: |
| DISeR: Designing Imaging Systems with Reinforcement Learning | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tzofi.github.io/diser/) <br /> [![GitHub](https://img.shields.io/github/stars/tzofi/diser?style=flat)](https://github.com/tzofi/diser) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_DISeR_Designing_Imaging_Systems_with_Reinforcement_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13851-b31b1b.svg)](https://arxiv.org/abs/2309.13851) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Lm80OZh5eDg) |
| Segmentation of Tubular Structures using Iterative Training with Tailored Samples | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_Segmentation_of_Tubular_Structures_Using_Iterative_Training_with_Tailored_Samples_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08727-b31b1b.svg)](https://arxiv.org/abs/2309.08727) | :heavy_minus_sign: |
| Time-to-Contact Map by Joint Estimation of Up-to-Scale Inverse Depth and Global Motion using a Single Event Camera | [![GitHub](https://img.shields.io/github/stars/neuromorphic-paris/ETTCM?style=flat)](https://github.com/neuromorphic-paris/ETTCM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nunes_Time-to-Contact_Map_by_Joint_Estimation_of_Up-to-Scale_Inverse_Depth_and_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
