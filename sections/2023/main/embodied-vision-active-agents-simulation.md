# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/computational-imaging.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/recognition-retrieval.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Embodied Vision: Active Agents, Simulation

![Section Papers](https://img.shields.io/badge/Section%20Papers-15-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-14-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-8-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-6-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Skill Transformer: A Monolithic Policy for Mobile Manipulation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Skill_Transformer_A_Monolithic_Policy_for_Mobile_Manipulation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09873-b31b1b.svg)](https://arxiv.org/abs/2308.09873) | :heavy_minus_sign: |
| ENTL: Embodied Navigation Trajectory Learner | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kotar_ENTL_Embodied_Navigation_Trajectory_Learner_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02639-b31b1b.svg)](https://arxiv.org/abs/2304.02639) | :heavy_minus_sign: |
| DREAMWALKER: Mental Planning for Continuous Vision-Language Navigation | [![GitHub](https://img.shields.io/github/stars/hanqingwangai/Dreamwalker?style=flat)](https://github.com/hanqingwangai/Dreamwalker) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DREAMWALKER_Mental_Planning_for_Continuous_Vision-Language_Navigation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07498-b31b1b.svg)](https://arxiv.org/abs/2308.07498) | :heavy_minus_sign: |
| Scene Graph Contrastive Learning for Embodied Navigation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Scene_Graph_Contrastive_Learning_for_Embodied_Navigation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Perpetual Humanoid Control for Real-Time Simulated Avatars | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zhengyiluo.github.io/PHC/) <br /> [![GitHub](https://img.shields.io/github/stars/DelinQu/qrsc?style=flat)](https://github.com/DelinQu/qrsc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Perpetual_Humanoid_Control_for_Real-time_Simulated_Avatars_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.06456-b31b1b.svg)](https://arxiv.org/abs/2305.06456) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zS6Y00EW37A) |
| Grounding 3D Object Affordance from 2D Interactions in Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yyvhang.github.io/publications/IAG/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/yyvhang/IAGNet?style=flat)](https://github.com/yyvhang/IAGNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10437-b31b1b.svg)](https://arxiv.org/abs/2303.10437) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GfCPUM1nAHI) |
| Navigating to Objects Specified by Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jacobkrantz.github.io/modular_iin) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Krantz_Navigating_to_Objects_Specified_by_Images_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01192-b31b1b.svg)](https://arxiv.org/abs/2304.01192) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=273jjBvu48s) |
| PEANUT: Predicting and Navigating to Unseen Targets | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ajzhai.github.io/PEANUT/) <br /> [![GitHub](https://img.shields.io/github/stars/ajzhai/PEANUT?style=flat)](https://github.com/ajzhai/PEANUT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_PEANUT_Predicting_and_Navigating_to_Unseen_Targets_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02497-b31b1b.svg)](https://arxiv.org/abs/2212.02497) | :heavy_minus_sign: |
| Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Context-Aware_Planning_and_Environment-Aware_Memory_for_Instruction_Following_Embodied_Agents_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07241-b31b1b.svg)](https://arxiv.org/abs/2308.07241) | :heavy_minus_sign: |
| Learning Foresightful Dense Visual Affordance for Deformable Object Manipulation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://hyperplane-lab.github.io/DeformableAffordance/) <br /> [![GitHub](https://img.shields.io/github/stars/TritiumR/DeformableAffordance?style=flat)](https://github.com/TritiumR/DeformableAffordance) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Foresightful_Dense_Visual_Affordance_for_Deformable_Object_Manipulation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11057-b31b1b.svg)](https://arxiv.org/abs/2303.11057) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aYneBzwhOGs) |
| Exploiting Proximity-Aware Tasks for Embodied Social Navigation | [![GitHub](https://img.shields.io/github/stars/EnricoCancelli/ProximitySocialNav?style=flat)](https://github.com/EnricoCancelli/ProximitySocialNav) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cancelli_Exploiting_Proximity-Aware_Tasks_for_Embodied_Social_Navigation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00767-b31b1b.svg)](https://arxiv.org/abs/2212.00767) | :heavy_minus_sign: |
| Bird's-Eye-View Scene Graph for Vision-Language Navigation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Birds-Eye-View_Scene_Graph_for_Vision-Language_Navigation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04758-b31b1b.svg)](https://arxiv.org/abs/2308.04758) | :heavy_minus_sign: |
| Active Neural Mapping | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Active_Neural_Mapping_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.16246-b31b1b.svg)](https://arxiv.org/abs/2308.16246) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=psPvanfh7SA) |
| Omnidirectional Information Gathering for Knowledge Transfer-based Audio-Visual Navigation | [![GitHub](https://img.shields.io/github/stars/chenjinyubuaa/ORAN?style=flat)](https://github.com/chenjinyubuaa/ORAN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Omnidirectional_Information_Gathering_for_Knowledge_Transfer-Based_Audio-Visual_Navigation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10306-b31b1b.svg)](https://arxiv.org/abs/2308.10306) | :heavy_minus_sign: |
| Multi-Object Navigation with Dynamically Learned Neural Implicit Representations | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pierremarza.github.io/projects/dynamic_implicit_representations/) <br /> [![GitHub](https://img.shields.io/github/stars/PierreMarza/dynamic_implicit_representations?style=flat)](https://github.com/PierreMarza/dynamic_implicit_representations) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Marza_Multi-Object_Navigation_with_Dynamically_Learned_Neural_Implicit_Representations_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.05129-b31b1b.svg)](https://arxiv.org/abs/2210.05129) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=r_F9M80GPUI) |
