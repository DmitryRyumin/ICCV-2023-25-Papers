# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/3d-shape-modeling-and-processing.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/transfer-low-shot-and-continual-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
    </a>
</div>

## Human Pose/Shape Estimation

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| EMDB: The Electromagnetic Database of Global 3D Human Pose and Shape in the Wild | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://eth-ait.github.io/emdb/) <br /> [![GitHub](https://img.shields.io/github/stars/eth-ait/emdb)](https://github.com/eth-ait/emdb) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kaufmann_EMDB_The_Electromagnetic_Database_of_Global_3D_Human_Pose_and_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.16894-b31b1b.svg)](https://arxiv.org/abs/2308.16894) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=H66-YE4GUHI) |
| ReFit: Recurrent Fitting Network for 3D Human Recovery | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yufu-wang.github.io/refit_humans/) <br /> [![GitHub](https://img.shields.io/github/stars/yufu-wang/ReFit)](https://github.com/yufu-wang/ReFit) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ReFit_Recurrent_Fitting_Network_for_3D_Human_Recovery_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11184-b31b1b.svg)](https://arxiv.org/abs/2308.11184) | :heavy_minus_sign: |
| Global Adaptation Meets Local Generalization: Unsupervised Domain Adaptation for 3D Human Pose Estimation | [![GitHub](https://img.shields.io/github/stars/rese1f/PoseDA)](https://github.com/rese1f/PoseDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_Global_Adaptation_Meets_Local_Generalization_Unsupervised_Domain_Adaptation_for_3D_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16456-b31b1b.svg)](https://arxiv.org/abs/2303.16456) | :heavy_minus_sign: |
| Spectral Graphormer: Spectral Graph-based Transformer for Egocentric Two-Hand Reconstruction using Multi-View Color Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://eldentse.github.io/Spectral-Graphormer/) <br /> [![GitHub](https://img.shields.io/github/stars/eldentse/Spectral-Graphormer)](https://github.com/eldentse/Spectral-Graphormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tse_Spectral_Graphormer_Spectral_Graph-Based_Transformer_for_Egocentric_Two-Hand_Reconstruction_using_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11015-b31b1b.svg)](https://arxiv.org/abs/2308.11015) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cfsk5e5C_Xs) |
| Realistic Full-Body Tracking from Sparse Observations via Joint-Level Modeling | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zxz267.github.io/AvatarJLM/) <br /> [![GitHub](https://img.shields.io/github/stars/zxz267/AvatarJLM)](https://github.com/zxz267/AvatarJLM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Realistic_Full-Body_Tracking_from_Sparse_Observations_via_Joint-Level_Modeling_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.08855-b31b1b.svg)](https://arxiv.org/abs/2308.08855) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=H2sPFL0T3yk) |
| Rethinking Pose Estimation in Crowds: Overcoming the Detection Information Bottleneck and Ambiguity | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://amathislab.github.io/BUCTD/) <br /> [![GitHub](https://img.shields.io/github/stars/amathislab/BUCTD)](https://github.com/amathislab/BUCTD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07879-b31b1b.svg)](https://arxiv.org/abs/2306.07879) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=BHZnA-CZeZY) |
| HDG-ODE: A Hierarchical Continuous-Time Model for Human Pose Forecasting | [![GitHub](https://img.shields.io/github/stars/SBU-YCX/HDG-ODE)](https://github.com/SBU-YCX/HDG-ODE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xing_HDG-ODE_A_Hierarchical_Continuous-Time_Model_for_Human_Pose_Forecasting_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| AffordPose: A Large-Scale Dataset of Hand-Object Interactions with Affordance-Driven Hand Pose | [![GitHub](https://img.shields.io/github/stars/GentlesJan/AffordPose)](https://github.com/GentlesJan/AffordPose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_AffordPose_A_Large-Scale_Dataset_of_Hand-Object_Interactions_with_Affordance-Driven_Hand_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08942-b31b1b.svg)](https://arxiv.org/abs/2309.08942) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s89tlzoM_M0) |
| PhaseMP: Robust 3D Pose Estimation via Phase-Conditioned Human Motion Prior | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PhaseMP_Robust_3D_Pose_Estimation_via_Phase-conditioned_Human_Motion_Prior_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Synthesizing Diverse Human Motions in 3D Indoor Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zkf1997.github.io/DIMOS/) <br /> [![GitHub](https://img.shields.io/github/stars/zkf1997/DIMOS)](https://github.com/zkf1997/DIMOS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Synthesizing_Diverse_Human_Motions_in_3D_Indoor_Scenes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.12411-b31b1b.svg)](https://arxiv.org/abs/2305.12411) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=O3VpvETNjcw) |
| TEMPO: Efficient Multi-View Pose Estimation, Tracking, and Forecasting | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rccchoudhury.github.io/tempo2023/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Choudhury_TEMPO_Efficient_Multi-View_Pose_Estimation_Tracking_and_Forecasting_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.07910-b31b1b.svg)](https://arxiv.org/abs/2309.07910) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jxmBQqmVkIw) |
<!-- | Diffusion-based 3D Human Pose Estimation with Multi-Hypothesis Aggregation |  |  |  |
| Towards Robust and Smooth 3D Multi-Person Pose Estimation from Monocular Videos in the Wild |  |  |  |
| Humans in 4D: Reconstructing and Tracking Humans with Transformers |  |  |  |
| NPC: Neural Point Characters from Video |  |  |  |
| Priority-Centric Human Motion Generation in Discrete Latent Space |  |  |  |
| NCHO: Unsupervised Learning for Neural 3D Composition of Humans and Objects |  |  |  |
| Cyclic Test-Time Adaptation on Monocular Video for 3D Human Mesh Reconstruction |  |  |  |
| MHEntropy: Entropy Meets Multiple Hypotheses for Pose and Shape Recovery |  |  |  |
| Probabilistic Triangulation for Uncalibrated Multi-View 3D Human Pose Estimation |  |  |  |
| DiffPose: SpatioTemporal Diffusion Model for Video-Based Human Pose Estimation |  |  |  |
| Reconstructing Groups of People with Hypergraph Relational Reasoning |  |  |  |
| MixSynthFormer: A Transformer Encoder-Like Structure with Mixed Synthetic Self-Attention for Efficient Human Pose Estimation |  |  |  |
| Dynamic Hyperbolic Attention Network for Fine Hand-Object Reconstruction |  |  |  |
| Human from Blur: Human Pose Tracking from Blurry Images |  |  |  |
| AG3D: Learning to Generate 3D Avatars from 2D Image Collections |  |  |  |
| InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion |  |  |  |
| SEFD: Learning to Distill Complex Pose and Occlusion |  |  |  |
| 3D Human Mesh Recovery with Sequentially Global Rotation Estimation |  |  |  |
| Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video |  |  |  |
| PHRIT: Parametric Hand Representation with Implicit Template |  |  |  |
| HopFIR: Hop-Wise GraphFormer with Intragroup Joint Refinement for 3D Human Pose Estimation |  |  |  |
| PriorGuided Source-Free Domain Adaptation for Human Pose Estimation |  |  |  |
| Cloth2Body: Generating 3D Human Body Mesh from 2D Clothing |  |  |  |
| PoseFix: Correcting 3D Human Poses with Natural Language |  |  |  |
| Group Pose: A Simple Baseline for End-to-End Multi-Person Pose Estimation |  |  |  |
| Make-an-Animation: Large-Scale Text-Conditional 3D Human Motion Generation |  |  |  |
| NSF: Neural Surface Fields for Human Modeling from Monocular Depth |  |  |  |
| Hierarchical Generation of Human-Object Interactions with Diffusion Probabilistic Models |  |  |  |
| Dynamic Mesh Recovery from Partial Point Cloud Sequence |  |  |  |
| MotionBERT: A Unified Perspective on Learning Human Motion Representations |  |  |  |
| Novel-View Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views |  |  |  |
| OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision |  |  |  |
| Neural Interactive Keypoint Detection |  |  |  |
| Plausible Uncertainties for Human Pose Regression |  |  |  |
| TORE: Token Reduction for Efficient Human Mesh Recovery with Transformer |  |  |  |
| Weakly-Supervised 3D Pose Transfer with Keypoints |  |  |  | -->
