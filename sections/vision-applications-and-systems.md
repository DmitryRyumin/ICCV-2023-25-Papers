# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/geometric-deep-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/machine-learning-and-dataset.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
    </a>
</div>

## Vision Applications and Systems

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Democratising 2D Sketch to 3D Shape Retrieval through Pivoting | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iM1A81QEhfw) |
| Towards Instance-Adaptive Inference for Federated Learning | [![GitHub](https://img.shields.io/github/stars/chunmeifeng/FedIns)](https://github.com/chunmeifeng/FedIns) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Towards_Instance-adaptive_Inference_for_Federated_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06051-b31b1b.svg)](https://arxiv.org/abs/2308.06051) | :heavy_minus_sign: |
| TransTIC: Transferring Transformer-based Image Compression from Human Perception to Machine Perception |  |  |  |
| Counting Crowds in Bad Weather |  |  |  |
| NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection |  |  |  |
| MEGA: Multimodal Alignment Aggregation and Distillation for Cinematic Video Segmentation |  |  |  |
| Bring Clipart to Life |  |  |  |
| UpCycling: Semi-Supervised 3D Object Detection without Sharing Raw-Level Unlabeled Scenes |  |  |  |
| Graph Matching with Bi-Level Noisy Correspondence |  |  |  |
| Anomaly Detection using Score-based Perturbation Resilience |  |  |  |
| Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception |  |  |  |
| Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing | [![GitHub](https://img.shields.io/github/stars/aimagelab/multimodal-garment-designer)](https://github.com/aimagelab/multimodal-garment-designer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02051-b31b1b.svg)](https://arxiv.org/abs/2304.02051) | :heavy_minus_sign: |
| Towards Unifying Medical Vision-and-Language Pre-Training via Soft Prompts |  |  |  |
| MAS: Towards Resource-Efficient Federated Multiple-Task Learning |  |  |  |
| Hierarchical Visual Categories Modeling: A Joint Representation Learning and Density Estimation Framework for Out-of-Distribution Detection |  |  |  |
| Improving Generalization in Visual Reinforcement Learning via Conflict-Aware Gradient Agreement Augmentation |  |  |  |
| Tiny Updater: Towards Efficient Neural Network-Driven Software Updating |  |  |  |
| Multiple Planar Object Tracking |  |  |  |
| OmnimatteRF: Robust Omnimatte with 3D Background Modeling |  |  |  |
| Ordinal Label Distribution Learning |  |  |  |
| Re-Mine, Learn and Reason: Exploring the Cross-Modal Semantic Correlations for Language-Guided HOI Detection |  |  |  |
| MUVA: A New Large-Scale Benchmark for Multi-View Amodal Instance Segmentation in the Shopping Scenario |  |  |  |
| Editable Image Geometric Abstraction via Neural Primitive Assembly |  |  |  |
| One-Shot Recognition of any Material Anywhere using Contrastive Learning with Physics-based Rendering |  |  |  |
| Fast Full-Frame Video Stabilization with Iterative Optimization |  |  |  |
| Two Birds, One Stone: A Unified Framework for Joint Learning of Image and Video Style Transfers |  |  |  |
| Multi-Modal Gated Mixture of Local-to-Global Experts for Dynamic Image Fusion |  |  |  |
| SAFE: Sensitivity-Aware Features for Out-of-Distribution Object Detection |  |  |  |
| GeT: Generative Target Structure Debiasing for Domain Adaptation |  |  |  |
| HairCLIPv2: Unifying Hair Editing via Proxy Feature Blending |  |  |  |
| Deformer: Dynamic Fusion Transformer for Robust Hand Pose Estimation |  |  |  |
| Improving Continuous Sign Language Recognition with Cross-Lingual Signs | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10809-b31b1b.svg)](https://arxiv.org/abs/2308.10809) | :heavy_minus_sign: |
| A Parse-then-Place Approach for Generating Graphic Layouts from Textual Descriptions | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_A_Parse-Then-Place_Approach_for_Generating_Graphic_Layouts_from_Textual_Descriptions_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12700-b31b1b.svg)](https://arxiv.org/abs/2308.12700) | :heavy_minus_sign: |
| DISeR: Designing Imaging Systems with Reinforcement Learning | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tzofi.github.io/diser/) <br /> [![GitHub](https://img.shields.io/github/stars/tzofi/diser)](https://github.com/tzofi/diser) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_DISeR_Designing_Imaging_Systems_with_Reinforcement_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13851-b31b1b.svg)](https://arxiv.org/abs/2309.13851) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Lm80OZh5eDg) |
| Segmentation of Tubular Structures using Iterative Training with Tailored Samples | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_Segmentation_of_Tubular_Structures_Using_Iterative_Training_with_Tailored_Samples_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08727-b31b1b.svg)](https://arxiv.org/abs/2309.08727) | :heavy_minus_sign: |
| Time-to-Contact Map by Joint Estimation of Up-to-Scale Inverse Depth and Global Motion using a Single Event Camera | [![GitHub](https://img.shields.io/github/stars/neuromorphic-paris/ETTCM)](https://github.com/neuromorphic-paris/ETTCM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nunes_Time-to-Contact_Map_by_Joint_Estimation_of_Up-to-Scale_Inverse_Depth_and_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
