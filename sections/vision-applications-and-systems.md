# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/geometric-deep-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/machine-learning-and-dataset.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
    </a>
</div>

## Vision Applications and Systems

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Democratising 2D Sketch to 3D Shape Retrieval through Pivoting | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iM1A81QEhfw) |
| Towards Instance-Adaptive Inference for Federated Learning | [![GitHub](https://img.shields.io/github/stars/chunmeifeng/FedIns)](https://github.com/chunmeifeng/FedIns) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Towards_Instance-adaptive_Inference_for_Federated_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06051-b31b1b.svg)](https://arxiv.org/abs/2308.06051) | :heavy_minus_sign: |
| TransTIC: Transferring Transformer-based Image Compression from Human Perception to Machine Perception | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.05085-b31b1b.svg)](https://arxiv.org/abs/2306.05085) | :heavy_minus_sign: |
| Counting Crowds in Bad Weather | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://awccnet.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/awccnet/AWCC-Net)](https://github.com/awccnet/AWCC-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Counting_Crowds_in_Bad_Weather_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.01209-b31b1b.svg)](https://arxiv.org/abs/2306.01209) | :heavy_minus_sign: |
| NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chenfengxu714.github.io/nerfdet/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/NeRF-Det)](https://github.com/facebookresearch/NeRF-Det) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_NeRF-Det_Learning_Geometry-Aware_Volumetric_Representation_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.14620-b31b1b.svg)](https://arxiv.org/abs/2307.14620) | :heavy_minus_sign: |
| MEGA: Multimodal Alignment Aggregation and Distillation for Cinematic Video Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sadoughi_MEGA_Multimodal_Alignment_Aggregation_and_Distillation_For_Cinematic_Video_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11185-b31b1b.svg)](https://arxiv.org/abs/2308.11185) | :heavy_minus_sign: |
| Bring Clipart to Life | [![GitHub](https://img.shields.io/github/stars/dangsq/ClipFaceShop)](https://github.com/dangsq/ClipFaceShop) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Bring_Clipart_to_Life_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| UpCycling: Semi-Supervised 3D Object Detection without Sharing Raw-Level Unlabeled Scenes | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_UpCycling_Semi-supervised_3D_Object_Detection_without_Sharing_Raw-level_Unlabeled_Scenes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11950-b31b1b.svg)](https://arxiv.org/abs/2211.11950) | :heavy_minus_sign: |
| Graph Matching with Bi-Level Noisy Correspondence | [![GitHub](https://img.shields.io/github/stars/XLearning-SCU/2023-ICCV-COMMON)](https://github.com/XLearning-SCU/2023-ICCV-COMMON) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Graph_Matching_with_Bi-level_Noisy_Correspondence_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04085-b31b1b.svg)](https://arxiv.org/abs/2212.04085) | :heavy_minus_sign: |
| Anomaly Detection using Score-based Perturbation Resilience | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_Anomaly_Detection_using_Score-based_Perturbation_Resilience_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ydk122024.github.io/SCOPE/) <br /> [![GitHub](https://img.shields.io/github/stars/starfdu1418/SCOPE)](https://github.com/starfdu1418/SCOPE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Spatio-Temporal_Domain_Awareness_for_Multi-Agent_Collaborative_Perception_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13929-b31b1b.svg)](https://arxiv.org/abs/2307.13929) | :heavy_minus_sign: |
| Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing | [![GitHub](https://img.shields.io/github/stars/aimagelab/multimodal-garment-designer)](https://github.com/aimagelab/multimodal-garment-designer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02051-b31b1b.svg)](https://arxiv.org/abs/2304.02051) | :heavy_minus_sign: |
| Towards Unifying Medical Vision-and-Language Pre-Training via Soft Prompts |  |  |  |
| MAS: Towards Resource-Efficient Federated Multiple-Task Learning |  |  |  |
| Hierarchical Visual Categories Modeling: A Joint Representation Learning and Density Estimation Framework for Out-of-Distribution Detection |  |  |  |
| Improving Generalization in Visual Reinforcement Learning via Conflict-Aware Gradient Agreement Augmentation |  |  |  |
| Tiny Updater: Towards Efficient Neural Network-Driven Software Updating |  |  |  |
| Multiple Planar Object Tracking |  |  |  |
| OmnimatteRF: Robust Omnimatte with 3D Background Modeling |  |  |  |
| Ordinal Label Distribution Learning |  |  |  |
| Re-Mine, Learn and Reason: Exploring the Cross-Modal Semantic Correlations for Language-Guided HOI Detection |  |  |  |
| MUVA: A New Large-Scale Benchmark for Multi-View Amodal Instance Segmentation in the Shopping Scenario |  |  |  |
| Editable Image Geometric Abstraction via Neural Primitive Assembly |  |  |  |
| One-Shot Recognition of any Material Anywhere using Contrastive Learning with Physics-based Rendering |  |  |  |
| Fast Full-Frame Video Stabilization with Iterative Optimization |  |  |  |
| Two Birds, One Stone: A Unified Framework for Joint Learning of Image and Video Style Transfers |  |  |  |
| Multi-Modal Gated Mixture of Local-to-Global Experts for Dynamic Image Fusion |  |  |  |
| SAFE: Sensitivity-Aware Features for Out-of-Distribution Object Detection |  |  |  |
| GeT: Generative Target Structure Debiasing for Domain Adaptation |  |  |  |
| HairCLIPv2: Unifying Hair Editing via Proxy Feature Blending |  |  |  |
| Deformer: Dynamic Fusion Transformer for Robust Hand Pose Estimation |  |  |  |
| Improving Continuous Sign Language Recognition with Cross-Lingual Signs | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10809-b31b1b.svg)](https://arxiv.org/abs/2308.10809) | :heavy_minus_sign: |
| A Parse-then-Place Approach for Generating Graphic Layouts from Textual Descriptions | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_A_Parse-Then-Place_Approach_for_Generating_Graphic_Layouts_from_Textual_Descriptions_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12700-b31b1b.svg)](https://arxiv.org/abs/2308.12700) | :heavy_minus_sign: |
| DISeR: Designing Imaging Systems with Reinforcement Learning | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tzofi.github.io/diser/) <br /> [![GitHub](https://img.shields.io/github/stars/tzofi/diser)](https://github.com/tzofi/diser) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_DISeR_Designing_Imaging_Systems_with_Reinforcement_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13851-b31b1b.svg)](https://arxiv.org/abs/2309.13851) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Lm80OZh5eDg) |
| Segmentation of Tubular Structures using Iterative Training with Tailored Samples | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_Segmentation_of_Tubular_Structures_Using_Iterative_Training_with_Tailored_Samples_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08727-b31b1b.svg)](https://arxiv.org/abs/2309.08727) | :heavy_minus_sign: |
| Time-to-Contact Map by Joint Estimation of Up-to-Scale Inverse Depth and Global Motion using a Single Event Camera | [![GitHub](https://img.shields.io/github/stars/neuromorphic-paris/ETTCM)](https://github.com/neuromorphic-paris/ETTCM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nunes_Time-to-Contact_Map_by_Joint_Estimation_of_Up-to-Scale_Inverse_Depth_and_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
