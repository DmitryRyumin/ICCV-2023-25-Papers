# ICCV-2023-Papers

## Transfer, Low-Shot, Continual, Long-Tail Learning

![Section Papers](https://img.shields.io/badge/Section%20Papers-43-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-36-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-27-1D7FBF)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| ImbSAM: A Closer Look at Sharpness-Aware Minimization in Class-Imbalanced Recognition | [![GitHub](https://img.shields.io/github/stars/cool-xuan/Imbalanced_SAM)](https://github.com/cool-xuan/Imbalanced_SAM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ImbSAM_A_Closer_Look_at_Sharpness-Aware_Minimization_in_Class-Imbalanced_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07815-b31b1b.svg)](https://arxiv.org/abs/2308.07815) | :heavy_minus_sign: |
| LFS-GAN: Lifelong Few-Shot Image Generation | [![GitHub](https://img.shields.io/github/stars/JJuOn/LFS-GAN)](https://github.com/JJuOn/LFS-GAN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11917-b31b1b.svg)](https://arxiv.org/abs/2308.11917) | :heavy_minus_sign: |
| Augmented Box Replay: Overcoming Foreground Shift for Incremental Object Detection | [![GitHub](https://img.shields.io/github/stars/YuyangSunshine/ABR_IOD)](https://github.com/YuyangSunshine/ABR_IOD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Augmented_Box_Replay_Overcoming_Foreground_Shift_for_Incremental_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12427-b31b1b.svg)](https://arxiv.org/abs/2307.12427) | :heavy_minus_sign: |
| Contrastive Model Adaptation for Cross-Condition Robustness in Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/brdav/cma)](https://github.com/brdav/cma) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bruggemann_Contrastive_Model_Adaptation_for_Cross-Condition_Robustness_in_Semantic_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05194-b31b1b.svg)](https://arxiv.org/abs/2303.05194) | :heavy_minus_sign: |
| Towards Effective Instance Discrimination Contrastive Loss for Unsupervised Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/zhyx12/EIDCo)](https://github.com/zhyx12/EIDCo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Effective_Instance_Discrimination_Contrastive_Loss_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2202.02802-b31b1b.svg)](https://arxiv.org/abs/2202.02802) | :heavy_minus_sign: |
| Adversarial Bayesian Augmentation for Single-Source Domain Generalization | [![GitHub](https://img.shields.io/github/stars/shengcheng/ABA)](https://github.com/shengcheng/ABA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Adversarial_Bayesian_Augmentation_for_Single-Source_Domain_Generalization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09520-b31b1b.svg)](https://arxiv.org/abs/2307.09520) | :heavy_minus_sign: |
| Measuring Asymmetric Gradient Discrepancy in Parallel Continual Learning | [![GitHub](https://img.shields.io/github/stars/fanlyu/maxdo)](https://github.com/fanlyu/maxdo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| CSDA: Learning Category-Scale Joint Feature for Domain Adaptive Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_CSDA_Learning_Category-Scale_Joint_Feature_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Distilling from Similar Tasks for Transfer Learning on a Budget | [![GitHub](https://img.shields.io/github/stars/Kennethborup/DistillWeighted)](https://github.com/Kennethborup/DistillWeighted) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Borup_Distilling_from_Similar_Tasks_for_Transfer_Learning_on_a_Budget_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.12314-b31b1b.svg)](https://arxiv.org/abs/2304.12314) | :heavy_minus_sign: |
| Complementary Domain Adaptation and Generalization for Unsupervised Continual Domain Shift Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Complementary_Domain_Adaptation_and_Generalization_for_Unsupervised_Continual_Domain_Shift_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15833-b31b1b.svg)](https://arxiv.org/abs/2303.15833) | :heavy_minus_sign: |
| Camera-Driven Representation Learning for Unsupervised Domain Adaptive Person Re-Identification | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cvlab.yonsei.ac.kr/projects/CaCL/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Camera-Driven_Representation_Learning_for_Unsupervised_Domain_Adaptive_Person_Re-identification_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11901-b31b1b.svg)](https://arxiv.org/abs/2308.11901) | :heavy_minus_sign: |
| Introducing Language Guidance in Prompt-based Continual Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_Introducing_Language_Guidance_in_Prompt-based_Continual_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.15827-b31b1b.svg)](https://arxiv.org/abs/2308.15827) | :heavy_minus_sign: |
| Fast and Accurate Transferability Measurement by Evaluating Intra-Class Feature Variance | [![GitHub](https://img.shields.io/github/stars/snudatalab/TMI)](https://github.com/snudatalab/TMI) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Fast_and_Accurate_Transferability_Measurement_by_Evaluating_Intra-class_Feature_Variance_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.05986-b31b1b.svg)](https://arxiv.org/abs/2308.05986) | :heavy_minus_sign: |
| A Unified Continual Learning Framework with General Parameter-Efficient Tuning | [![GitHub](https://img.shields.io/github/stars/gqk/LAE)](https://github.com/gqk/LAE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_A_Unified_Continual_Learning_Framework_with_General_Parameter-Efficient_Tuning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10070-b31b1b.svg)](https://arxiv.org/abs/2303.10070) | :heavy_minus_sign: |
| SFHarmony: Source Free Domain Adaptation for Distributed Neuroimaging Analysis | [![GitHub](https://img.shields.io/github/stars/nkdinsdale/SFHarmony)](https://github.com/nkdinsdale/SFHarmony) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dinsdale_SFHarmony_Source_Free_Domain_Adaptation_for_Distributed_Neuroimaging_Analysis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15965-b31b1b.svg)](https://arxiv.org/abs/2303.15965) | :heavy_minus_sign: |
| Towards Realistic Evaluation of Industrial Continual Learning Scenarios with an Emphasis on Energy Consumption and Computational Footprint | [![GitHub](https://img.shields.io/github/stars/Vivek9Chavan/RECIL)](https://github.com/Vivek9Chavan/RECIL) <br /> [![InVar](https://img.shields.io/badge/InVar-dataset-20BEFF.svg)](https://fordatis.fraunhofer.de/handle/fordatis/329.2) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chavan_Towards_Realistic_Evaluation_of_Industrial_Continual_Learning_Scenarios_with_an_ICCV_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TsWfYqz8qbk) |
| CDAC: Cross-Domain Attention Consistency in Transformer for Domain Adaptive Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/wangkaihong/CDAC)](https://github.com/wangkaihong/CDAC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CDAC_Cross-domain_Attention_Consistency_in_Transformer_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14703-b31b1b.svg)](https://arxiv.org/abs/2211.14703) | :heavy_minus_sign: |
| PC-Adapter: Topology-Aware Adapter for Efficient Domain Adaption on Point Clouds with Rectified Pseudo-Label | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_PC-Adapter_Topology-Aware_Adapter_for_Efficient_Domain_Adaption_on_Point_Clouds_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.16936-b31b1b.svg)](https://arxiv.org/abs/2309.16936) | :heavy_minus_sign: |
| DETA: Denoised Task Adaptation for Few-Shot Learning | [![GitHub](https://img.shields.io/github/stars/JimZAI/DETA)](https://github.com/JimZAI/DETA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06315-b31b1b.svg)](https://arxiv.org/abs/2303.06315) | :heavy_minus_sign: |
| Activate and Reject: Towards Safe Domain Generalization under Category Shift | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Activate_and_Reject_Towards_Safe_Domain_Generalization_under_Category_Shift_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Generalizable Decision Boundaries: Dualistic Meta-Learning for Open Set Domain Generalization | [![GitHub](https://img.shields.io/github/stars/zzwdx/MEDIC)](https://github.com/zzwdx/MEDIC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Generalizable_Decision_Boundaries_Dualistic_Meta-Learning_for_Open_Set_Domain_Generalization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09391-b31b1b.svg)](https://arxiv.org/abs/2308.09391) | :heavy_minus_sign: |
| Continual Zero-Shot Learning through Semantically Guided Generative Random Walks | [![GitHub](https://img.shields.io/github/stars/wx-zhang/IGCZSL)](https://github.com/wx-zhang/IGCZSL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Continual_Zero-Shot_Learning_through_Semantically_Guided_Generative_Random_Walks_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12366-b31b1b.svg)](https://arxiv.org/abs/2308.12366) | :heavy_minus_sign: |
| Zero-Shot Point Cloud Segmentation by Semantic-Visual Aware Synthesis | [![GitHub](https://img.shields.io/github/stars/leolyj/3DPC-GZSL)](https://github.com/leolyj/3DPC-GZSL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Point_Cloud_Segmentation_by_Semantic-Visual_Aware_Synthesis_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| MDCS: More Diverse Experts with Consistency Self-Distillation for Long-Tailed Recognition | [![GitHub](https://img.shields.io/github/stars/fistyee/MDCS)](https://github.com/fistyee/MDCS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MDCS_More_Diverse_Experts_with_Consistency_Self-distillation_for_Long-tailed_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09922-b31b1b.svg)](https://arxiv.org/abs/2308.09922) | :heavy_minus_sign: |
| Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02429-b31b1b.svg)](https://arxiv.org/abs/2309.02429) | :heavy_minus_sign: |
| Confidence-based Visual Dispersal for Few-Shot Unsupervised Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/Bostoncake/C-VisDiT)](https://github.com/Bostoncake/C-VisDiT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.15575-b31b1b.svg)](https://arxiv.org/abs/2309.15575) | :heavy_minus_sign: |
| BEV-DG: Cross-Modal Learning under Bird's-Eye View for Domain Generalization of 3D Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_BEV-DG_Cross-Modal_Learning_under_Birds-Eye_View_for_Domain_Generalization_of_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06530-b31b1b.svg)](https://arxiv.org/abs/2308.06530) | :heavy_minus_sign: |
| CDFSL-V: Cross-Domain Few-Shot Learning for Videos | [![GitHub](https://img.shields.io/github/stars/Sarinda251/CDFSL-V)](https://github.com/Sarinda251/CDFSL-V) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Samarasinghe_CDFSL-V_Cross-Domain_Few-Shot_Learning_for_Videos_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03989-b31b1b.svg)](https://arxiv.org/abs/2309.03989) | :heavy_minus_sign: |
| Energy-based Self-Training and Normalization for Unsupervised Domain Adaptation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Herath_Energy-based_Self-Training_and_Normalization_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Regularized Mask Tuning: Uncovering Hidden Knowledge in Pre-Trained Vision-Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wuw2019.github.io/R-AMT/) <br /> [![GitHub](https://img.shields.io/github/stars/wuw2019/R-AMT)](https://github.com/wuw2019/R-AMT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Regularized_Mask_Tuning_Uncovering_Hidden_Knowledge_in_Pre-Trained_Vision-Language_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15049-b31b1b.svg)](https://arxiv.org/abs/2307.15049) | :heavy_minus_sign: |
| NAPA-VQ: Neighborhood-Aware Prototype Augmentation with Vector Quantization for Continual Learning | [![GitHub](https://img.shields.io/github/stars/TamashaM/NAPA-VQ)](https://github.com/TamashaM/NAPA-VQ) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Malepathirana_NAPA-VQ_Neighborhood-Aware_Prototype_Augmentation_with_Vector_Quantization_for_Continual_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09297-b31b1b.svg)](https://arxiv.org/abs/2308.09297) | :heavy_minus_sign: |
| A Sentence Speaks a Thousand Images: Domain Generalization through Distilling CLIP with Language Guidance | [![GitHub](https://img.shields.io/github/stars/OoDBag/RISE)](https://github.com/OoDBag/RISE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_A_Sentence_Speaks_a_Thousand_Images_Domain_Generalization_through_Distilling_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.12530-b31b1b.svg)](https://arxiv.org/abs/2309.12530) | :heavy_minus_sign: |
| ViM: Vision Middleware for Unified Downstream Transferring | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_ViM_Vision_Middleware_for_Unified_Downstream_Transferring_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06911-b31b1b.svg)](https://arxiv.org/abs/2303.06911) | :heavy_minus_sign: |
| Learning to Learn: How to Continuously Teach Humans and Machines | [![GitHub](https://img.shields.io/github/stars/ZhangLab-DeepNeuroCogLab/Learning2Learn)](https://github.com/ZhangLab-DeepNeuroCogLab/Learning2Learn) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Learning_to_Learn_How_to_Continuously_Teach_Humans_and_Machines_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.15470-b31b1b.svg)](https://arxiv.org/abs/2211.15470) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xz1TSRAQCN4) |
| A Good Student is Cooperative and Reliable: CNN-Transformer Collaborative Learning for Semantic Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vlislab22.github.io/CTCL/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_A_Good_Student_is_Cooperative_and_Reliable_CNN-Transformer_Collaborative_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12574-b31b1b.svg)](https://arxiv.org/abs/2307.12574) | :heavy_minus_sign: |
| Online Class Incremental Learning on Stochastic Blurry Task Boundary via Mask and Visual Prompt Tuning | [![GitHub](https://img.shields.io/github/stars/moonjunyyy/Si-Blurry)](https://github.com/moonjunyyy/Si-Blurry) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_Online_Class_Incremental_Learning_on_Stochastic_Blurry_Task_Boundary_via_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09303-b31b1b.svg)](https://arxiv.org/abs/2308.09303) | :heavy_minus_sign: |
| Heterogeneous Forgetting Compensation for Class-Incremental Learning | [![GitHub](https://img.shields.io/github/stars/JiahuaDong/HFC)](https://github.com/JiahuaDong/HFC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Heterogeneous_Forgetting_Compensation_for_Class-Incremental_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03374-b31b1b.svg)](https://arxiv.org/abs/2308.03374) | :heavy_minus_sign: |
| Disposable Transfer Learning for Selective Source Task Unlearning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Koh_Disposable_Transfer_Learning_for_Selective_Source_Task_Unlearning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09971-b31b1b.svg)](https://arxiv.org/abs/2308.09971) | :heavy_minus_sign: |
| Online Continual Learning on Hierarchical Label Expansion | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Online_Continual_Learning_on_Hierarchical_Label_Expansion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14374-b31b1b.svg)](https://arxiv.org/abs/2308.14374) | :heavy_minus_sign: |
| Black-Box Unsupervised Domain Adaptation with Bi-Directional Atkinson-Shiffrin Memory | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13236-b31b1b.svg)](https://arxiv.org/abs/2308.13236) | :heavy_minus_sign: |
| Local and Global Logit Adjustments for Long-Tailed Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_Local_and_Global_Logit_Adjustments_for_Long-Tailed_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| FS-DETR: Few-Shot DEtection TRansformer with Prompting and without Re-Training | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.04845-b31b1b.svg)](https://arxiv.org/abs/2210.04845) | :heavy_minus_sign: |
| Tuning Pre-Trained Model via Moment Probing | [![GitHub](https://img.shields.io/github/stars/mingzeG/Moment-Probing)](https://github.com/mingzeG/Moment-Probing) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Tuning_Pre-trained_Model_via_Moment_Probing_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11342-b31b1b.svg)](https://arxiv.org/abs/2307.11342) | :heavy_minus_sign: |
