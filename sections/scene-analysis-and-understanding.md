# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/medical-and-biological-vision-cell-microscopy.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/multimodal-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
    </a>
</div>

## Scene Analysis and Understanding

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Generalized Few-Shot Point Cloud Segmentation via Geometric Words | [![GitHub](https://img.shields.io/github/stars/Pixie8888/GFS-3DSeg_GWs)](https://github.com/Pixie8888/GFS-3DSeg_GWs) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Generalized_Few-Shot_Point_Cloud_Segmentation_via_Geometric_Words_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.11222-b31b1b.svg)](https://arxiv.org/abs/2309.11222) | :heavy_minus_sign: |
| Boosting 3-DoF Ground-to-Satellite Camera Localization Accuracy via Geometry-Guided Cross-View Transformer | [![GitHub](https://img.shields.io/github/stars/shiyujiao/Boosting3DoFAccuracy)](https://github.com/shiyujiao/Boosting3DoFAccuracy) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Boosting_3-DoF_Ground-to-Satellite_Camera_Localization_Accuracy_via_Geometry-Guided_Cross-View_Transformer_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08015-b31b1b.svg)](https://arxiv.org/abs/2307.08015) | :heavy_minus_sign: |
| EP2P-Loc: End-to-End 3D Point to 2D Pixel Localization for Large-Scale Visual Localization | [![GitHub](https://img.shields.io/github/stars/minnjung/EP2P-Loc)](https://github.com/minnjung/EP2P-Loc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_EP2P-Loc_End-to-End_3D_Point_to_2D_Pixel_Localization_for_Large-Scale_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.07471-b31b1b.svg)](https://arxiv.org/abs/2309.07471) | :heavy_minus_sign: |
| Multi-Task View Synthesis with Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zsh2000.github.io/mtvs.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/zsh2000/MuvieNeRF)](https://github.com/zsh2000/MuvieNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Multi-task_View_Synthesis_with_Neural_Radiance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.17450-b31b1b.svg)](https://arxiv.org/abs/2309.17450) | :heavy_minus_sign: |
| Multi-Task Learning with Knowledge Distillation for Dense Prediction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World | [![GitHub](https://img.shields.io/github/stars/Yuqifan1117/CaCao)](https://github.com/Yuqifan1117/CaCao) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Visually-Prompted_Language_Model_for_Fine-Grained_Scene_Graph_Generation_in_an_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13233-b31b1b.svg)](https://arxiv.org/abs/2303.13233) | :heavy_minus_sign: |
| CMDA: Cross-Modality Domain Adaptation for Nighttime Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/XiaRho/CMDA)](https://github.com/XiaRho/CMDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CMDA_Cross-Modality_Domain_Adaptation_for_Nighttime_Semantic_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15942-b31b1b.svg)](https://arxiv.org/abs/2307.15942) | :heavy_minus_sign: |
| VQA-GNN: Reasoning with Multimodal Knowledge via Graph Neural Networks for Visual Question Answering | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_VQA-GNN_Reasoning_with_Multimodal_Knowledge_via_Graph_Neural_Networks_for_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2205.11501-b31b1b.svg)](https://arxiv.org/abs/2205.11501) | :heavy_minus_sign: |
| Disentangle then Parse: Night-Time Semantic Segmentation with Illumination Disentanglement | [![GitHub](https://img.shields.io/github/stars/w1oves/DTP)](https://github.com/w1oves/DTP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Disentangle_then_Parse_Night-time_Semantic_Segmentation_with_Illumination_Disentanglement_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09362-b31b1b.svg)](https://arxiv.org/abs/2307.09362) | :heavy_minus_sign: |
| Visual Traffic Knowledge Graph Generation from Scene Images | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://www.nlpr.ia.ac.cn/pal/RS10K.html) <br /> | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Visual_Traffic_Knowledge_Graph_Generation_from_Scene_Images_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Agglomerative Transformer for Human-Object Interaction Detection | [![GitHub](https://img.shields.io/github/stars/six6607/AGER)](https://github.com/six6607/AGER) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Agglomerative_Transformer_for_Human-Object_Interaction_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.08370-b31b1b.svg)](https://arxiv.org/abs/2308.08370) | :heavy_minus_sign: |
| 3D Neural Embedding Likelihood: Probabilistic Inverse Graphics for Robust 6D Pose Estimation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_3D_Neural_Embedding_Likelihood_Probabilistic_Inverse_Graphics_for_Robust_6D_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.03744-b31b1b.svg)](https://arxiv.org/abs/2302.03744) | :heavy_minus_sign: |
| HiLo: Exploiting High Low Frequency Relations for Unbiased Panoptic Scene Graph Generation | [![GitHub](https://img.shields.io/github/stars/franciszzj/HiLo)](https://github.com/franciszzj/HiLo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_HiLo_Exploiting_High_Low_Frequency_Relations_for_Unbiased_Panoptic_Scene_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15994-b31b1b.svg)](https://arxiv.org/abs/2303.15994) | :heavy_minus_sign: |
| RLIPv2: Fast Scaling of Relational Language-Image Pre-Training | [![GitHub](https://img.shields.io/github/stars/JacobYuan7/RLIPv2)](https://github.com/JacobYuan7/RLIPv2) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_RLIPv2_Fast_Scaling_of_Relational_Language-Image_Pre-Training_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09351-b31b1b.svg)](https://arxiv.org/abs/2308.09351) | :heavy_minus_sign: |
| UniSeg: A Unified Multi-Modal LiDAR Segmentation Network and the OpenPCSeg Codebase | [![GitHub](https://img.shields.io/github/stars/PJLab-ADG/PCSeg)](https://github.com/PJLab-ADG/PCSeg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_UniSeg_A_Unified_Multi-Modal_LiDAR_Segmentation_Network_and_the_OpenPCSeg_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.05573-b31b1b.svg)](https://arxiv.org/abs/2309.05573) | :heavy_minus_sign: |
| See more and Know More: Zero-Shot Point Cloud Segmentation via Multi-Modal Visual Data | [![GitHub](https://img.shields.io/github/stars/4DVLab/See_More_Know_More)](https://github.com/4DVLab/See_More_Know_More) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_See_More_and_Know_More_Zero-shot_Point_Cloud_Segmentation_via_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.10782-b31b1b.svg)](https://arxiv.org/abs/2307.10782) | :heavy_minus_sign: |
| Compositional Feature Augmentation for Unbiased Scene Graph Generation | [![GitHub](https://img.shields.io/github/stars/HKUST-LongGroup/CFA)](https://github.com/HKUST-LongGroup/CFA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Compositional_Feature_Augmentation_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06712-b31b1b.svg)](https://arxiv.org/abs/2308.06712) | :heavy_minus_sign: |
| Multi-Weather Image Restoration via Domain Translation | [![GitHub](https://img.shields.io/github/stars/pwp1208/Domain_Translation_Multi-weather_Restoration)](https://github.com/pwp1208/Domain_Translation_Multi-weather_Restoration) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Patil_Multi-weather_Image_Restoration_via_Domain_Translation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| CLIPTER: Looking at the Bigger Picture in Scene Text Recognition | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Aberdam_CLIPTER_Looking_at_the_Bigger_Picture_in_Scene_Text_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.07464-b31b1b.svg)](https://arxiv.org/abs/2301.07464) | :heavy_minus_sign: |
| Towards Models that Can See and Read | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ganz_Towards_Models_that_Can_See_and_Read_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.07389-b31b1b.svg)](https://arxiv.org/abs/2301.07389) | :heavy_minus_sign: |
<!-- | SurroundOcc: Multi-Camera 3D Occupancy Prediction for Autonomous Driving |  |  |  |
| DDP: Diffusion Model for Dense Visual Prediction |  |  |  |
| Understanding 3D Object Interaction from a Single Image |  |  |  |
| ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces |  |  |  |
| Improving Equivariance in State-of-the-Art Supervised Depth and Normal Predictors |  |  |  |
| CrossMatch: Source-Free Domain Adaptive Semantic Segmentation via Cross-Modal Consistency Training |  |  |  |
| Semantic Attention Flow Fields for Monocular Dynamic Scene Decomposition |  |  |  |
| Holistic Geometric Feature Learning for Structured Reconstruction |  |  |  |
| Scalable Multi-Temporal Remote Sensing Change Data Generation via Simulating Stochastic Change Process |  |  |  |
| TaskExpert: Dynamically Assembling Multi-Task Representations with Memorial Mixture-of-Experts |  |  |  |
| Thinking Image Color Aesthetics Assessment: Models, Datasets and Benchmarks |  |  |  |
| STEERER: Resolving Scale Variations for Counting and Localization via Selective Inheritance Learning |  |  |  |
| Object-Aware Gaze Target Detection |  |  |  |
| Weakly Supervised Referring Image Segmentation with Intra-Chunk and Inter-Chunk Consistency |  |  |  |
| Vision Relation Transformer for Unbiased Scene Graph Generation |  |  |  |
| DDIT: Semantic Scene Completion via Deformable Deep Implicit Templates |  |  |  |
| DQS3D: Densely-Matched Quantization-Aware Semi-Supervised 3D Detection |  |  |  |
| Shape Anchor Guided Holistic Indoor Scene Understanding |  |  |  |
| SGAligner: 3D Scene Alignment with Scene Graphs |  |  |  |
| Betrayed by Captions: Joint Caption Grounding and Generation for Open Vocabulary Instance Segmentation |  |  |  | -->
