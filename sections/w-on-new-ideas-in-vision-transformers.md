# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/w-on-cv-in-plant-phenotyping-and-agriculture.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/w-representation-learning-with-very-limited-images.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Workshop on New Ideas in Vision Transformers

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Explaining Through Transformer Input Sampling | [![GitHub](https://img.shields.io/github/stars/aenglebert/Transformer_Input_Sampling)](https://github.com/aenglebert/Transformer_Input_Sampling) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Englebert_Explaining_Through_Transformer_Input_Sampling_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| Actor-Agnostic Multi-Label Action Recognition with Multi-Modal Query | [![GitHub](https://img.shields.io/github/stars/mondalanindya/MSQNet)](https://github.com/mondalanindya/MSQNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Mondal_Actor-Agnostic_Multi-Label_Action_Recognition_with_Multi-Modal_Query_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.10763-b31b1b.svg)](https://arxiv.org/abs/2307.10763) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bafoEVdQYJg) |
| All-Pairs Consistency Learning forWeakly Supervised Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Sun_All-pairs_Consistency_Learning_forWeakly_Supervised_Semantic_Segmentation_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| Dual-Contrastive Dual-Consistency Dual-Transformer: A Semi-Supervised Approach to Medical Image Segmentation | [![GitHub](https://img.shields.io/github/stars/ziyangwang007/CV-SSL-MIS)](https://github.com/ziyangwang007/CV-SSL-MIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Wang_Dual-Contrastive_Dual-Consistency_Dual-Transformer_A_Semi-Supervised_Approach_to_Medical_Image_Segmentation_ICCVW_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JU9koBE83co) |
| A Hybrid Visual Transformer for Efficient Deep Human Activity Recognition | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Djenouri_A_Hybrid_Visual_Transformer_for_Efficient_Deep_Human_Activity_Recognition_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| Which Tokens to Use? Investigating Token Reduction in Vision Transformers | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://vap.aau.dk/tokens/) <br /> [![GitHub](https://img.shields.io/github/stars/JoakimHaurum/TokenReduction)](https://github.com/JoakimHaurum/TokenReduction) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Haurum_Which_Tokens_to_Use_Investigating_Token_Reduction_in_Vision_Transformers_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04657-b31b1b.svg)](https://arxiv.org/abs/2308.04657) | :heavy_minus_sign: |
| Hierarchical Spatiotemporal Transformers for Video Object Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Yoo_Hierarchical_Spatiotemporal_Transformers_for_Video_Object_Segmentation_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08263-b31b1b.svg)](https://arxiv.org/abs/2307.08263) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JV9TyazM38Y) |
| IDTransformer: Transformer for Intrinsic Image Decomposition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://morpheus3000.github.io/IDTransformer.web/) <br /> [![GitHub](https://img.shields.io/github/stars/ParthaDasWeb/IDTransformer.web)](https://github.com/ParthaDasWeb/IDTransformer.web) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Das_IDTransformer_Transformer_for_Intrinsic_Image_Decomposition_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| MSViT: Dynamic Mixed-Scale Tokenization for Vision Transformers | [![GitHub](https://img.shields.io/github/stars/Qualcomm-AI-research/batchshaping)](https://github.com/Qualcomm-AI-research/batchshaping) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Havtorn_MSViT_Dynamic_Mixed-Scale_Tokenization_for_Vision_Transformers_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.02321-b31b1b.svg)](https://arxiv.org/abs/2307.02321) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1H7LJ7-v58w) |
| Template-Guided Illumination Correction for Document Images with Imperfect Geometric Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://felixhertlein.github.io/illtrtemplate/) <br /> [![GitHub](https://img.shields.io/github/stars/FelixHertlein/illtrtemplate-model)](https://github.com/FelixHertlein/illtrtemplate-model) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Hertlein_Template-Guided_Illumination_Correction_for_Document_Images_with_Imperfect_Geometric_Reconstruction_ICCVW_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CWrMHbvScSM) |
| Spatio-Temporal Convolution-Attention Video Network |  |  |  |
| TSOSVNet: Teacher-Student Collaborative Knowledge Distillation for Online Signature Verification |  |  |  |
| SeMask: Semantically Masked Transformers for Semantic Segmentation |  |  |  |
| TransInpaint: Transformer-based Image Inpainting with Context Adaptation |  |  |  |
| Interactive Image Segmentation with Cross-Modality Vision Transformers |  |  |  |
| MOSAIC: Multi-Object Segmented Arbitrary Stylization using CLIP |  |  |  |
| On Moving Object Segmentation from Monocular Video with Transformers |  |  |  |
| SCSC: Spatial Cross-Scale Convolution Module to Strengthen Both CNNs and Transformers |  |  |  |
