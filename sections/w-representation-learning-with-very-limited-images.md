# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/w-on-new-ideas-in-vision-transformers.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/w-to-nerf-or-not-to-nerf.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Representation Learning with very Limited Images: The Potential of Self-, Synthetic- and Formula-Supervision

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Image Guided Inpainting with Parameter Efficient Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Lim_Image_Guided_Inpainting_with_Parameter_Efficient_Learning_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| Augmenting Features via Contrastive Learning-based Generative Model for Long-Tailed Classification | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Park_Augmenting_Features_via_Contrastive_Learning-Based_Generative_Model_for_Long-Tailed_Classification_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| G2L: A High-Dimensional Geometric Approach for Automatic Generation of Highly Accurate Pseudo-Labels | [![GitHub](https://img.shields.io/github/stars/Hmic1102/Auto-generated-pseudo-label?style=flat)](https://github.com/Hmic1102/Auto-generated-pseudo-label) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Kender_G2L_A_High-Dimensional_Geometric_Approach_for_Automatic_Generation_of_Highly_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| Self-Supervised Hypergraphs for Learning Multiple World Interpretations | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Marcu_Self-Supervised_Hypergraphs_for_Learning_Multiple_World_Interpretations_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07615-b31b1b.svg)](https://arxiv.org/abs/2308.07615) | :heavy_minus_sign: |
| Deep Generative Networks for Heterogeneous Augmentation of Cranial Defects | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Kwarciak_Deep_Generative_Networks_for_Heterogeneous_Augmentation_of_Cranial_Defects_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04883-b31b1b.svg)](https://arxiv.org/abs/2308.04883) | :heavy_minus_sign: |
| 360&deg; from a Single Camera: A Few-Shot Approach for LiDAR Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Reichardt_360deg_from_a_Single_Camera_A_Few-Shot_Approach_for_LiDAR_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| Adaptive Self-Training for Object Detection | [![GitHub](https://img.shields.io/github/stars/rvandeghen/ASTOD?style=flat)](https://github.com/rvandeghen/ASTOD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Vandeghen_Adaptive_Self-Training_for_Object_Detection_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.05911-b31b1b.svg)](https://arxiv.org/abs/2212.05911) | :heavy_minus_sign: |
| FedLID: Self-Supervised Federated Learning for Leveraging Limited Image Data | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Psaltis_FedLID_Self-Supervised_Federated_Learning_for_Leveraging_Limited_Image_Data_ICCVW_2023_paper.pdf) | :heavy_minus_sign: |
| A Horse with no Labels: Self-Supervised Horse Pose Estimation from Unlabelled Images and Synthetic Prior | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Sosa_A_Horse_with_no_Labels_Self-Supervised_Horse_Pose_Estimation_from_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03411-b31b1b.svg)](https://arxiv.org/abs/2308.03411) | :heavy_minus_sign: |
| Boosting Semi-Supervised Learning by Bridging High and Low-Confidence Predictions | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Nguyen_Boosting_Semi-Supervised_Learning_by_Bridging_high_and_low-Confidence_Predictions_ICCVW_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07509-b31b1b.svg)](https://arxiv.org/abs/2308.07509) | :heavy_minus_sign: |
| SelectNAdapt: Support Set Selection for Few-Shot Domain Adaptation |  |  |  |
| MIAD: A Maintenance Inspection Dataset for Unsupervised Anomaly Detection |  |  |  |
| Enhancing Classification Accuracy on Limited Data via Unconditional GAN |  |  |  |
| Self-Training and Multi-Task Learning for Limited Data: Evaluation Study on Object Detection |  |  |  |
| JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition |  |  |  |
| Semantic RGB-D Image Synthesis |  |  |  |
| Learning Universal Semantic Correspondences with No Supervision and Automatic Data Curation |  |  |  |
| Guiding Video Prediction with Explicit Procedural Knowledge |  |  |  |
| Frequency-Aware Self-Supervised Long-Tailed Learning |  |  |  |
| Tensor Factorization for Leveraging Cross-Modal Knowledge in Data-Constrained Infrared Object Detection |  |  |  |
