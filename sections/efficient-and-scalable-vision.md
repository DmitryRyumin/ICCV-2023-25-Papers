# ICCV-2023-Papers

## Efficient and Scalable Vision

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| AdaNIC: Towards Practical Neural Image Compression via Dynamic Transform Routing | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Rethinking Vision Transformers for MobileNet Size and Speed | [![GitHub](https://img.shields.io/github/stars/snap-research/EfficientFormer)](https://github.com/snap-research/EfficientFormer) | [![arXiv](https://img.shields.io/badge/arXiv-2212.08059-b31b1b.svg)](https://arxiv.org/abs/2212.08059) | :heavy_minus_sign: |
| DELFlow: Dense Efficient Learning of Scene Flow for Large-Scale Point Clouds | [![GitHub](https://img.shields.io/github/stars/IRMVLab/DELFlow)](https://github.com/IRMVLab/DELFlow) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04383-b31b1b.svg)](https://arxiv.org/abs/2308.04383) | :heavy_minus_sign: |
| Eventful Transformers: Leveraging Temporal Redundancy in Vision Transformers | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.13494-b31b1b.svg)](https://arxiv.org/abs/2308.13494) | :heavy_minus_sign: |
| Inherent Redundancy in Spiking Neural Networks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.08227-b31b1b.svg)](https://arxiv.org/abs/2308.08227) | :heavy_minus_sign: |
| Achievement-based Training Progress Balancing for Multi-Task Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Prune Spatio-temporal Tokens by Semantic-aware Temporal Accumulation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.04549-b31b1b.svg)](https://arxiv.org/abs/2308.04549) | :heavy_minus_sign: |
| Differentiable Transportation Pruning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.08483-b31b1b.svg)](https://arxiv.org/abs/2307.08483) | :heavy_minus_sign: |
| XiNet: Efficient Neural Networks for tinyML | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Jumping through Local Minima: Quantization in the Loss Landscape of Vision Transformers | [![GitHub](https://img.shields.io/github/stars/enyac-group/evol-q)](https://github.com/enyac-group/evol-q) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10814-b31b1b.svg)](https://arxiv.org/abs/2308.10814) | :heavy_minus_sign: |
| A2Q: Accumulator-Aware Quantization with Guaranteed Overflow Avoidance | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.04383-b31b1b.svg)](https://arxiv.org/abs/2308.13504v1) | :heavy_minus_sign: |
| Workie-Talkie: Accelerating Federated Learning by Overlapping Computing and Communications via Contrastive Regularization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| DenseShift: Towards Accurate and Transferable Low-Bit Shift Network | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2208.09708-b31b1b.svg)](https://arxiv.org/abs/2208.09708) | :heavy_minus_sign: |
| PRANC: Pseudo RAndom Networks for Compacting deep models | [![GitHub](https://img.shields.io/github/stars/UCDvision/PRANC)](https://github.com/UCDvision/PRANC) | [![arXiv](https://img.shields.io/badge/arXiv-2206.08464-b31b1b.svg)](https://arxiv.org/abs/2206.08464) | :heavy_minus_sign: |
| Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement | [![GitHub](https://img.shields.io/github/stars/apple/ml-dr)](https://github.com/apple/ml-dr) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08983-b31b1b.svg)](https://arxiv.org/abs/2303.08983) | :heavy_minus_sign: |
| A Fast Unified System for 3D Object Detection and Tracking | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Estimator Meets Equilibrium Perspective: A Rectified Straight Through Estimator for Binary Neural Networks Training | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.06689-b31b1b.svg)](https://arxiv.org/abs/2308.06689) | :heavy_minus_sign: |
| I-ViT: Integer-only Quantization for Efficient Vision Transformer Inference | [![GitHub](https://img.shields.io/github/stars/zkkli/I-ViT)](https://github.com/zkkli/I-ViT) | [![arXiv](https://img.shields.io/badge/arXiv-2207.01405-b31b1b.svg)](https://arxiv.org/abs/2207.01405) | :heavy_minus_sign: |
| EMQ: Evolving Training-free Proxies for Automated Mixed Precision Quantization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.10554-b31b1b.svg)](https://arxiv.org/abs/2307.10554) | :heavy_minus_sign: |
| Local or Global: Selective Knowledge Assimilation for Federated Learning with Limited Labels | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.08809-b31b1b.svg)](https://arxiv.org/abs/2307.08809) | :heavy_minus_sign: |
| DataDAM: Efficient Dataset Distillation with Attention Matching | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SAFE: Machine Unlearning With Shard Graphs | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.13169-b31b1b.svg)](https://arxiv.org/abs/2304.13169) | :heavy_minus_sign: |
| ResQ: Residual Quantization for Video Perception | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.09511-b31b1b.svg)](https://arxiv.org/abs/2308.09511) | :heavy_minus_sign: |
| Efficient Computation Sharing for Multi-Task Visual Scene Understanding | [![GitHub](https://img.shields.io/github/stars/IRMVLab/DELFlow)](https://github.com/IRMVLab/DELFlow) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09663-b31b1b.svg)](https://arxiv.org/abs/2303.09663) | :heavy_minus_sign: |
| Essential Matrix Estimation using Convex Relaxations in Orthogonal Space | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TripLe: Revisiting Pretrained Model Reuse and Progressive Learning for Efficient Vision Transformer Scaling and Searching | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| DiffRate: Differentiable Compression Rate for Efficient Vision Transformers | [![GitHub](https://img.shields.io/github/stars/OpenGVLab/DiffRate)](https://github.com/OpenGVLab/DiffRate) | [![arXiv](https://img.shields.io/badge/arXiv-2305.17997-b31b1b.svg)](https://arxiv.org/abs/2305.17997) | :heavy_minus_sign: |
| Bridging Cross-task Protocol Inconsistency for Distillation in Dense Object Detection | [![GitHub](https://img.shields.io/github/stars/TinyTigerPan/BCKD)](https://github.com/TinyTigerPan/BCKD) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04383-b31b1b.svg)]([https://arxiv.org/abs/2308.04383](https://arxiv.org/abs/2308.14286)) | :heavy_minus_sign: |
| From Knowledge Distillation to Self-Knowledge Distillation: A Unified Approach with Normalized Loss and Customized Soft Labels | [![GitHub](https://img.shields.io/github/stars/yzd-v/cls_KD)](https://github.com/yzd-v/cls_KD) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13005-b31b1b.svg)](https://arxiv.org/abs/2303.13005) | :heavy_minus_sign: |
| Efficient 3D Semantic Segmentation with Superpoint Transformer | [![GitHub](https://img.shields.io/github/stars/drprojects/superpoint_transformer)](https://github.com/drprojects/superpoint_transformer) | [![arXiv](https://img.shields.io/badge/arXiv-2306.08045-b31b1b.svg)](https://arxiv.org/abs/2306.08045) | :heavy_minus_sign: |
| Dataset Quantization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.10524-b31b1b.svg)](https://arxiv.org/abs/2308.10524) | :heavy_minus_sign: |
| Revisiting the Parameter Efficiency of Adapters from the Perspective of Precision Redundancy | [![GitHub](https://img.shields.io/github/stars/JieShibo/PETL-ViT)](https://github.com/JieShibo/PETL-ViT) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16867-b31b1b.svg)](https://arxiv.org/abs/2307.16867) | :heavy_minus_sign: |
| RepQ-ViT: Scale Reparameterization for Post-Training Quantization of Vision Transformers | [![GitHub](https://img.shields.io/github/stars/zkkli/RepQ-ViT)](https://github.com/zkkli/RepQ-ViT) | [![arXiv](https://img.shields.io/badge/arXiv-2212.08254-b31b1b.svg)](https://arxiv.org/abs/2212.08254) | :heavy_minus_sign: |
| Semantically Structured Image Compression via Irregular Group-Based Decoupling | [![GitHub](https://img.shields.io/github/stars/IRMVLab/DELFlow)](https://github.com/IRMVLab/DELFlow) | [![arXiv](https://img.shields.io/badge/arXiv-2305.02586-b31b1b.svg)](https://arxiv.org/abs/2305.02586) | :heavy_minus_sign: |
| SeiT: Storage-Efficient Vision Training with Tokens Using 1% of Pixel Storage | [![GitHub](https://img.shields.io/github/stars/naver-ai/seit)](https://github.com/naver-ai/seit) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11114-b31b1b.svg)](https://arxiv.org/abs/2303.11114) | :heavy_minus_sign: |
| SMMix: Self-Motivated Image Mixing for Vision Transformers | [![GitHub](https://img.shields.io/github/stars/ChenMnZ/SMMix)](https://github.com/ChenMnZ/SMMix) | [![arXiv](https://img.shields.io/badge/arXiv-2212.12977-b31b1b.svg)](https://arxiv.org/abs/2212.12977) | :heavy_minus_sign: |
| Multi-Label Knowledge Distillation | [![GitHub](https://img.shields.io/github/stars/penghui-yang/L2D)](https://github.com/penghui-yang/L2D) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06453-b31b1b.svg)](https://arxiv.org/abs/2308.06453) | :heavy_minus_sign: |
| UGC: Unified GAN Compression for Efficient Image-to-Image Translation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving Camera Videos with Spherical Buffers and Padded Convolutions | [![GitHub](https://img.shields.io/github/stars/IRMVLab/DELFlow)](https://github.com/IRMVLab/DELFlow) | [![arXiv](https://img.shields.io/badge/arXiv-2210.09887-b31b1b.svg)](https://arxiv.org/abs/2210.09887) | :heavy_minus_sign: |
| EfficientViT: Lightweight Multi-Scale Attention for High-Resolution Dense Prediction | [![GitHub](https://img.shields.io/github/stars/mit-han-lab/efficientvit)](https://github.com/mit-han-lab/efficientvit) | [![arXiv](https://img.shields.io/badge/arXiv-2205.14756-b31b1b.svg)](https://arxiv.org/abs/2205.14756) | :heavy_minus_sign: |
| DREAM: Efficient Dataset Distillation by Representative Matching | [![GitHub](https://img.shields.io/github/stars/lyq312318224/DREAM)](https://github.com/lyq312318224/DREAM) | [![arXiv](https://img.shields.io/badge/arXiv-2302.14416-b31b1b.svg)](https://arxiv.org/abs/2302.14416) | :heavy_minus_sign: |
| INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2204.07439-b31b1b.svg)](https://arxiv.org/abs/2204.07439) | :heavy_minus_sign: |
| Deep Incubation: Training Large Models by Divide-and-Conquering | [![GitHub](https://img.shields.io/github/stars/LeapLabTHU/Deep-Incubation)](https://github.com/LeapLabTHU/Deep-Incubation) | [![arXiv](https://img.shields.io/badge/arXiv-2212.04129-b31b1b.svg)](https://arxiv.org/abs/2212.04129) | :heavy_minus_sign: |
| AdaMV-MoE: Adaptive Multi-Task Vision Mixture-of-Experts | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Overcoming Forgetting Catastrophe in Quantization-Aware Training | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Window-Based Early-Exit Cascades for Uncertainty Estimation: When Deep Ensembles are More Efficient than Single Models | [![GitHub](https://img.shields.io/github/stars/Guoxoug/window-early-exit)](https://github.com/Guoxoug/window-early-exit) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08010-b31b1b.svg)](https://arxiv.org/abs/2303.08010) | :heavy_minus_sign: |
| ORC: Network Group-based Knowledge Distillation using Online Role Change | [![GitHub](https://img.shields.io/github/stars/IRMVLab/DELFlow)](https://github.com/IRMVLab/DELFlow) | [![arXiv](https://img.shields.io/badge/arXiv-2206.01186-b31b1b.svg)](https://arxiv.org/abs/2206.01186) | :heavy_minus_sign: |
| RMP-Loss: Regularizing Membrane Potential Distribution for Spiking Neural Networks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.06787-b31b1b.svg)](https://arxiv.org/abs/2308.06787) | :heavy_minus_sign: |
| Structural Alignment for Network Pruning through Partial Regularization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Automated Knowledge Distillation via Monte Carlo Tree Search | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications | [![GitHub](https://img.shields.io/github/stars/Amshaker/SwiftFormer)](https://github.com/Amshaker/SwiftFormer) | [![arXiv](https://img.shields.io/badge/arXiv-2303.15446-b31b1b.svg)](https://arxiv.org/abs/2303.15446) | :heavy_minus_sign: |
| Causal-DFQ: Causality Guided Data-Free Network Quantization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Efficient Joint Optimization of Layer-Adaptive Weight Pruning in Deep Neural Networks | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Automatic Network Pruning via Hilbert-Schmidt Independence Criterion Lasso under Information Bottleneck Principle | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Distribution Shift Matters for Knowledge Distillation with Webly Collected Images | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.11469-b31b1b.svg)](https://arxiv.org/abs/2307.11469) | :heavy_minus_sign: |
| FastRecon: Few-shot Industrial Anomaly Detection via Fast Feature Reconstruction | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| E<sup>2</sup>VPT: An Effective and Efficient Approach for Visual Prompt Tuning | [![GitHub](https://img.shields.io/github/stars/ChengHan111/E2VPT)](https://github.com/ChengHan111/E2VPT) | [![arXiv](https://img.shields.io/badge/arXiv-2307.13770-b31b1b.svg)](https://arxiv.org/abs/2307.13770) | :heavy_minus_sign: |
| Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation | [![GitHub](https://img.shields.io/github/stars/kkakkkka/ETRIS)](https://github.com/kkakkkka/ETRIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.11545-b31b1b.svg)](https://arxiv.org/abs/2307.11545) | :heavy_minus_sign: |
| SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Efficient Deep Space Filling Curve | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Q-Diffusion: Quantizing Diffusion Models | [![GitHub](https://img.shields.io/github/stars/Xiuyu-Li/q-diffusion)](https://github.com/Xiuyu-Li/q-diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2302.04304-b31b1b.svg)](https://arxiv.org/abs/2302.04304) | :heavy_minus_sign: |
| Lossy and Lossless (L2) Post-training Model Size Compression | [![GitHub](https://img.shields.io/github/stars/ModelTC/L2_Compression)](https://github.com/ModelTC/L2_Compression) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04269-b31b1b.svg)](https://arxiv.org/abs/2308.04269) | :heavy_minus_sign: |
| Robustifying Token Attention for Vision Transformers | [![GitHub](https://img.shields.io/github/stars/guoyongcs/TAPADL)](https://github.com/guoyongcs/TAPADL) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11126-b31b1b.svg)](https://arxiv.org/abs/2303.11126) | :heavy_minus_sign: |
