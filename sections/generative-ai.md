# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/recognition-segmentation-and-shape-analysis.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/humans-3d-modeling-and-driving.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
    </a>
</div>

## Generative AI

![Section Papers](https://img.shields.io/badge/Section%20Papers-14-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-13-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-10-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| CLIPascene: Scene Sketching with Different Types and Levels of Abstraction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://clipascene.github.io/CLIPascene/) <br /> [![GitHub](https://img.shields.io/github/stars/yael-vinker/SceneSketch)](https://github.com/yael-vinker/SceneSketch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Vinker_CLIPascene_Scene_Sketching_with_Different_Types_and_Levels_of_Abstraction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.17256-b31b1b.svg)](https://arxiv.org/abs/2211.17256) | :heavy_minus_sign: |
| LD-ZNet: A Latent Diffusion Approach for Text-based Image Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://koutilya-pnvr.github.io/LD-ZNet/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12343-b31b1b.svg)](https://arxiv.org/abs/2303.12343) | :heavy_minus_sign: |
| TexFusion: Synthesizing 3D Textures with Text-Guided Image Diffusion Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://research.nvidia.com/labs/toronto-ai/texfusion/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.13772-b31b1b.svg)](https://arxiv.org/abs/2310.13772) | :heavy_minus_sign: |
| NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://oppo-us-research.github.io/NeuRBF-website/) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://cse.buffalo.edu/~jsyuan/papers/2023/ICCV2023_zhang.pdf) | :heavy_minus_sign: |
| Scalable Diffusion Models with Transformers | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.wpeebles.com/DiT) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/DiT)](https://github.com/facebookresearch/DiT) | [![arXiv](https://img.shields.io/badge/arXiv-2212.09748-b31b1b.svg)](https://arxiv.org/abs/2212.09748) | :heavy_minus_sign: |
| Texture Generation on 3D Meshes with Point-UV Diffusion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cvmi-lab.github.io/Point-UV-Diffusion/) <br /> [![GitHub](https://img.shields.io/github/stars/CVMI-Lab/Point-UV-Diffusion)](https://github.com/CVMI-Lab/Point-UV-Diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10490-b31b1b.svg)](https://arxiv.org/abs/2308.10490) | :heavy_minus_sign: |
| Generative Novel View Synthesis with 3D-Aware Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nvlabs.github.io/genvs/) <br /> [![GitHub](https://img.shields.io/github/stars/NVlabs/genvs)](https://github.com/NVlabs/genvs) | [![arXiv](https://img.shields.io/badge/arXiv-2304.02602-b31b1b.svg)](https://arxiv.org/abs/2304.02602) | :heavy_minus_sign: |
| DiffFit: Unlocking Transferability of Large Diffusion Models via Simple Parameter-Efficient Fine-Tuning | [![GitHub](https://img.shields.io/github/stars/mkshing/DiffFit-pytorch)](https://github.com/mkshing/DiffFit-pytorch) | [![arXiv](https://img.shields.io/badge/arXiv-2304.06648-b31b1b.svg)](https://arxiv.org/abs/2304.06648) | :heavy_minus_sign: |
| VQ3D: Learning a 3D-Aware Generative Model on ImageNet | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kylesargent.github.io/vq3d) | [![arXiv](https://img.shields.io/badge/arXiv-2302.06833-b31b1b.svg)](https://arxiv.org/abs/2302.06833) | :heavy_minus_sign: |
| Ref-NeuS: Ambiguity-Reduced Neural Implicit Surface Learning for Multi-View Reconstruction with Reflection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://g3956.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/EnVision-Research/Ref-NeuS)](https://github.com/EnVision-Research/Ref-NeuS) | [![arXiv](https://img.shields.io/badge/arXiv-2303.10840-b31b1b.svg)](https://arxiv.org/abs/2303.10840) | :heavy_minus_sign: |
| A Complete Recipe for Diffusion Generative Models | [![GitHub](https://img.shields.io/github/stars/mandt-lab/PSLD)](https://github.com/mandt-lab/PSLD) | [![arXiv](https://img.shields.io/badge/arXiv-2303.01748-b31b1b.svg)](https://arxiv.org/abs/2303.01748) | :heavy_minus_sign: |
| MMVP: Motion-Matrix-based Video Prediction | [![GitHub](https://img.shields.io/github/stars/Kay1794/MMVP-motion-matrix-based-video-prediction)](https://github.com/Kay1794/MMVP-motion-matrix-based-video-prediction) | [![arXiv](https://img.shields.io/badge/arXiv-2308.16154-b31b1b.svg)](https://arxiv.org/abs/2308.16154) | :heavy_minus_sign: |
| Cross-Ray Neural Radiance Fields for Novel-View Synthesis from Unconstrained Image Collections |  |  |  |
| Effective Real Image Editing with Accelerated Iterative Diffusion Inversion |  |  |  |
| Simulating Fluids in Real-World Still Images | [![GitHub](https://img.shields.io/github/stars/simon3dv/SLR-SFS)](https://github.com/simon3dv/SLR-SFS) | [![arXiv](https://img.shields.io/badge/arXiv-2204.11335-b31b1b.svg)](https://arxiv.org/abs/2204.11335) | :heavy_minus_sign: |
| FateZero: Fusing Attentions for Zero-Shot Text-based Video Editing | [![GitHub](https://img.shields.io/github/stars/ChenyangQiQi/FateZero)](https://github.com/ChenyangQiQi/FateZero) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09535-b31b1b.svg)](https://arxiv.org/abs/2303.09535) | :heavy_minus_sign: |
| ELITE: Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation |  |  |  |
| Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators |  |  |  |
| Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models |  |  |  |
| DiffPose: Multi-Hypothesis Human Pose Estimation using Diffusion Models |  |  |  |
| HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation |  |  |  |
| Role-Aware Interaction Generation from Textual Description |  |  |  |
| PhysDiff: Physics-Guided Human Motion Diffusion Model |  |  |  |
| Forward Flow for Novel View Synthesis of Dynamic Scenes |  |  |  |
