# ICCV-2025-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICCV-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/sections/2025/main/structure-and-motion.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Multi-Modal Learning

![Section Papers](https://img.shields.io/badge/Section%20Papers-5-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-5-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-2-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [GT-Loc: Unifying when and where in Images through a Joint Embedding Space](https://iccv.thecvf.com/virtual/2025/poster/544) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://davidshatwell.com/gtloc.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Shatwell_GT-Loc_Unifying_When_and_Where_in_Images_Through_a_Joint_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2507.10473-b31b1b.svg)](http://arxiv.org/abs/2507.10473) | :heavy_minus_sign: |
| [Scaling Laws for Native Multimodal Models](https://iccv.thecvf.com/virtual/2025/poster/1224) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Shukor_Scaling_Laws_for_Native_Multimodal_Models_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2504.07951-b31b1b.svg)](http://arxiv.org/abs/2504.07951) | :heavy_minus_sign: |
| [FixTalk: Taming Identity Leakage for High-Quality Talking Head Generation in Extreme Cases](https://iccv.thecvf.com/virtual/2025/poster/1094) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Tan_FixTalk_Taming_Identity_Leakage_for_High-Quality_Talking_Head_Generation_in_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2507.01390-b31b1b.svg)](http://arxiv.org/abs/2507.01390) | :heavy_minus_sign: |
| [Differentiable Room Acoustic Rendering with Multi-View Vision Priors](https://iccv.thecvf.com/virtual/2025/poster/2654) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://humathe.github.io/avdar/) <br /> [![GitHub](https://img.shields.io/github/stars/HuMathe/av-dar?style=flat)](https://github.com/HuMathe/av-dar) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Jin_Differentiable_Room_Acoustic_Rendering_with_Multi-View_Vision_Priors_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2504.21847-b31b1b.svg)](http://arxiv.org/abs/2504.21847) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=thtuB1kRwPU) |
| [Token Activation Map to Visually Explain Multimodal LLMs](https://iccv.thecvf.com/virtual/2025/poster/2224) | [![GitHub](https://img.shields.io/github/stars/xmed-lab/TAM?style=flat)](https://github.com/xmed-lab/TAM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Li_Token_Activation_Map_to_Visually_Explain_Multimodal_LLMs_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2506.23270-b31b1b.svg)](http://arxiv.org/abs/2506.23270) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GnVd-MuZRr8) |
