# ICCV-2025-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICCV-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/sections/2025/main/vision-and-graphics.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/sections/2025/main/content-generation.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Applications and Evaluation

![Section Papers](https://img.shields.io/badge/Section%20Papers-6-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-4-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-5-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-3-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [ROAR: Reducing Inversion Error in Generative Image Watermarking](https://iccv.thecvf.com/virtual/2025/poster/969) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Wang_ROAR_Reducing_Inversion_Error_in_Generative_Image_Watermarking_ICCV_2025_paper.pdf) | :heavy_minus_sign: |
| [Moto: Latent Motion Token as the Bridging Language for Learning Robot Manipulation from Videos](https://iccv.thecvf.com/virtual/2025/poster/797) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chenyi99.github.io/moto/) <br /> [![GitHub](https://img.shields.io/github/stars/TencentARC/Moto?style=flat)](https://github.com/TencentARC/Moto) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Chen_Moto_Latent_Motion_Token_as_the_Bridging_Language_for_Learning_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2412.04445-b31b1b.svg)](http://arxiv.org/abs/2412.04445) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WflfXxKnSms) |
| [Automated Model Evaluation for Object Detection via Prediction Consistency and Reliability](https://iccv.thecvf.com/virtual/2025/poster/68) | [![GitHub](https://img.shields.io/github/stars/YonseiML/autoeval-det?style=flat)](https://github.com/YonseiML/autoeval-det) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Yoo_Automated_Model_Evaluation_for_Object_Detection_via_Prediction_Consistency_and_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2508.12082-b31b1b.svg)](http://arxiv.org/abs/2508.12082) | :heavy_minus_sign: |
| [Counting Stacked Objects](https://iccv.thecvf.com/virtual/2025/poster/1475) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://corentindumery.github.io/projects/stacks.html) <br /> [![GitHub](https://img.shields.io/github/stars/CorentinDumery/3d-counting?style=flat)](https://github.com/CorentinDumery/3d-counting) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Dumery_Counting_Stacked_Objects_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2411.19149-b31b1b.svg)](http://arxiv.org/abs/2411.19149) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mXTAXor3-VE) |
| [MIORe and VAR-MIORe: Benchmarks to Push the Boundaries of Restoration](https://iccv.thecvf.com/virtual/2025/poster/2056) | [![GitHub](https://img.shields.io/github/stars/george200150/MIORe?style=flat)](https://github.com/george200150/MIORe) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Ciubotariu_MIORe__VAR-MIORe_Benchmarks_to_Push_the_Boundaries_of_Restoration_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2509.06803-b31b1b.svg)](http://arxiv.org/abs/2509.06803) | :heavy_minus_sign: |
| [Soft Local Completeness: Rethinking Completeness in XAI](https://iccv.thecvf.com/virtual/2025/poster/1851) | [![GitHub](https://img.shields.io/github/stars/xaisloc/sloc?style=flat)](https://github.com/xaisloc/sloc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Haddad_Soft_Local_Completeness_Rethinking_Completeness_in_XAI_ICCV_2025_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7XN8b9KFh5I) |
