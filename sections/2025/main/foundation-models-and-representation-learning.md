# ICCV-2025-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICCV-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/sections/2025/main/view-synthesis-and-scene-reconstruction.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/sections/2025/main/human-modeling.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Foundation Models and Representation Learning

![Section Papers](https://img.shields.io/badge/Section%20Papers-6-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-5-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-4-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-4-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [RS-vHeat: Heat Conduction Guided Efficient Remote Sensing Foundation Model](https://iccv.thecvf.com/virtual/2025/poster/514) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Hu_RS-vHeat_Heat_Conduction_Guided_Efficient_Remote_Sensing_Foundation_Model_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2411.17984-b31b1b.svg)](http://arxiv.org/abs/2411.17984) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UjZdpRIVLAg) |
| [Towards a Unified Copernicus Foundation Model for Earth Vision](https://iccv.thecvf.com/virtual/2025/poster/373) | [![GitHub](https://img.shields.io/github/stars/zhu-xlab/Copernicus-FM?style=flat)](https://github.com/zhu-xlab/Copernicus-FM) <br /> [![Hugging Face Model](https://img.shields.io/badge/ðŸ¤—-model-FFD21F.svg)](https://huggingface.co/wangyi111/Copernicus-FM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Wang_Towards_a_Unified_Copernicus_Foundation_Model_for_Earth_Vision_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2503.11849-b31b1b.svg)](http://arxiv.org/abs/2503.11849) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ar0IAN0TFrc) |
| [Learning Streaming Video Representation via Multitask Training](https://iccv.thecvf.com/virtual/2025/poster/2713) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://go2heart.github.io/streamformer/) <br /> [![GitHub](https://img.shields.io/github/stars/Go2Heart/StreamFormer?style=flat)](https://github.com/Go2Heart/StreamFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Yan_Learning_Streaming_Video_Representation_via_Multitask_Training_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2504.20041-b31b1b.svg)](http://arxiv.org/abs/2504.20041) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xiTuLWXOuhE) |
| [LoftUp: Learning a Coordinate-based Feature Upsampler for Vision Foundation Models](https://iccv.thecvf.com/virtual/2025/poster/252) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://andrehuang.github.io/loftup-site/) <br /> [![GitHub](https://img.shields.io/github/stars/andrehuang/loftup?style=flat)](https://github.com/andrehuang/loftup) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Huang_LoftUp_Learning_a_Coordinate-Based_Feature_Upsampler_for_Vision_Foundation_Models_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2504.14032-b31b1b.svg)](http://arxiv.org/abs/2504.14032) | :heavy_minus_sign: |
| [Learning Visual Hierarchies in Hyperbolic Space for Image Retrieval](https://iccv.thecvf.com/virtual/2025/poster/489) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Wang_Learning_Visual_Hierarchies_in_Hyperbolic_Space_for_Image_Retrieval_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2411.17490-b31b1b.svg)](http://arxiv.org/abs/2411.17490) | :heavy_minus_sign: |
| [GMMamba: Group Masking Mamba for whole Slide Image Classification](https://iccv.thecvf.com/virtual/2025/poster/1554) | [![GitHub](https://img.shields.io/github/stars/titizheng/GMMamba?style=flat)](https://github.com/titizheng/GMMamba) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Zheng_GMMamba_Group_Masking_Mamba_for_Whole_Slide_Image_Classification_ICCV_2025_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4ESvkE2x9So) |
