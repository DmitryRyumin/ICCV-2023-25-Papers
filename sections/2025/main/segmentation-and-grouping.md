# ICCV-2025-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICCV-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/sections/2025/main/physical-scene-perception.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/sections/2025/main/session-1.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Segmentation and Grouping

![Section Papers](https://img.shields.io/badge/Section%20Papers-5-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-5-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-5-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-1-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [CorrCLIP: Reconstructing Patch Correlations in CLIP for Open-Vocabulary Semantic Segmentation](https://iccv.thecvf.com/virtual/2025/poster/1462) | [![GitHub](https://img.shields.io/github/stars/zdk258/CorrCLIP?style=flat)](https://github.com/zdk258/CorrCLIP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Zhang_CorrCLIP_Reconstructing_Patch_Correlations_in_CLIP_for_Open-Vocabulary_Semantic_Segmentation_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2411.10086-b31b1b.svg)](http://arxiv.org/abs/2411.10086) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pw2n7nBQuHo) |
| [E-SAM: Training-Free Segment Every Entity Model](https://iccv.thecvf.com/virtual/2025/poster/298) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://weimingz996.github.io/E-SAM/) <br /> [![GitHub](https://img.shields.io/github/stars/weimingz996/E-SAM?style=flat)](https://github.com/weimingz996/E-SAM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Zhang_E-SAM_Training-Free_Segment_Every_Entity_Model_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2503.12094-b31b1b.svg)](http://arxiv.org/abs/2503.12094) | :heavy_minus_sign: |
| [Online Reasoning Video Segmentation with Just-in-Time Digital Twins](https://iccv.thecvf.com/virtual/2025/poster/1805) | [![GitHub](https://img.shields.io/github/stars/yiqings/jitbench?style=flat)](https://github.com/yiqings/jitbench) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Shen_Online_Reasoning_Video_Segmentation_with_Just-in-Time_Digital_Twins_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2503.21056-b31b1b.svg)](http://arxiv.org/abs/2503.21056) | :heavy_minus_sign: |
| [Easy3D: A Simple Yet Effective Method for 3D Interactive Segmentation](https://iccv.thecvf.com/virtual/2025/poster/2598) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://simonelli-andrea.github.io/easy3d/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/easy3d?style=flat)](https://github.com/facebookresearch/easy3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Simonelli_Easy3D_A_Simple_Yet_Effective_Method_for_3D_Interactive_Segmentation_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2504.11024-b31b1b.svg)](http://arxiv.org/abs/2504.11024) | :heavy_minus_sign: |
| [ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds](https://iccv.thecvf.com/virtual/2025/poster/2456) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://bxiang233.github.io/FF3D/) <br /> [![GitHub](https://img.shields.io/github/stars/SmartForest-no/ForestFormer3D?style=flat)](https://github.com/SmartForest-no/ForestFormer3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2025/papers/Xiang_ForestFormer3D_A_Unified_Framework_for_End-to-End_Segmentation_of_Forest_LiDAR_ICCV_2025_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2506.16991-b31b1b.svg)](http://arxiv.org/abs/2506.16991) | :heavy_minus_sign: |
