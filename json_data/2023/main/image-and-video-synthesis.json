[
  {
    "title": "Text-Driven Generative Domain Adaptation with Spectral Consistency Regularization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Victarry/Adaptation-SCR",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Text-Driven_Generative_Domain_Adaptation_with_Spectral_Consistency_Regularization_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "MosaiQ: Quantum Generative Adversarial Networks for Image Generation on NISQ Computers",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Silver_MosaiQ_Quantum_Generative_Adversarial_Networks_for_Image_Generation_on_NISQ_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.11096",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Controllable Visual-Tactile Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "RuihanGao/visual-tactile-synthesis",
    "web_page": null,
    "github_page": "https://visual-tactile-synthesis.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Controllable_Visual-Tactile_Synthesis_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2305.03051",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "TdwPfwsGX3I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Editing Implicit Assumptions in Text-to-Image Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "bahjat-kawar/time-diffusion",
    "web_page": null,
    "github_page": "https://time-diffusion.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Orgad_Editing_Implicit_Assumptions_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.08084",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human Avatars",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "SamsungLabs/DINAR",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Svitov_DINAR_Diffusion_Inpainting_of_Neural_Textures_for_One-Shot_Human_Avatars_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.09375",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Smoothness Similarity Regularization for Few-Shot GAN Adaptation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sushko_Smoothness_Similarity_Regularization_for_Few-Shot_GAN_Adaptation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.09717",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "HSR-Diff: Hyperspectral Image Super-Resolution via Conditional Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2306.12085",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Long-Term Photometric Consistent Novel View Synthesis with Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "YorkUCVIL/Photoconsistent-NVS",
    "web_page": null,
    "github_page": "https://yorkucvil.github.io/Photoconsistent-NVS/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Long-Term_Photometric_Consistent_Novel_View_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.10700",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "AutoDiffusion: Training-Free Optimization of Time Steps and Architectures for Automated Diffusion Model Acceleration",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AutoDiffusion_Training-Free_Optimization_of_Time_Steps_and_Architectures_for_Automated_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.10438",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Collecting the Puzzle Pieces: Disentangled Self-Driven Human Pose Transfer by Permuting Textures",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "NannanLi999/pt_square",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Collecting_The_Puzzle_Pieces_Disentangled_Self-Driven_Human_Pose_Transfer_by_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2210.01887",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Multi-Directional Subspace Editing in Style-Space",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "chennaveh/MDSE",
    "web_page": null,
    "github_page": "https://chennaveh.github.io/MDSE/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Naveh_Multi-Directional_Subspace_Editing_in_Style-Space_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2211.11825",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "HyperReenact: One-Shot Reenactment via Jointly Learning to Refine and Retarget Faces",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "StelaBou/HyperReenact",
    "web_page": null,
    "github_page": "https://stelabou.github.io/hyperreenact.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bounareli_HyperReenact_One-Shot_Reenactment_via_Jointly_Learning_to_Refine_and_Retarget_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.10797",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Generating Realistic Images from in-the-Wild Sounds",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Generating_Realistic_Images_from_In-the-wild_Sounds_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.02405",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "CC3D: Layout-Conditioned Generation of Compositional 3D Scenes",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "sherwinbahmani/cc3d",
    "web_page": null,
    "github_page": "https://sherwinbahmani.github.io/cc3d/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bahmani_CC3D_Layout-Conditioned_Generation_of_Compositional_3D_Scenes_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.12074",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "UMFuse: Unified Multi View Fusion for Human Editing Applications",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://mdsrlab.github.io/2023/08/13/UMFuse-ICCV.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_UMFuse_Unified_Multi_View_Fusion_for_Human_Editing_Applications_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2211.10157",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Evaluating Data Attribution for Text-to-Image Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "PeterWang512/GenDataAttribution",
    "web_page": null,
    "github_page": "https://peterwang512.github.io/GenDataAttribution/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Evaluating_Data_Attribution_for_Text-to-Image_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2306.09345",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "iO6fiSyyv40",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Neural Characteristic Function Learning for Conditional Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Zhangjialu126/ccf_gan",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Neural_Characteristic_Function_Learning_for_Conditional_Image_Generation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "WaveIPT: Joint Attention and Flow Alignment in the Wavelet Domain for Pose Transfer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_WaveIPT_Joint_Attention_and_Flow_Alignment_in_the_Wavelet_domain_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "LayoutDiffusion: Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "microsoft/LayoutGeneration",
    "web_page": null,
    "github_page": "https://github.com/microsoft/LayoutGeneration/tree/main/LayoutDiffusion",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LayoutDiffusion_Improving_Graphic_Layout_Generation_by_Discrete_Diffusion_Probabilistic_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.11589",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Human-Inspired Facial Sketch Synthesis with Dynamic Adaptation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "AiArt-HDU/HIDA",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Human-Inspired_Facial_Sketch_Synthesis_with_Dynamic_Adaptation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.00216",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Conceptual and Hierarchical Latent Space Decomposition for Face Editing",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ozkan_Conceptual_and_Hierarchical_Latent_Space_Decomposition_for_Face_Editing_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Improving Diversity in Zero-Shot GAN Adaptation with Semantic Variations",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Improving_Diversity_in_Zero-Shot_GAN_Adaptation_with_Semantic_Variations_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.10554",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "BallGAN: 3D-Aware Image Synthesis with a Spherical Background",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "minjung-s/BallGAN",
    "web_page": null,
    "github_page": "https://minjung-s.github.io/ballgan",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_BallGAN_3D-aware_Image_Synthesis_with_a_Spherical_Background_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2301.09091",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "RUIWWMiomuY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "End-to-End Diffusion Latent Optimization Improves Classifier Guidance",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "salesforce/DOODL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wallace_End-to-End_Diffusion_Latent_Optimization_Improves_Classifier_Guidance_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.13703",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Deep Geometrized Cartoon Line Inbetweening",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "lisiyao21/AnimeInbet",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.16643",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "UnitedHuman/UnitedHuman",
    "web_page": null,
    "github_page": "https://unitedhuman.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_UnitedHuman_Harnessing_Multi-Source_Data_for_High-Resolution_Human_Generation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.14335",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "pdsfUYFDLSw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Towards Authentic Face Restoration with Iterative Diffusion Models and Beyond",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Towards_Authentic_Face_Restoration_with_Iterative_Diffusion_Models_and_Beyond_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.08996",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "SVDiff: Compact Parameter Space for Diffusion Fine-Tuning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "mkshing/svdiff-pytorch",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_SVDiff_Compact_Parameter_Space_for_Diffusion_Fine-Tuning_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.11305",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "MI-GAN: A Simple Baseline for Image Inpainting on Mobile Devices",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Picsart-AI-Research/MI-GAN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sargsyan_MI-GAN_A_Simple_Baseline_for_Image_Inpainting_on_Mobile_Devices_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Structure and Content-Guided Video Synthesis with Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://research.runwayml.com/gen1",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Esser_Structure_and_Content-Guided_Video_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2302.03011",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Y2_JmgzTeeo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Yuxinn-J/Scenimefy",
    "web_page": null,
    "github_page": "https://yuxinn-j.github.io/projects/Scenimefy.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/YuxinJ/Scenimefy",
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Scenimefy_Learning_to_Craft_Anime_Scene_via_Semi-Supervised_Image-to-Image_Translation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.12968",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Efficient-VQGAN: Towards High-Resolution Image Generation with Efficient Vision Transformers",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2310.05400",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "A Latent Space of Stochastic Diffusion Models for Zero-Shot Image Editing and Guidance",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "humansensinglab/cycle-diffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Generative Multiplane Neural Radiance for 3D-Aware Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "VIROBO-15/GMNR",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.01172",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Parallax-Tolerant Unsupervised Deep Image Stitching",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "nie-lang/UDIS2",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_Parallax-Tolerant_Unsupervised_Deep_Image_Stitching_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2302.08207",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "GAIT: Generating Aesthetic Indoor Tours with Deep Reinforcement Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "desaixie/gait",
    "web_page": null,
    "github_page": "https://desaixie.github.io/gait-rl/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_GAIT_Generating_Aesthetic_Indoor_Tours_with_Deep_Reinforcement_Learning_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "EverLight: Indoor-Outdoor Editable HDR Lighting Estimation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://lvsn.github.io/everlight/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dastjerdi_EverLight_Indoor-Outdoor_Editable_HDR_Lighting_Estimation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.13207",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Mk2ZhXxzLRY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Prompt Tuning Inversion for Text-Driven Image Editing using Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Prompt_Tuning_Inversion_for_Text-driven_Image_Editing_Using_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2305.04441",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Efficient Diffusion Training via Min-SNR Weighting Strategy",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "TiankaiHang/Min-SNR-Diffusion-Training",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hang_Efficient_Diffusion_Training_via_Min-SNR_Weighting_Strategy_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.09556",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "showlab/BoxDiff",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.10816",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Improving Sample Quality of Diffusion Models using Self-Attention Guidance",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "KU-CVLAB/Self-Attention-Guidance",
    "web_page": null,
    "github_page": "https://ku-cvlab.github.io/Self-Attention-Guidance/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Improving_Sample_Quality_of_Diffusion_Models_Using_Self-Attention_Guidance_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2210.00939",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Not All Steps are Created Equal: Selective Diffusion Distillation for Image Manipulation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "EnVision-Research/Selective-Diffusion-Distillation",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_All_Steps_are_Created_Equal_Selective_Diffusion_Distillation_for_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.08448",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Deep Image Harmonization with Learnable Augmentation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "bcmi/SycoNet-Adaptive-Image-Harmonization",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Learnable_Augmentation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.00376",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Out-of-Domain GAN Inversion via Invertibility Decomposition for Photo-Realistic Human Face Manipulation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "AbnerVictor/OOD-GAN-inversion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Out-of-Domain_GAN_Inversion_via_Invertibility_Decomposition_for_Photo-Realistic_Human_Face_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2212.09262",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Bidirectionally Deformable Motion Modulation for Video-based Human Pose Transfer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "rocketappslab/bdmm",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Bidirectionally_Deformable_Motion_Modulation_For_Video-based_Human_Pose_Transfer_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.07754",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Size does Matter: Size-Aware Virtual Try-On via Clothing-Oriented Transformation Try-On Network",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "cotton6/COTTON-size-does-matter",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Size_Does_Matter_Size-aware_Virtual_Try-on_via_Clothing-oriented_Transformation_Try-on_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "VidStyleODE: Disentangled Video Editing via StyleGAN and NeuralODEs",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "MoayedHajiAli/VidStyleODE-official",
    "web_page": null,
    "github_page": "https://cyberiada.github.io/VidStyleODE/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ali_VidStyleODE_Disentangled_Video_Editing_via_StyleGAN_and_NeuralODEs_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.06020",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Cfh-mgr1isc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Learning Global-Aware Kernel for Image Harmonization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Learning_Global-aware_Kernel_for_Image_Harmonization_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2305.11676",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Expressive Text-to-Image Generation with Rich Text",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "SongweiGe/rich-text-to-image",
    "web_page": null,
    "github_page": "https://rich-text-to-image.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/songweig/rich-text-to-image",
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Expressive_Text-to-Image_Generation_with_Rich_Text_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.06720",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ihDbAUh0LXk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "A Large-Scale Outdoor Multi-Modal Dataset and Benchmark for Novel View Synthesis and Implicit Scene Reconstruction",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "luchongshan/OMMO",
    "web_page": "https://ommo.luchongshan.com/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_A_Large-Scale_Outdoor_Multi-Modal_Dataset_and_Benchmark_for_Novel_View_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2301.06782",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": "https://www.loom.com/share/7b9ed35bfb3649eda051398d3a51cda7",
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Fictionarry/ER-NeRF",
    "web_page": null,
    "github_page": "https://fictionarry.github.io/ER-NeRF/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Efficient_Region-Aware_Neural_Radiance_Fields_for_High-Fidelity_Talking_Portrait_Synthesis_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.09323",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Gc2d3Z8MMuI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Perceptual Artifacts Localization for Image Synthesis Tasks",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "owenzlz/PAL4VST",
    "web_page": null,
    "github_page": "https://owenzlz.github.io/PAL4VST/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Perceptual_Artifacts_Localization_for_Image_Synthesis_Tasks_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2310.05590",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "pmh9960/GCDP",
    "web_page": null,
    "github_page": "https://pmh9960.github.io/research/GCDP/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Learning_to_Generate_Semantic_Layouts_for_Higher_Text-Image_Correspondence_in_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.08157",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "StylerDALLE: Language-Guided Style Transfer using a Vector-Quantized Tokenizer of a Large-Scale Generative Model",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zipengxuc/StylerDALLE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_StylerDALLE_Language-Guided_Style_Transfer_Using_a_Vector-Quantized_Tokenizer_of_a_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.09268",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Shortcut-V2V: Compression Framework for Video-to-Video Translation based on Temporal Redundancy Reduction",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "indigopyj/Shortcut-V2V",
    "web_page": null,
    "github_page": "https://shortcut-v2v.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chung_Shortcut-V2V_Compression_Framework_for_Video-to-Video_Translation_Based_on_Temporal_Redundancy_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.08011",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Tune-a-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "showlab/Tune-A-Video",
    "web_page": null,
    "github_page": "https://tuneavideo.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/Tune-A-Video-library/Tune-A-Video-Training-UI",
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2212.11565",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "BlendFace: Re-Designing Identity Encoders for Face-Swapping",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "mapooon/BlendFace",
    "web_page": null,
    "github_page": "https://mapooon.github.io/BlendFacePage/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shiohara_BlendFace_Re-designing_Identity_Encoders_for_Face-Swapping_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.10854",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Talking Head Generation with Probabilistic Audio-to-Visual Diffusion Priors",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://zxyin.github.io/TH-PAD/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Talking_Head_Generation_with_Probabilistic_Audio-to-Visual_Diffusion_Priors_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2212.04248",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "CrLXg7Cq8w8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "LinkGAN: Linking GAN Latents to Pixels for Controllable Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zhujiapeng/linkgan",
    "web_page": null,
    "github_page": "https://zhujiapeng.github.io/linkgan/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_LinkGAN_Linking_GAN_Latents_to_Pixels_for_Controllable_Image_Synthesis_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2301.04604",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Open-Vocabulary Object Segmentation with Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Lipurple/Grounded-Diffusion",
    "web_page": null,
    "github_page": "https://lipurple.github.io/Grounded_Diffusion/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Open-vocabulary_Object_Segmentation_with_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2301.05221",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "StyleDiffusion: Controllable Disentangled Style Transfer via Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "rafaelheid-it/StyleDiffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleDiffusion_Controllable_Disentangled_Style_Transfer_via_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.07863",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "ToonTalker: Cross-Domain Face Reenactment",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "OpenTalker/ToonTalker",
    "web_page": null,
    "github_page": "https://opentalker.github.io/ToonTalker/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_ToonTalker_Cross-Domain_Face_Reenactment_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.12866",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Dense Text-to-Image Generation with Attention Modulation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "naver-ai/DenseDiffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.12964",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Householder Projector for Unsupervised Latent Semantics Discovery",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "KingJamesSong/HouseholderGAN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Householder_Projector_for_Unsupervised_Latent_Semantics_Discovery_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.08012",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Deep Image Harmonization with Globally Guided Feature Transformation and Relation Distillation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "bcmi/Image-Harmonization-Dataset-ccHarmony",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Globally_Guided_Feature_Transformation_and_Relation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.00356",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "One-Shot Generative Domain Adaptation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "genforce/genda",
    "web_page": null,
    "github_page": "https://genforce.github.io/genda/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_One-Shot_Generative_Domain_Adaptation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2111.09876",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Hashing Neural Video Decomposition with Multiplicative Residuals in Space-Time",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "vllab/hashing-nvd",
    "web_page": null,
    "github_page": "https://lightbulb12294.github.io/hashing-nvd/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Hashing_Neural_Video_Decomposition_with_Multiplicative_Residuals_in_Space-Time_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.14022",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Versatile Diffusion: Text, Images and Variations All in One Diffusion Model",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "SHI-Labs/Versatile-Diffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/shi-labs/Versatile-Diffusion",
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Versatile_Diffusion_Text_Images_and_Variations_All_in_One_Diffusion_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2211.08332",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Harnessing the Spatial-Temporal Attention of Diffusion Models for High-Fidelity Text-to-Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "UCSB-NLP-Chang/Diffusion-SpaceTime-Attn",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.03869",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "vvictoryuki/FreeDoM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_FreeDoM_Training-Free_Energy-Guided_Conditional_Diffusion_Model_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.09833",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "TencentARC/MasaCtrl",
    "web_page": null,
    "github_page": "https://ljzycmd.github.io/projects/MasaCtrl/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/TencentARC/MasaCtrl",
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.08465",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Personalized Image Generation for Color Vision Deficiency Population",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Jiangshuyi0V0/CVD-GAN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Personalized_Image_Generation_for_Color_Vision_Deficiency_Population_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "ReNeRF: Relightable Neural Radiance Fields with Nearfield Lighting",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ReNeRF_Relightable_Neural_Radiance_Fields_with_Nearfield_Lighting_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "iPBesfjNVXM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "MagicFusion/MagicFusion.github.io",
    "web_page": null,
    "github_page": "https://magicfusion.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MagicFusion_Boosting_Text-to-Image_Generation_Performance_by_Fusing_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.13126",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap using Pose-Preserved Text-to-Image Diffusion",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "gwang-kim/PODIA-3D",
    "web_page": null,
    "github_page": "https://gwang-kim.github.io/podia_3d/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_PODIA-3D_Domain_Adaptation_of_3D_Generative_Model_Across_Large_Domain_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.01900",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "KNpbtqeDshk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Pluralistic Aging Diffusion Autoencoder",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "raywang335/PADA",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Pluralistic_Aging_Diffusion_Autoencoder_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.11086",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "DPM-OT: A New Diffusion Probabilistic Model based on Optimal Transport",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "cognaclee/DPM-OT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DPM-OT_A_New_Diffusion_Probabilistic_Model_Based_on_Optimal_Transport_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.11308",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "yuangan/EAT_code",
    "web_page": null,
    "github_page": "https://yuangan.github.io/eat/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gan_Efficient_Emotional_Adaptation_for_Audio-Driven_Talking-Head_Generation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.04946",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "lp2nSLZp-88",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "DiFaReli: Diffusion Face Relighting",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "diffusion-face-relighting/difareli_code",
    "web_page": null,
    "github_page": "https://diffusion-face-relighting.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ponglertnapakorn_DiFaReli_Diffusion_Face_Relighting_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.09479",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "TALL: Thumbnail Layout for Deepfake Video Detection",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "rainy-xu/TALL4Deepfake",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_TALL_Thumbnail_Layout_for_Deepfake_Video_Detection_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.07494",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "LAW-Diffusion: Complex Scene Generation by Diffusion with Layouts",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAW-Diffusion_Complex_Scene_Generation_by_Diffusion_with_Layouts_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.06713",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "DreamPose: Fashion Video Synthesis with Stable Diffusion",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "johannakarras/DreamPose",
    "web_page": "https://grail.cs.washington.edu/projects/dreampose/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Karras_DreamPose_Fashion_Video_Synthesis_with_Stable_Diffusion_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.06025",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Ablating Concepts in Text-to-Image Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "nupurkmr9/concept-ablation",
    "web_page": "https://www.cs.cmu.edu/~concept-ablation/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/nupurkmr9/concept-ablation",
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kumari_Ablating_Concepts_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.13516",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "DReg-NeRF: Deep Registration for Neural Radiance Fields",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "AIBluefisher/DReg-NeRF",
    "web_page": null,
    "github_page": "https://aibluefisher.github.io/DReg-NeRF/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DReg-NeRF_Deep_Registration_for_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.09386",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "The Euclidean Space is Evil: Hyperbolic Attribute Editing for Few-Shot Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "lingxiao-li/HAE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_The_Euclidean_Space_is_Evil_Hyperbolic_Attribute_Editing_for_Few-shot_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2211.12347",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Discriminative Class Tokens for Text-to-Image Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "idansc/discriminative_class_tokens",
    "web_page": null,
    "github_page": "https://vesteinn.github.io/disco/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Schwartz_Discriminative_Class_Tokens_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.17155",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "General Image-to-Image Translation with One-Shot Image Guidance",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "CrystalNeuro/visual-concept-translator",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.14352",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Text2Performer: Text-Driven Human Video Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "yumingj/Text2Performer",
    "web_page": null,
    "github_page": "https://yumingj.github.io/projects/Text2Performer.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Text2Performer_Text-Driven_Human_Video_Generation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.08483",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "YwhaJUk_qo0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "AesPA-Net: Aesthetic Pattern-Aware Style Transfer Networks",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "kibeom-hong/aespa-net",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_AesPA-Net_Aesthetic_Pattern-Aware_Style_Transfer_Networks_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.09724",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Controllable Person Image Synthesis with Pose-Constrained Latent Diffusion",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "BrandonHanx/PoCoLD",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Controllable_Person_Image_Synthesis_with_Pose-Constrained_Latent_Diffusion_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "PATMAT: Person Aware Tuning of Mask-Aware Transformer for Face Inpainting",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "humansensinglab/PATMAT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Motamed_PATMAT_Person_Aware_Tuning_of_Mask-Aware_Transformer_for_Face_Inpainting_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.06107",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Virtual Try-On with Pose-Garment Keypoints Guided Inpainting",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "lizhi-ntu/KGI",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Virtual_Try-On_with_Pose-Garment_Keypoints_Guided_Inpainting_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Online Clustered Codebook",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "lyndonzheng/CVQ-VAE",
    "web_page": "https://chuanxiaz.com/cvq/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Online_Clustered_Codebook_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.15139",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "g098J5Obxvs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "InfiniCity: Infinite-Scale City Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://hubert0527.github.io/infinicity/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_InfiniCity_Infinite-Scale_City_Synthesis_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2301.09637",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "eaoTVZSLPH4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Make-it-3D: High-fidelity 3D Creation from a Single Image with Diffusion Prior",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "junshutang/Make-It-3D",
    "web_page": null,
    "github_page": "https://make-it-3d.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.14184",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "2M8JJFeDBFk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "SAMPLING: Scene-Adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://pkuvdig.github.io/SAMPLING/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.06323",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "StyleLipSync: Style-based Personalized Lip-Sync Video Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "AMEERAZAM08/StyleLipSync",
    "web_page": null,
    "github_page": "https://stylelipsync.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ki_StyleLipSync_Style-based_Personalized_Lip-sync_Video_Generation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2305.00521",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "StyleInV: A Temporal Style Modulated Inversion Network for Unconditional Video Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "johannwyh/StyleInV",
    "web_page": "https://www.mmlab-ntu.com/project/styleinv/index.html",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleInV_A_Temporal_Style_Modulated_Inversion_Network_for_Unconditional_Video_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.16909",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "R_v_L-32_Vo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "3D-Aware Generative Model for Improved Side-View Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jo_3D-Aware_Generative_Model_for_Improved_Side-View_Image_Synthesis_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.10388",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "YSerin/ZeCon",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Contrastive_Loss_for_Text-Guided_Diffusion_Image_Style_Transfer_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.08622",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "FlipNeRF: Flipped Reflection Rays for Few-Shot Novel View Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "shawn615/FlipNeRF",
    "web_page": null,
    "github_page": "https://shawn615.github.io/flipnerf/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_FlipNeRF_Flipped_Reflection_Rays_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2306.17723",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_XNsRxzaPjw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Inverse Problem Regularization with Hierarchical Variational Autoencoders",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "jprost76/PnP-HVAE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Prost_Inverse_Problem_Regularization_with_Hierarchical_Variational_Autoencoders_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.11217",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "3D-Aware Blending with Generative NeRFs",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "naver-ai/BlendNeRF",
    "web_page": null,
    "github_page": "https://blandocs.github.io/blendnerf",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_3D-aware_Blending_with_Generative_NeRFs_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2302.06608",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "mwLPY-QIxkc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "NeMF: Inverse Volume Rendering with Neural Microflake Field",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "YoujiaZhang/NeMF",
    "web_page": null,
    "github_page": "https://youjiazhang.github.io/NeMF/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_NeMF_Inverse_Volume_Rendering_with_Neural_Microflake_Field_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.00782",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Preserve your Own Correlation: A Noise Prior for Video Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://research.nvidia.com/labs/dir/pyoco/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Preserve_Your_Own_Correlation_A_Noise_Prior_for_Video_Diffusion_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2305.10474",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "iVS-Net: Learning Human View Synthesis from Internet Videos",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_iVS-Net_Learning_Human_View_Synthesis_from_Internet_Videos_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "EGC: Image Generation and Classification via a Diffusion Energy-based Model",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "GuoQiushan/EGC",
    "web_page": null,
    "github_page": "https://guoqiushan.github.io/egc.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.02012",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Automatic Animation of Hair Blowing in Still Portrait Photos",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Rysertio/automatic-hair-blowing",
    "web_page": null,
    "github_page": "https://nevergiveu.github.io/AutomaticHairBlowing/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_Automatic_Animation_of_Hair_Blowing_in_Still_Portrait_Photos_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.14207",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "HoloFusion: Towards Photo-Realistic 3D Generative Modeling",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://holodiffusion.github.io/holofusion/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Karnewar_HoloFusion_Towards_Photo-realistic_3D_Generative_Modeling_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.14244",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "wJ7PfTgcVgM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Foreground Object Search by Distilling Composite Image Feature",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "bcmi/Foreground-Object-Search-Dataset-FOSD",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Foreground_Object_Search_by_Distilling_Composite_Image_Feature_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.04990",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "OrthoPlanes: A Novel Representation for Better 3D-Awareness of GANs",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "OrthoPlanes/op3d",
    "web_page": null,
    "github_page": "https://orthoplanes.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_OrthoPlanes_A_Novel_Representation_for_Better_3D-Awareness_of_GANs_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.15830",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "o8ghAi975vo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "3DHumanGAN: 3D-Aware Human Image Generation with 3D Pose Mapping",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "3dhumangan/3DHumanGAN",
    "web_page": null,
    "github_page": "https://3dhumangan.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2212.07378",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "-bUNfhNYj24",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "MODA: Mapping-Once Audio-Driven Portrait Animation with Dual Attentions",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://liuyunfei.net/projects/iccv23-moda/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MODA_Mapping-Once_Audio-driven_Portrait_Animation_with_Dual_Attentions_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.10008",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "VO6m49VC3zw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Minimum Latency Deep Online Video Stabilization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "liuzhen03/NNDVS",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Minimum_Latency_Deep_Online_Video_Stabilization_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2212.02073",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "StableVideo: Text-Driven Consistency-Aware Diffusion Video Editing",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "rese1f/StableVideo",
    "web_page": null,
    "github_page": "https://rese1f.github.io/StableVideo/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_StableVideo_Text-driven_Consistency-aware_Diffusion_Video_Editing_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.09592",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "qKs09aX1AJM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Localizing Object-Level Shape Variations with Text-to-Image Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "orpatashnik/local-prompt-mixing",
    "web_page": null,
    "github_page": "https://orpatashnik.github.io/local-prompt-mixing/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.11306",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "harlanhong/ICCV2023-MCNET",
    "web_page": null,
    "github_page": "https://harlanhong.github.io/publications/mcnet.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Implicit_Identity_Representation_Conditioned_Memory_Compensation_Network_for_Talking_Head_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.09906",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "ESSAformer: Efficient Transformer for Hyperspectral Image Super-Resolution",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Rexzhan/ESSAformer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.14010",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "GlueGen: Plug and Play Multi-Modal Encoders for X-to-Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "salesforce/GlueGen",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_GlueGen_Plug_and_Play_Multi-modal_Encoders_for_X-to-image_Generation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.10056",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "UHDNeRF: Ultra-High-Definition Neural Radiance Fields",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_UHDNeRF_Ultra-High-Definition_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "All-to-Key Attention for Arbitrary Style Transfer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "LearningHx/StyA2K",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_All-to-Key_Attention_for_Arbitrary_Style_Transfer_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2212.04105",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Diverse Inpainting and Editing with GAN Inversion",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yildirim_Diverse_Inpainting_and_Editing_with_GAN_Inversion_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.15033",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "C9L_4jPNi7k",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "MoTIF: Learning Motion Trajectories with Local Implicit Neural Functions for Continuous Space-Time Video Super-Resolution",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "sichun233746/MoTIF",
    "web_page": null,
    "github_page": "https://sichun233746.github.io/MoTIF/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.07988",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "RANA: Relightable Articulated Neural Avatars",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://nvlabs.github.io/RANA/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Iqbal_RANA_Relightable_Articulated_Neural_Avatars_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2212.03237",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "s-hIhIMjPqQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "DiffCloth: Diffusion based Garment Synthesis and Manipulation via Structural Cross-Modal Semantic Alignment",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DiffCloth_Diffusion_Based_Garment_Synthesis_and_Manipulation_via_Structural_Cross-modal_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.11206",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Masked Diffusion Transformer is a Strong Image Synthesizer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "sail-sg/MDT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/shgao/MDT",
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.14389",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "vvictoryuki/FreeDoM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_FreeDoM_Training-Free_Energy-Guided_Conditional_Diffusion_Model_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.09833",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "CLNeRF: Continual Learning Meets NeRF",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "IntelLabs/CLNeRF",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_CLNeRF_Continual_Learning_Meets_NeRF_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "nLRt6OoDGq0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Rethinking Fast Fourier Convolution in Image Inpainting",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "1911cty/Unbiased-Fast-Fourier-Convolution",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chu_Rethinking_Fast_Fourier_Convolution_in_Image_Inpainting_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Pix2Video: Video Editing using Image Diffusion",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "duyguceylan/pix2video",
    "web_page": null,
    "github_page": "https://duyguceylan.github.io/pix2video.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ceylan_Pix2Video_Video_Editing_using_Image_Diffusion_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.12688",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Multi-View Spectral Polarization Propagation for Video Glass Segmentation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_Multi-view_Spectral_Polarization_Propagation_for_Video_Glass_Segmentation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "WALDO: Future Video Synthesis using Object Layer Decomposition and Parametric Flow Prediction",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "16lemoing/waldo",
    "web_page": null,
    "github_page": "https://16lemoing.github.io/waldo/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Le_Moing_WALDO_Future_Video_Synthesis_Using_Object_Layer_Decomposition_and_Parametric_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2211.14308",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Ray Conditioning: Trading Photo-Consistency for Photo-Realism in Multi-View Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "echen01/ray-conditioning",
    "web_page": null,
    "github_page": "https://ray-cond.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Ray_Conditioning_Trading_Photo-consistency_for_Photo-realism_in_Multi-view_Image_Generation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.13681",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "S88qmycnOJA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Text-Conditioned Sampling Framework for Text-to-Image Generation with Masked Generative Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Text-Conditioned_Sampling_Framework_for_Text-to-Image_Generation_with_Masked_Generative_Models_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.01515",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  },
  {
    "title": "Efficient Video Prediction via Sparsely Conditioned Flow Matching",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "araachie/river",
    "web_page": null,
    "github_page": "https://araachie.github.io/river/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Davtyan_Efficient_Video_Prediction_via_Sparsely_Conditioned_Flow_Matching_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2211.14575",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis"
  }
]