[
  {
    "title": "Skill Transformer: A Monolithic Policy for Mobile Manipulation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Skill_Transformer_A_Monolithic_Policy_for_Mobile_Manipulation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.09873",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "ENTL: Embodied Navigation Trajectory Learner",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kotar_ENTL_Embodied_Navigation_Trajectory_Learner_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.02639",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "DREAMWALKER: Mental Planning for Continuous Vision-Language Navigation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "hanqingwangai/Dreamwalker",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DREAMWALKER_Mental_Planning_for_Continuous_Vision-Language_Navigation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.07498",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Scene Graph Contrastive Learning for Embodied Navigation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Scene_Graph_Contrastive_Learning_for_Embodied_Navigation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Perpetual Humanoid Control for Real-Time Simulated Avatars",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "DelinQu/qrsc",
    "web_page": null,
    "github_page": "https://zhengyiluo.github.io/PHC/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Perpetual_Humanoid_Control_for_Real-time_Simulated_Avatars_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2305.06456",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "zS6Y00EW37A",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Grounding 3D Object Affordance from 2D Interactions in Images",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "yyvhang/IAGNet",
    "web_page": null,
    "github_page": "https://yyvhang.github.io/publications/IAG/index.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.10437",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "GfCPUM1nAHI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Navigating to Objects Specified by Images",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://jacobkrantz.github.io/modular_iin",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Krantz_Navigating_to_Objects_Specified_by_Images_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.01192",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "273jjBvu48s",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "PEANUT: Predicting and Navigating to Unseen Targets",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ajzhai/PEANUT",
    "web_page": null,
    "github_page": "https://ajzhai.github.io/PEANUT/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_PEANUT_Predicting_and_Navigating_to_Unseen_Targets_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2212.02497",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Context-Aware_Planning_and_Environment-Aware_Memory_for_Instruction_Following_Embodied_Agents_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.07241",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Learning Foresightful Dense Visual Affordance for Deformable Object Manipulation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "TritiumR/DeformableAffordance",
    "web_page": null,
    "github_page": "https://hyperplane-lab.github.io/DeformableAffordance/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Foresightful_Dense_Visual_Affordance_for_Deformable_Object_Manipulation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.11057",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "aYneBzwhOGs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Exploiting Proximity-Aware Tasks for Embodied Social Navigation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "EnricoCancelli/ProximitySocialNav",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cancelli_Exploiting_Proximity-Aware_Tasks_for_Embodied_Social_Navigation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2212.00767",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Bird's-Eye-View Scene Graph for Vision-Language Navigation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Birds-Eye-View_Scene_Graph_for_Vision-Language_Navigation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.04758",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Active Neural Mapping",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Active_Neural_Mapping_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.16246",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "psPvanfh7SA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Omnidirectional Information Gathering for Knowledge Transfer-based Audio-Visual Navigation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "chenjinyubuaa/ORAN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Omnidirectional_Information_Gathering_for_Knowledge_Transfer-Based_Audio-Visual_Navigation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.10306",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  },
  {
    "title": "Multi-Object Navigation with Dynamically Learned Neural Implicit Representations",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "PierreMarza/dynamic_implicit_representations",
    "web_page": null,
    "github_page": "https://pierremarza.github.io/projects/dynamic_implicit_representations/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Marza_Multi-Object_Navigation_with_Dynamically_Learned_Neural_Implicit_Representations_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2210.05129",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "r_F9M80GPUI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Embodied Vision: Active Agents, Simulation"
  }
]